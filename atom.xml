<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>DO IT THE GEEK WAY</title>
  <subtitle>GEEK OR DIE</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://athrunsun.github.io/"/>
  <updated>2019-03-18T08:00:19.502Z</updated>
  <id>https://athrunsun.github.io/</id>
  
  <author>
    <name>Bruce Sun</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Reusing Reducer Logic</title>
    <link href="https://athrunsun.github.io/2018/06/09/2018-6/reusing_reducer_logic/"/>
    <id>https://athrunsun.github.io/2018/06/09/2018-6/reusing_reducer_logic/</id>
    <published>2018-06-09T09:48:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://redux.js.org/recipes/structuring-reducers/reusing-reducer-logic" target="_blank" rel="external">Reusing Reducer Logic</a></li>
<li><a href="https://stackoverflow.com/questions/42906358/" target="_blank" rel="external">having multiple instance of same reusable redux react components on the same page/route</a></li>
</ul>
<h1 id="The-problem-description"><a href="#The-problem-description" class="headerlink" title="The problem description"></a>The problem description</h1><p>Say in a web app, we have a lot of data tables on different pages, every table has a pagination component.</p>
<p>How do we setup current page index and current page size for each table? At first thought we might want to setup action creators and reducers for each of the page with the same methods and state inside, just with different module names.</p>
<pre><code class="javascript">// Action creator
const setPageIndex = pageIndex =&gt; ({
    type: &#39;SET_PAGE_INDEX&#39;,
    payload: pageIndex,
});

// Reducer
const createInitialState = () =&gt; ({
    pageIndex: 0,
});

const paginationReducer = (state = createInitialState(), action) =&gt; {
    switch (action.type) {
        case &#39;SET_PAGE_INDEX&#39;:
            return Object.assign({}, state, { pageIndex: action.payload });
        default:
            return state;
    }
};
</code></pre>
<p>But this way we’ll get a lot of duplicate code!</p>
<h1 id="Namespace-to-the-rescue"><a href="#Namespace-to-the-rescue" class="headerlink" title="Namespace to the rescue"></a>Namespace to the rescue</h1><p>All these action creators and reducers share the same logic, just with different names, so in order to reuse the same logic, we should instead build action factory and reducer factory like the following.</p>
<p>Action creator <code>actions/paginationActions.js</code>:</p>
<pre><code class="javascript">const ACTION_TYPES = {
    SET_PAGE_INDEX: &#39;SET_PAGE_INDEX&#39;,
};

const setPageIndexFactory = namespace =&gt; pageIndex =&gt; ({
    type: `${namespace}/${ACTION_TYPES.SET_PAGE_INDEX}`,
    payload: pageIndex,
});

const actionsFactory = namespace =&gt; ({
    setPageIndex: setPageIndexFactory(namespace),
});

export { ACTION_TYPES, actionsFactory };
</code></pre>
<p>Reducer <code>reducers/paginationReducer.js</code>:</p>
<pre><code class="javascript">import { ACTION_TYPES } from &#39;actions/paginationActions&#39;;

const createInitialState = () =&gt; ({
    pageIndex: 0,
});

const paginationReducerFactory = namespace =&gt; (state = createInitialState(), action) =&gt; {
    switch (action.type) {
        case `${namespace}/${ACTION_TYPES.SET_PAGE_INDEX}`:
            return Object.assign({}, state, { pageIndex: action.payload });
        default:
            return state;
    }
};

export default paginationReducerFactory;
</code></pre>
<p>Say the namespace of one of our web pages is <code>DOCUMENT/DETAILS</code>, which is defined in <code>constants.js</code>:</p>
<pre><code class="javascript">const NAMESPACE = {
    DOCUMENT_DETAILS: &#39;DOCUMENT/DETAILS&#39;,
};

export { NAMESPACE };
</code></pre>
<p>In our <code>reducers/index.js</code>, define rootReducer as the following:</p>
<pre><code class="javascript">import { NAMESPACE } from &#39;constants&#39;;
import paginationReducerFactory from &#39;reducers/paginationReducer&#39;;

export default {
    [`pagination_${NAMESPACE.DOCUMENT_DETAILS}`]: paginationReducerFactory(NAMESPACE.DOCUMENT_DETAILS),
};
</code></pre>
<p>And here is how to use it in our components:</p>
<pre><code class="javascript">import React, { Component } from &#39;react&#39;;
import { bindActionCreators } from &#39;redux&#39;;
import { connect } from &#39;react-redux&#39;;

import { NAMESPACE } from &#39;constants&#39;;

import { actionsFactory as allPaginationActionsFactory } from &#39;actions/paginationActions&#39;;

const MODULE_NAMESPACE = NAMESPACE.DOCUMENT_DETAILS;

class DocumentDetails extends Component {
    render() {
        const { pageIndex, paginationActions } = this.props;

        return (
            &lt;DataTable pageIndex={pageIndex} onPageIndexChangeHandler={paginationActions.setPageIndex} /&gt;
        );
    }
}

const mapStateToProps = state =&gt; ({
    pagination: state[`pagination_${MODULE_NAMESPACE}`],
});

const mapDispatchToProps = dispatch =&gt; ({
    paginationActions: bindActionCreators(allPaginationActionsFactory(MODULE_NAMESPACE), dispatch),
});

export default connect(mapStateToProps, mapDispatchToProps)(DocumentDetails);
</code></pre>
<h1 id="Make-it-more-universal"><a href="#Make-it-more-universal" class="headerlink" title="Make it more universal"></a>Make it more universal</h1><p>Say our data table component is universal, here is how to define it in a universal way:</p>
<pre><code class="javascript">import React, { Component } from &#39;react&#39;;
import { bindActionCreators } from &#39;redux&#39;;
import { connect } from &#39;react-redux&#39;;

import { actionsFactory as allPaginationActionsFactory } from &#39;actions/paginationActions&#39;;

class CommonDataTable extends Component {
    render() {
        const { pageIndex, paginationActions } = this.props;

        return (
            ...
        );
    }
}

const mapStateToProps = (state, ownProps) =&gt; ({
    pagination: state[`pagination_${ownProps.namespace}`],
});

const mapDispatchToProps = (dispatch, ownProps) =&gt; ({
    paginationActions: bindActionCreators(allPaginationActionsFactory(ownProps.namespace), dispatch),
});

export default connect(mapStateToProps, mapDispatchToProps)(CommonDataTable);
</code></pre>
<p>So in our <code>DocumentDetails</code> page we shall use it like this:</p>
<pre><code class="javascript">import { NAMESPACE } from &#39;constants&#39;;

const MODULE_NAMESPACE = NAMESPACE.DOCUMENT_DETAILS;

class DocumentDetails extends Component {
    render() {
        return (
            &lt;CommonDataTable namespace={MODULE_NAMESPACE} /&gt;
        );
    }
}
</code></pre>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Official Redux documentation express a different way but I feel the above approach is more comprehensive to me.</p>
<p>At last, reusing reducer logic is IMPORTANT simply because “DO NOT REPEAT YOURSELF” is IMPORTANT.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Reference&quot;&gt;&lt;a href=&quot;#Reference&quot; class=&quot;headerlink&quot; title=&quot;Reference&quot;&gt;&lt;/a&gt;Reference&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://redux.js.org/recipe
    
    </summary>
    
      <category term="Frontend" scheme="https://athrunsun.github.io/categories/Frontend/"/>
    
    
      <category term="React" scheme="https://athrunsun.github.io/tags/React/"/>
    
      <category term="Redux" scheme="https://athrunsun.github.io/tags/Redux/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) Refs and the Reflog</title>
    <link href="https://athrunsun.github.io/2016/12/20/2016-12/refs_and_the_reflog/"/>
    <id>https://athrunsun.github.io/2016/12/20/2016-12/refs_and_the_reflog/</id>
    <published>2016-12-20T13:36:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.atlassian.com/git/tutorials/refs-and-the-reflog/" target="_blank" rel="external">Original Post</a></p>
<img src="/2016/12/20/2016-12/refs_and_the_reflog/header.svg" alt="Header" title="Header">
<h1 id="Refs-and-the-Reflog"><a href="#Refs-and-the-Reflog" class="headerlink" title="Refs and the Reflog"></a>Refs and the Reflog</h1><p>Git is all about commits: you stage commits, create commits, view old commits, and transfer commits between repositories using many different Git commands. The majority of these commands operate on a commit in some form or another, and many of them accept a commit reference as a parameter. For example, you can use <code>git checkout</code> to view an old commit by passing in a commit hash, or you can use it to switch branches by passing in a branch name.</p>
<img src="/2016/12/20/2016-12/refs_and_the_reflog/many_ways_of_referring_to_a_commit.svg" alt="Many ways of referring to a commit" title="Many ways of referring to a commit">
<p>By understanding the many ways to refer to a commit, you make all of these commands that much more powerful. In this chapter, we’ll shed some light on the internal workings of common commands like <code>git checkout</code>, <code>git branch</code>, and <code>git push</code> by exploring the many methods of referring to a commit.</p>
<p>We’ll also learn how to revive seemingly “lost” commits by accessing them through Git’s reflog mechanism.</p>
<h2 id="Hashes"><a href="#Hashes" class="headerlink" title="Hashes"></a>Hashes</h2><p>The most direct way to reference a commit is via its SHA-1 hash. This acts as the unique ID for each commit. You can find the hash of all your commits in the <code>git log</code> output.</p>
<pre><code>commit 0c708fdec272bc4446c6cabea4f0022c2b616eba
Author: Mary Johnson &lt;mary@example.com&gt;
Date:   Wed Jul 9 16:37:42 2014 -0500

    Some commit message
</code></pre><p>When passing the commit to other Git commands, you only need to specify enough characters to uniquely identify the commit. For example, you can inspect the above commit with <code>git show</code> by running the following command:</p>
<pre><code class="shell">git show 0c708f
</code></pre>
<p>It’s sometimes necessary to resolve a branch, tag, or another indirect reference into the corresponding commit hash. For this, you can use the <code>git rev-parse</code> command. The following returns the hash of the commit pointed to by the <code>master</code> branch:</p>
<pre><code class="shell">git rev-parse master
</code></pre>
<p>This is particularly useful when writing custom scripts that accept a commit reference. Instead of parsing the commit reference manually, you can let <code>git rev-parse</code> normalize the input for you.</p>
<h2 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h2><p>A <strong>ref</strong> is an indirect way of referring to a commit. You can think of it as a user-friendly alias for a commit hash. This is Git’s internal mechanism of representing branches and tags.</p>
<p>Refs are stored as normal text files in the <code>.git/refs</code> directory, where <code>.git</code> is usually called <code>.git</code>. To explore the refs in one of your repositories, navigate to <code>.git/refs</code>. You should see the following structure, but it will contain different files depending on what branches, tags, and remotes you have in your repo:</p>
<pre><code>.git/refs/
    heads/
        master
        some-feature
    remotes/
        origin/
            master
    tags/
        v0.9
</code></pre><p>The <code>heads</code> directory defines all of the local branches in you repository. Each filename matches the name of the corresponding branch, and inside the file you’ll find a commit hash. This commit hash is the location of the tip of the branch. To verify this, try running the following two commands from the root of the Git repository:</p>
<pre><code># Output the contents of `refs/heads/master` file:
cat .git/refs/heads/master

# Inspect the commit at the tip of the `master` branch:
git log -1 master
</code></pre><p>The commit hash return by the <code>cat</code> command should match the commit ID displayed by <code>git log</code>.</p>
<p>To change the location of the <code>master</code> branch, all Git has to do is change the contents of the <code>refs/heads/master</code> file. Similarly, creating a new branch is simply a matter of writing a commit hash to a new file. This is part of the reason why Git branches are so lightweight compared to SVN.</p>
<p>The <code>tags</code> directory works the exact same way, but it contains tags instead of branches. The <code>remotes</code> directory lists all remote repositories that you created with <code>git remote</code> as separate subdirectories. Inside each one, you’ll find all the remote branches that have been fetched into your repository.</p>
<h3 id="Specifying-Refs"><a href="#Specifying-Refs" class="headerlink" title="Specifying Refs"></a>Specifying Refs</h3><p>When passing a ref to a Git command, you can either define the full name of the ref, or use a short name and let Git search for a matching ref. You should already be familiar with short names for refs, as this is what you’re using each time you refer to a branch by name.</p>
<pre><code class="shell">git show some-feature
</code></pre>
<p>The <code>some-feature</code> argument in the above command is actually a short name for the branch. Git resolves this to <code>refs/heads/some-feature</code> before using it. You can also specify the full ref on the command line, like so:</p>
<pre><code class="shell">git show refs/heads/some-feature
</code></pre>
<p>This avoids any ambiguity regarding the location of the ref. This is necessary, for instance, if you had both a tag and a branch called <code>some-feature</code>. However, if you’re using proper naming conventions, ambiguity between tags and branches shouldn’t generally be a problem.</p>
<p>We’ll see more full ref names in the Refspecs section.</p>
<h2 id="Packed-Refs"><a href="#Packed-Refs" class="headerlink" title="Packed Refs"></a>Packed Refs</h2><p>For large repositories, Git will periodically perform a garbage collection to remove unnecessary objects and compress refs into a single file for more efficient performance. You can force this compression with the garbage collection command:</p>
<pre><code class="shell">git gc
</code></pre>
<p>This moves all of the individual branch and tag files in the <code>refs</code> folder into a single file called <code>packed-refs</code> located in the top of the <code>.git</code> directory. If you open up this file, you’ll find a mapping of commit hashes to refs:</p>
<pre><code>00f54250cf4e549fdfcafe2cf9a2c90bc3800285 refs/heads/feature
0e25143693cfe9d5c2e83944bbaf6d3c4505eb17 refs/heads/master
bb883e4c91c870b5fed88fd36696e752fb6cf8e6 refs/tags/v0.9
</code></pre><p>On the outside, normal Git functionality won’t be affected in any way. But, if you’re wondering why your <code>.git/refs</code> folder is empty, this is where the refs went.</p>
<h2 id="Special-Refs"><a href="#Special-Refs" class="headerlink" title="Special Refs"></a>Special Refs</h2><p>In addition to the <code>refs</code> directory, there are a few special refs that reside in the top-level <code>.git</code> directory. They are listed below:</p>
<ul>
<li><code>HEAD</code> – The currently checked-out commit/branch.</li>
<li><code>FETCH_HEAD</code> – The most recently fetched branch from a remote repo.</li>
<li><code>ORIG_HEAD</code> – A backup reference to <code>HEAD</code> before drastic changes to it.</li>
<li><code>MERGE_HEAD</code> – The commit(s) that you’re merging into the current branch with <code>git merge</code>.</li>
<li><code>CHERRY_PICK_HEAD</code> – The commit that you’re cherry-picking.</li>
</ul>
<p>These refs are all created and updated by Git when necessary. For example, The <code>git pull</code> command first runs <code>git fetch</code>, which updates the <code>FETCH_HEAD</code> reference. Then, it runs <code>git merge FETCH_HEAD</code> to finish pulling the fetched branches into the repository. Of course, you can use all of these like any other ref, as I’m sure you’ve done with <code>HEAD</code>.</p>
<p>These files contain different content depending on their type and the state of your repository. The <code>HEAD</code> ref can contain either a <strong>symbolic ref</strong>, which is simply a reference to another ref instead of a commit hash, or a commit hash. For example, take a look at the contents of <code>HEAD</code> when you’re on the <code>master</code> branch:</p>
<pre><code class="shell">git checkout master
cat .git/HEAD
</code></pre>
<p>This will output <code>ref: refs/heads/master</code>, which means that <code>HEAD</code> points to the <code>refs/heads/master</code> ref. This is how Git knows that the <code>master</code> branch is currently checked out. If you were to switch to another branch, the contents of <code>HEAD</code> would be updated to reflect the new branch. But, if you were to check out a commit instead of a branch, <code>HEAD</code> would contain a commit hash instead of a symbolic ref. This is how Git knows that it’s in a detached HEAD state.</p>
<p>For the most part, <code>HEAD</code> is the only reference that you’ll be using directly. The others are generally only useful when writing lower-level scripts that need to hook into Git’s internal workings.</p>
<h2 id="Refspecs"><a href="#Refspecs" class="headerlink" title="Refspecs"></a>Refspecs</h2><p>A refspec maps a branch in the local repository to a branch in a remote repository. This makes it possible to manage remote branches using local Git commands and to configure some advanced <code>git push</code> and <code>git fetch</code> behavior.</p>
<p>A refspec is specified as <code>[+]&lt;src&gt;:&lt;dst&gt;</code>. The <code>&lt;src&gt;</code> parameter is the source branch in the local repository, and the <code>&lt;dst&gt;</code> parameter is the destination branch in the remote repository. The optional <code>+</code> sign is for forcing the remote repository to perform a non-fast-forward update.</p>
<p>Refspecs can be used with the <code>git push</code> command to give a different name to the remote branch. For example, the following command pushes the <code>master</code> branch to the <code>origin</code> remote repo like an ordinary <code>git push</code>, but it uses <code>qa-master</code> as the name for the branch in the <code>origin</code> repo. This is useful for QA teams that need to push their own branches to a remote repo.</p>
<pre><code class="shell">git push origin master:refs/heads/qa-master
</code></pre>
<p>You can also use refspecs for deleting remote branches. This is a common situation for feature-branch workflows that push the feature branches to a remote repo (e.g., for backup purposes). The remote feature branches still reside in the remote repo after they are deleted from the local repo, so you get a build-up of dead feature branches as your project progresses. You can delete them by pushing a refspec that has an empty <code>&lt;src&gt;</code> parameter, like so:</p>
<pre><code class="shell">git push origin :some-feature
</code></pre>
<p>This is very convenient, since you don’t need to log in to your remote repository and manually delete the remote branch. Note that as of Git v1.7.0 you can use the <code>--delete</code> flag instead of the above method. The following will have the same effect as the above command:</p>
<pre><code class="shell">git push origin --delete some-feature
</code></pre>
<p>By adding a few lines to the Git configuration file, you can use refspecs to alter the behavior of <code>git fetch</code>. By default, <code>git fetch</code> fetches all of the branches in the remote repository. The reason for this is the following section of the <code>.git/config</code> file:</p>
<pre><code>[remote &quot;origin&quot;]
    url = https://git@github.com:mary/example-repo.git
    fetch = +refs/heads/*:refs/remotes/origin/*
</code></pre><p>The <code>fetch</code> line tells <code>git fetch</code> to download all of the branches from the <code>origin</code> repo. But, some workflows don’t need all of them. For example, many continuous integration workflows only care about the <code>master</code> branch. To fetch only the <code>master</code> branch, change the <code>fetch</code> line to match the following:</p>
<pre><code>[remote &quot;origin&quot;]
    url = https://git@github.com:mary/example-repo.git
    fetch = +refs/heads/master:refs/remotes/origin/master
</code></pre><p>You can also configure <code>git push</code> in a similar manner. For instance, if you want to always push the <code>master</code> branch to <code>qa-master</code> in the <code>origin</code> remote (as we did above), you would change the config file to:</p>
<pre><code>[remote &quot;origin&quot;]
    url = https://git@github.com:mary/example-repo.git
    fetch = +refs/heads/master:refs/remotes/origin/master
    push = refs/heads/master:refs/heads/qa-master
</code></pre><p>Refspecs give you complete control over how various Git commands transfer branches between repositories. They let you rename and delete branches from your local repository, fetch/push to branches with different names, and configure <code>git push</code> and <code>git fetch</code> to work with only the branches that you want.</p>
<h2 id="Relative-Refs"><a href="#Relative-Refs" class="headerlink" title="Relative Refs"></a>Relative Refs</h2><p>You can also refer to commits relative to another commit. The <code>~</code> character lets you reach parent commits. For example, the following displays the grandparent of <code>HEAD</code>:</p>
<pre><code class="shell">git show HEAD~2
</code></pre>
<p>But, when working with merge commits, things get a little more complicated. Since merge commits have more than one parent, there is more than one path that you can follow. For 3-way merges, the first parent is from the branch that you were on when you performed the merge, and the second parent is from the branch that you passed to the <code>git merge</code> command.</p>
<p>The <code>~</code> character will always follow the first parent of a merge commit. If you want to follow a different parent, you need to specify which one with the <code>^</code> character. For example, if <code>HEAD</code> is a merge commit, the following returns the second parent of <code>HEAD</code>.</p>
<pre><code class="shell">git show HEAD^2
</code></pre>
<p>You can use more than one <code>^</code> character to move more than one generation. For instance, this displays the grandparent of <code>HEAD</code> (assuming it’s a merge commit) that rests on the <em>second</em> parent.</p>
<pre><code class="shell">git show HEAD^2^1
</code></pre>
<p>To clarify how <code>~</code> and <code>^</code> work, the following figure shows you how to reach any commit from <code>A</code> using relative references. In some cases, there are multiple ways to reach a commit.</p>
<img src="/2016/12/20/2016-12/refs_and_the_reflog/accessing_commits_using_relative_refs.svg" alt="Accessing commits using relative refs" title="Accessing commits using relative refs">
<p>Relative refs can be used with the same commands that a normal ref can be used. For example, all of the following commands use a relative reference:</p>
<pre><code># Only list commits that are parent of the second parent of a merge commit
git log HEAD^2

# Remove the last 3 commits from the current branch
git reset HEAD~3

# Interactively rebase the last 3 commits on the current branch
git rebase -i HEAD~3
</code></pre><h2 id="The-Reflog"><a href="#The-Reflog" class="headerlink" title="The Reflog"></a>The Reflog</h2><p>The reflog is Git’s safety net. It records almost every change you make in your repository, regardless of whether you committed a snapshot or not. You can think of it is a chronological history of everything you’ve done in your local repo. To view the reflog, run the <code>git reflog</code> command. It should output something that looks like the following:</p>
<pre><code>400e4b7 HEAD@{0}: checkout: moving from master to HEAD~2
0e25143 HEAD@{1}: commit (amend): Integrate some awesome feature into `master`
00f5425 HEAD@{2}: commit (merge): Merge branch &#39;;feature&#39;;
ad8621a HEAD@{3}: commit: Finish the feature
</code></pre><p>This can be translated as follows:</p>
<ul>
<li>You just checked out <code>HEAD~2</code></li>
<li>Before that you amended a commit message</li>
<li>Before that you merged the <code>feature</code> branch into <code>master</code></li>
<li>Before that you committed a snapshot</li>
</ul>
<p>The <code>HEAD{&lt;n&gt;}</code> syntax lets you reference commits stored in the reflog. It works a lot like the <code>HEAD~&lt;n&gt;</code> references from the previous section, but the <code>&lt;n&gt;</code> refers to an entry in the reflog instead of the commit history.</p>
<p>You can use this to revert to a state that would otherwise be lost. For example, lets say you just scrapped a new feature with <code>git reset</code>. Your reflog might look something like this:</p>
<pre><code>ad8621a HEAD@{0}: reset: moving to HEAD~3
298eb9f HEAD@{1}: commit: Some other commit message
bbe9012 HEAD@{2}: commit: Continue the feature
9cb79fa HEAD@{3}: commit: Start a new feature
</code></pre><p>The three commits before the <code>git reset</code> are now dangling, which means that there is no way to reference them—except through the reflog. Now, let’s say you realize that you shouldn’t have thrown away all of your work. All you have to do is check out the <code>HEAD@{1}</code> commit to get back to the state of your repository before you ran <code>git reset</code>.</p>
<pre><code>git checkout HEAD@{1}
</code></pre><p>This puts you in a detached <code>HEAD</code> state. From here, you can create a new branch and continue working on your feature.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>You should now be quite comfortable referring to commits in a Git repository. We learned how branches and tags were stored as refs in the <code>.git</code> subdirectory, how to read a <code>packed-refs</code> file, how <code>HEAD</code> is represented, how to use refspecs for advanced pushing and fetching, and how to use the relative <code>~</code> and <code>^</code> operators to traverse a branch hierarchy.</p>
<p>We also took a look at the reflog, which is a way to reference commits that are not available through any other means. This is a great way to recover from those little “Oops, I shouldn’t have done that” situations.</p>
<p>The point of all this was to be able to pick out exactly the commit that you need in any given development scenario. It’s very easy to leverage the skills you learned in this article against your existing Git knowledge, as some of the most common commands accept refs as arguments, including <code>git log</code>, <code>git show</code>, <code>git checkout</code>, <code>git reset</code>, <code>git revert</code>, <code>git rebase</code>, and many others.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.atlassian.com/git/tutorials/refs-and-the-reflog/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;img src=&quot;/20
    
    </summary>
    
      <category term="Git" scheme="https://athrunsun.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://athrunsun.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) Merging vs. Rebasing</title>
    <link href="https://athrunsun.github.io/2016/12/19/2016-12/merging_vs_rebasing/"/>
    <id>https://athrunsun.github.io/2016/12/19/2016-12/merging_vs_rebasing/</id>
    <published>2016-12-19T08:00:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.atlassian.com/git/tutorials/merging-vs-rebasing" target="_blank" rel="external">Original Post</a></p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/header.svg" alt="Header" title="Header">
<h1 id="Merging-vs-Rebasing"><a href="#Merging-vs-Rebasing" class="headerlink" title="Merging vs. Rebasing"></a>Merging vs. Rebasing</h1><p>The <code>git rebase</code> command has a reputation for being magical Git voodoo that beginners should stay away from, but it can actually make life much easier for a development team when used with care. In this article, we’ll compare <code>git rebase</code> with the related <code>git merge</code> command and identify all of the potential opportunities to incorporate rebasing into the typical Git workflow.</p>
<h2 id="Conceptual-Overview"><a href="#Conceptual-Overview" class="headerlink" title="Conceptual Overview"></a>Conceptual Overview</h2><p>The first thing to understand about <code>git rebase</code> is that it solves the same problem as <code>git merge</code>. Both of these commands are designed to integrate changes from one branch into another branch—they just do it in very different ways.</p>
<p>Consider what happens when you start working on a new feature in a dedicated branch, then another team member updates the master branch with new commits. This results in a forked history, which should be familiar to anyone who has used Git as a collaboration tool.</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/a_forked_commit_history.svg" alt="A forked commit history" title="A forked commit history">
<p>Now, let’s say that the new commits in <code>master</code> are relevant to the feature that you’re working on. To incorporate the new commits into your <code>feature</code> branch, you have two options: merging or rebasing.</p>
<h3 id="The-Merge-Option"><a href="#The-Merge-Option" class="headerlink" title="The Merge Option"></a>The Merge Option</h3><p>The easiest option is to merge the <code>master</code> branch into the feature branch using something like the following:</p>
<pre><code class="shell">git checkout feature
git merge master
</code></pre>
<p>Or, you can condense this to a one-liner:</p>
<pre><code class="shell">git merge master feature
</code></pre>
<p>This creates a new “merge commit” in the <code>feature</code> branch that ties together the histories of both branches, giving you a branch structure that looks like this:</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/merging_master_into_the_feature_branch.svg" alt="Merging master into the feature branch" title="Merging master into the feature branch">
<p>Merging is nice because it’s a <em>non-destructive</em> operation. The existing branches are not changed in any way. This avoids all of the potential pitfalls of rebasing (discussed below).</p>
<p>On the other hand, this also means that the <code>feature</code> branch will have an extraneous merge commit every time you need to incorporate upstream changes. If <code>master</code> is very active, this can pollute your feature branch’s history quite a bit. While it’s possible to mitigate this issue with advanced <code>git log</code> options, it can make it hard for other developers to understand the history of the project.</p>
<h3 id="The-Rebase-Option"><a href="#The-Rebase-Option" class="headerlink" title="The Rebase Option"></a>The Rebase Option</h3><p>As an alternative to merging, you can rebase the <code>feature</code> branch onto <code>master</code> branch using the following commands:</p>
<pre><code class="shell">git checkout feature
git rebase master
</code></pre>
<p>This moves the entire <code>feature</code> branch to begin on the tip of the <code>master</code> branch, effectively incorporating all of the new commits in <code>master</code>. But, instead of using a merge commit, rebasing <em>re-writes</em> the project history by creating brand new commits for each commit in the original branch.</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/rebasing_the_feature_branch_onto_master.svg" alt="Rebasing the feature branch onto master" title="Rebasing the feature branch onto master">
<p>The major benefit of rebasing is that you get a much cleaner project history. First, it eliminates the unnecessary merge commits required by <code>git merge</code>. Second, as you can see in the above diagram, rebasing also results in a perfectly linear project history—you can follow the tip of <code>feature</code> all the way to the beginning of the project without any forks. This makes it easier to navigate your project with commands like <code>git log</code>, <code>git bisect</code>, and <code>gitk</code>.</p>
<p>But, there are two trade-offs for this pristine commit history: safety and traceability. If you don’t follow the <a href="https://www.atlassian.com/git/tutorials/merging-vs-rebasing/conceptual-overview#the-golden-rule-of-rebasing" target="_blank" rel="external">Golden Rule of Rebasing</a>, re-writing project history can be potentially catastrophic for your collaboration workflow. And, less importantly, rebasing loses the context provided by a merge commit—you can’t see when upstream changes were incorporated into the feature.</p>
<h3 id="Interactive-Rebasing"><a href="#Interactive-Rebasing" class="headerlink" title="Interactive Rebasing"></a>Interactive Rebasing</h3><p>Interactive rebasing gives you the opportunity to alter commits as they are moved to the new branch. This is even more powerful than an automated rebase, since it offers complete control over the branch’s commit history. Typically, this is used to clean up a messy history before merging a feature branch into <code>master</code>.</p>
<p>To begin an interactive rebasing session, pass the <code>i</code> option to the <code>git rebase</code> command:</p>
<pre><code class="shell">git checkout feature
git rebase -i master
</code></pre>
<p>This will open a text editor listing all of the commits that are about to be moved:</p>
<pre><code>pick 33d5b7a Message for commit #1
pick 9480b3d Message for commit #2
pick 5c67e61 Message for commit #3
</code></pre><p>This listing defines exactly what the branch will look like after the rebase is performed. By changing the <code>pick</code> command and/or re-ordering the entries, you can make the branch’s history look like whatever you want. For example, if the 2nd commit fixes a small problem in the 1st commit, you can condense them into a single commit with the <code>fixup</code> command:</p>
<pre><code>pick 33d5b7a Message for commit #1
fixup 9480b3d Message for commit #2
pick 5c67e61 Message for commit #3
</code></pre><p>When you save and close the file, Git will perform the rebase according to your instructions, resulting in project history that looks like the following:</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/squashing_a_commit_with_an_interactive_rebase.svg" alt="Squashing a commit with an interactive rebase" title="Squashing a commit with an interactive rebase">
<p>Eliminating insignificant commits like this makes your feature’s history much easier to understand. This is something that <code>git merge</code> simply cannot do.</p>
<h2 id="The-Golden-Rule-of-Rebasing"><a href="#The-Golden-Rule-of-Rebasing" class="headerlink" title="The Golden Rule of Rebasing"></a>The Golden Rule of Rebasing</h2><p>Once you understand what rebasing is, the most important thing to learn is when not to do it. The golden rule of <code>git rebase</code> is to never use it on <em>public</em> branches.</p>
<p>For example, think about what would happen if you rebased <code>master</code> onto your <code>feature</code> branch:</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/rebasing_the_master_branch.svg" alt="Rebasing the master branch" title="Rebasing the master branch">
<p>The rebase moves all of the commits in <code>master</code> onto the tip of <code>feature</code>. The problem is that this only happened in your repository. All of the other developers are still working with the original <code>master</code>. Since rebasing results in brand new commits, Git will think that your <code>master</code> branch’s history has diverged from everybody else’s.</p>
<p>The only way to synchronize the two <code>master</code> branches is to merge them back together, resulting in an extra merge commit and two sets of commits that contain the same changes (the original ones, and the ones from your rebased branch). Needless to say, this is a very confusing situation.</p>
<p>So, before you run <code>git rebase</code>, always ask yourself, “Is anyone else looking at this branch?” If the answer is yes, take your hands off the keyboard and start thinking about a non-destructive way to make your changes (e.g., the <code>git revert</code> command). Otherwise, you’re safe to re-write history as much as you like.</p>
<h3 id="Force-Pushing"><a href="#Force-Pushing" class="headerlink" title="Force-Pushing"></a>Force-Pushing</h3><p>If you try to push the rebased <code>master</code> branch back to a remote repository, Git will prevent you from doing so because it conflicts with the remote <code>master</code> branch. But, you can force the push to go through by passing the <code>--force</code> flag, like so:</p>
<pre><code class="shell"># Be very careful with this command!
git push --force
</code></pre>
<p>This overwrites the remote <code>master</code> branch to match the rebased one from your repository and makes things very confusing for the rest of your team. So, be very careful to use this command only when you know exactly what you’re doing.</p>
<p>One of the only times you should be force-pushing is when you’ve performed a local cleanup after you’ve pushed a private feature branch to a remote repository (e.g., for backup purposes). This is like saying, “Oops, I didn’t really want to push that original version of the feature branch. Take the current one instead.” Again, it’s important that nobody is working off of the commits from the original version of the feature branch.</p>
<h2 id="Workflow-Walkthrough"><a href="#Workflow-Walkthrough" class="headerlink" title="Workflow Walkthrough"></a>Workflow Walkthrough</h2><p>Rebasing can be incorporated into your existing Git workflow as much or as little as your team is comfortable with. In this section, we’ll take a look at the benefits that rebasing can offer at the various stages of a feature’s development.</p>
<p>The first step in any workflow that leverages <code>git rebase</code> is to create a dedicated branch for each feature. This gives you the necessary branch structure to safely utilize rebasing:</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/developing_a_feature_in_a_dedicated_branch.svg" alt="Developing a feature in a dedicated branch" title="Developing a feature in a dedicated branch">
<h3 id="Local-Cleanup"><a href="#Local-Cleanup" class="headerlink" title="Local Cleanup"></a>Local Cleanup</h3><p>One of the best ways to incorporate rebasing into your workflow is to clean up local, in-progress features. By periodically performing an interactive rebase, you can make sure each commit in your feature is focused and meaningful. This lets you write your code without worrying about breaking it up into isolated commits—you can fix it up after the fact.</p>
<p>When calling <code>git rebase</code>, you have two options for the new base: The feature’s parent branch (e.g., <code>master</code>), or an earlier commit in your feature. We saw an example of the first option in the Interactive Rebasing section. The latter option is nice when you only need to fix up the last few commits. For example, the following command begins an interactive rebase of only the last 3 commits.</p>
<pre><code class="shell">git checkout feature
git rebase -i HEAD~3
</code></pre>
<p>By specifying <code>HEAD~3</code> as the new base, you’re not actually moving the branch—you’re just interactively re-writing the 3 commits that follow it. Note that this will not incorporate upstream changes into the <code>feature</code> branch.</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/rebasing_onto_head_3.svg" alt="Rebasing onto HEAD~3" title="Rebasing onto HEAD~3">
<p>If you want to re-write the entire feature using this method, the <code>git merge-base</code> command can be useful to find the original base of the <code>feature</code> branch. The following returns the commit ID of the original base, which you can then pass to <code>git rebase</code>:</p>
<pre><code class="shell">git merge-base feature master
</code></pre>
<p>This use of interactive rebasing is a great way to introduce <code>git rebase</code> into your workflow, as it only affects local branches. The only thing other developers will see is your finished product, which should be a clean, easy-to-follow feature branch history.</p>
<p>But again, this only works for <em>private</em> feature branches. If you’re collaborating with other developers via the same feature branch, that branch is <em>public</em>, and you’re not allowed to re-write its history.</p>
<p>There is no <code>git merge</code> alternative for cleaning up local commits with an interactive rebase.</p>
<h3 id="Incorporating-Upstream-Changes-Into-a-Feature"><a href="#Incorporating-Upstream-Changes-Into-a-Feature" class="headerlink" title="Incorporating Upstream Changes Into a Feature"></a>Incorporating Upstream Changes Into a Feature</h3><p>In the <em>Conceptual Overview</em> section, we saw how a feature branch can incorporate upstream changes from <code>master</code> using either <code>git merge</code> or <code>git rebase</code>. Merging is a safe option that preserves the entire history of your repository, while rebasing creates a linear history by moving your feature branch onto the tip of <code>master</code>.</p>
<p>This use of <code>git rebase</code> is similar to a local cleanup (and can be performed simultaneously), but in the process it incorporates those upstream commits from <code>master</code>.</p>
<p>Keep in mind that it’s perfectly legal to rebase onto a remote branch instead of <code>master</code>. This can happen when collaborating on the same feature with another developer and you need to incorporate their changes into your repository.</p>
<p>For example, if you and another developer named John added commits to the <code>feature</code> branch, your repository might look like the following after fetching the remote <code>feature</code> branch from John’s repository:</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/collaborating_on_the_same_feature_branch.svg" alt="Collaborating on the same feature branch" title="Collaborating on the same feature branch">
<p>You can resolve this fork the exact same way as you integrate upstream changes from <code>master</code>: either merge your local <code>feature</code> with <code>john/feature</code>, or rebase your local <code>feature</code> onto the tip of <code>john/feature</code>.</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/merging_vs_rebasing_onto_a_remote_branch.svg" alt="Merging vs. rebasing onto a remote branch" title="Merging vs. rebasing onto a remote branch">
<p>Note that this rebase doesn’t violate the Golden Rule of Rebasing because only your local <code>feature</code> commits are being moved—everything before that is untouched. This is like saying, “add my changes to what John has already done.” In most circumstances, this is more intuitive than synchronizing with the remote branch via a merge commit.</p>
<p>By default, the <code>git pull</code> command performs a merge, but you can force it to integrate the remote branch with a rebase by passing it the <code>--rebase</code> option.</p>
<h3 id="Reviewing-a-Feature-With-a-Pull-Request"><a href="#Reviewing-a-Feature-With-a-Pull-Request" class="headerlink" title="Reviewing a Feature With a Pull Request"></a>Reviewing a Feature With a Pull Request</h3><p>If you use pull requests as part of your code review process, you need to avoid using <code>git rebase</code> after creating the pull request. As soon as you make the pull request, other developers will be looking at your commits, which means that it’s a public branch. Re-writing its history will make it impossible for Git and your teammates to track any follow-up commits added to the feature.</p>
<p>Any changes from other developers need to be incorporated with <code>git merge</code> instead of <code>git rebase</code>.</p>
<p>For this reason, it’s usually a good idea to clean up your code with an interactive rebase <em>before</em> submitting your pull request.</p>
<h3 id="Integrating-an-Approved-Feature"><a href="#Integrating-an-Approved-Feature" class="headerlink" title="Integrating an Approved Feature"></a>Integrating an Approved Feature</h3><p>After a feature has been approved by your team, you have the option of rebasing the feature onto the tip of the <code>master</code> branch before using <code>git merge</code> to integrate the feature into the main code base.</p>
<p>This is a similar situation to incorporating upstream changes into a feature branch, but since you’re not allowed to re-write commits in the <code>master</code> branch, you have to eventually use <code>git merge</code> to integrate the feature. However, by performing a rebase before the merge, you’re assured that the merge will be fast-forwarded, resulting in a perfectly linear history. This also gives you the chance to squash any follow-up commits added during a pull request.</p>
<img src="/2016/12/19/2016-12/merging_vs_rebasing/integrating_a_feature_into_master_with_and_without_a_rebase.svg" alt="Integrating a feature into master with and without a rebase" title="Integrating a feature into master with and without a rebase">
<p>If you’re not entirely comfortable with <code>git rebase</code>, you can always perform the rebase in a temporary branch. That way, if you accidentally mess up your feature’s history, you can check out the original branch and try again. For example:</p>
<pre><code class="shell">git checkout feature
git checkout -b temporary-branch
git rebase -i master
# [Clean up the history]
git checkout master
git merge temporary-branch
</code></pre>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>And that’s all you really need to know to start rebasing your branches. If you would prefer a clean, linear history free of unnecessary merge commits, you should reach for <code>git rebase</code> instead of <code>git merge</code> when integrating changes from another branch.</p>
<p>On the other hand, if you want to preserve the complete history of your project and avoid the risk of re-writing public commits, you can stick with <code>git merge</code>. Either option is perfectly valid, but at least now you have the option of leveraging the benefits of <code>git rebase</code>.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.atlassian.com/git/tutorials/merging-vs-rebasing&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;img src=&quot;/201
    
    </summary>
    
      <category term="Git" scheme="https://athrunsun.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://athrunsun.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) Lessons learned from a connection leak in production</title>
    <link href="https://athrunsun.github.io/2016/11/21/2016-11/lessons_learned_from_a_connection_leak_in_production/"/>
    <id>https://athrunsun.github.io/2016/11/21/2016-11/lessons_learned_from_a_connection_leak_in_production/</id>
    <published>2016-11-21T01:17:00.000Z</published>
    <updated>2019-03-18T08:00:19.498Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://phillbarber.blogspot.com/2014/02/lessons-learned-from-connection-leak-in.html" target="_blank" rel="external">Original Post</a></p>
<p>We recently encountered a connection leak with one of our services in production.  Here’s what happened, what we did and the lessons learned…</p>
<h1 id="Tests-and-Monitoring-detected-the-issue-silently"><a href="#Tests-and-Monitoring-detected-the-issue-silently" class="headerlink" title="Tests and Monitoring detected the issue (silently)"></a>Tests and Monitoring detected the issue (silently)</h1><p>Our automated tests (which run in production for this service) started failing soon after the incident occurred.  We didn’t immediately realise since they just went red on the dashboard and we just carried on about our business.  Our monitoring detected the issue immediately and also went red but crucially didn’t email us due to an environment specific config issue.</p>
<h2 id="The-alarm-is-raised"><a href="#The-alarm-is-raised" class="headerlink" title="The alarm is raised"></a>The alarm is raised</h2><p>A tester on the team realises that the tests had been failing for some time (some time being 4 hours… eek!) and gets us to start investigating.</p>
<p>Myself and another dev quickly looked into what was going on with our poorly <a href="http://dropwizard.codahale.com/" target="_blank" rel="external">dropwizard</a> app.  We could see from the monitoring dashboard that the application’s health check page was in error.  Viewing the page showed us that a downstream service (being called over http) was resulting in the following exception…</p>
<pre><code>com.sun.jersey.api.client.ClientHandlerException:
org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool
</code></pre><p>My gut reaction was that this was a timeout issue (since it usually is) and connections were not being released back to the connection pool after either slow connections or responses.  We saved the <a href="http://dropwizard.codahale.com/manual/core/#metrics" target="_blank" rel="external">metrics</a> info from the application and performed the classic <code>java kill -3</code> to get a thread dump for later reading.  We tried checking connectivity from the application’s host to the downstream service with telnet which revealed no issue.  We also tried simulating a http request with <code>wget</code> which (after a bit of confusion trying to suppress ssl certificate checking) also revealed no issues.  With no more debug ideas immediately coming to mind, restoring service had to be the priority.  A restart was performed and everything went green again.</p>
<p>Looking in the code revealed no obvious problems.  We had set our timeouts like good boy scouts and just couldn’t figure out what was wrong.  It clearly needed more investigation.</p>
<h1 id="We-see-the-same-thing-happening-in-our-Test-environment…-Great"><a href="#We-see-the-same-thing-happening-in-our-Test-environment…-Great" class="headerlink" title="We see the same thing happening in our Test environment… Great!"></a>We see the same thing happening in our Test environment… Great!</h1><p>With a lot more time to debug (what seemed like) the exact same issue we came up with the idea of looking at the current connections on the box….</p>
<pre><code>netstat -a
</code></pre><p>This revealed a lot of connections in the CLOSE_WAIT state.</p>
<p>A simple word count….</p>
<pre><code>netstat -a  | grep CLOSE_WAIT | wc -l
</code></pre><p>…gave us 1024 which just so happened to be the exact maximum size of our connection pool.  The connection pool was exhausted.  Restarting the application bought this down to zero and restored service as it did in production.</p>
<h1 id="Now-we-can-monitor-our-leak"><a href="#Now-we-can-monitor-our-leak" class="headerlink" title="Now we can monitor our leak"></a>Now we can monitor our leak</h1><p>With the command above, we were able to establish how many connections in the pool were in the CLOSE_WAIT state.  The closer it gets to 1024, the closer we are to another outage.  We then had the great idea of piping this command into mailx and spamming the team with the number every few hours.</p>
<p>Until we fix the connection leak - we need to keep an eye on these emails and restart the application before the bucket over fills (i.e. the connection pool is exhausted).  </p>
<h1 id="What-caused-the-leak"><a href="#What-caused-the-leak" class="headerlink" title="What caused the leak?"></a>What caused the leak?</h1><p>We were using Jersey which in-turn was using HttpComponents4 to send a http request to another service.  The service being called was very simple and did not return any response body, just a status code which was all we were interested in.  If the status code was 200, the user was logged in, anything else we treat as unauthorised.</p>
<p>The code below shows our mistake….</p>
<pre><code>public boolean isSessionActive(HttpServletRequest httpRequest) {
   ClientResponse response = jerseyClient
      .resource(url)
      .type(APPLICATION_JSON_TYPE)
      .header(&quot;Cookie&quot;, httpRequest.getHeader(&quot;Cookie&quot;))
      .get(ClientResponse.class);
  return response.getStatus() == 200;
}
</code></pre><p>We were not calling <code>close()</code> on the <code>ClientResponse</code> object which meant that the response’s input stream was not being closed, which meant that the connection was not released back into the pool.  This was a silly oversight on our part.  However, there’s a twist…</p>
<p>We had run performance tests which in turn executed this method a million times (far more invocations than connections in the pool) without us ever hitting any issues.  The question was, if the code was wrong, why was it not failing all the time?  </p>
<h1 id="For-every-bug-there’s-a-missing-test"><a href="#For-every-bug-there’s-a-missing-test" class="headerlink" title="For every bug, there’s a missing test"></a>For every bug, there’s a missing test</h1><p>The task of creating a test which would fail reliably each time due to this issue was 99% of the effort in understanding what was going on.  Before we identified the above culprit, a tester on our team, amazingly, found the exact scenario which caused the leased connections to increase.  It seemed that each time the service responded with a 403, the number of leased connections would increase by one.</p>
<p>Our component tests mocked the service being called in the above code with a great tool called <a href="http://wiremock.org/" target="_blank" rel="external">wiremock</a> which allows you to fully mock a web service by sending http requests to a server under your control.  When we examined the number of leased connections after the mocked 403 response, frustratingly it did not increase.  There was something different from our mocked 403 response and the actual 403 response.</p>
<p>The issue was, in a deployed environment, we called the webservice through a http load balancer that was configured to give an html error page if the response was 4xx.  This scenario created an input stream on the <code>ClientResponse</code> object which needed to be closed.</p>
<p>As soon as we adjusted our wiremock config to return a response body, we observed the same connection leak as in our deployed environment.  Now we could write a test that would fail due to the bug.  Rather than stop there, we concluded that there was no point in us checking the status after the one test alone as next time it could fail in a different place.  We added the following methods and annotations to our test base class:</p>
<pre><code>@Before
public void initialiseLeasedConnectionsCount() throws Exception{
   leasedConnectionCounts = getLeasedConnections();
}

@After
public void checkLeasedConnectionsHasNotIncremented() throws Exception{
   int leasedConnectionsAfter = getLeasedConnections();
   if (leasedConnectionCounts != leasedConnectionsAfter){
      fail(&quot;Expected to see leasedConnections stay the same but increased from : &quot; + leasedConnectionCounts + &quot; to: &quot; + leasedConnectionsAfter);
   }
}
</code></pre><p>If we hit another connection leak, we’ll know the exact scenario and it shouldn’t get anywhere near production this time.  Now we have a failing test, lets make it pass by fixing the connection leak….</p>
<pre><code>public boolean isSessionActive(HttpServletRequest httpRequest) {
   ClientResponse response = null;
   try{
      response = jerseyClient
         .resource(url)
         .type(APPLICATION_JSON_TYPE)
         .header(&quot;Cookie&quot;, httpRequest.getHeader(&quot;Cookie&quot;))
         .get(ClientResponse.class);
      return response.getStatus() == SC_OK;
   }
   finally {
      if (response != null){
         response.close();
      }
   }
}
</code></pre><h1 id="Lessons-Learned"><a href="#Lessons-Learned" class="headerlink" title="Lessons Learned"></a>Lessons Learned</h1><h2 id="Make-sure-your-alerts-alert"><a href="#Make-sure-your-alerts-alert" class="headerlink" title="Make sure your alerts alert"></a>Make sure your alerts alert</h2><p>Until you have proven you are actually getting emails to your inbox, all your wonderfully clever monitoring/alerting may be useless.  We lost 4 hours of availability this way!<br>I think that this is so important that I’m tempted to say it’s worth causing an incident when everyone is paying attention just to prove you have all the bases covered. <a href="http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html" target="_blank" rel="external">Netflix do this as routine</a> and at random times too.</p>
<h2 id="A-connection-pool-almost-exhausted-should-fire-an-alert"><a href="#A-connection-pool-almost-exhausted-should-fire-an-alert" class="headerlink" title="A connection pool almost exhausted should fire an alert"></a>A connection pool almost exhausted should fire an alert</h2><p>If we had received an alert when the connection pool was at around 75% capacity, we would have investigated, our connection leak before it caused an outage.  This has also been mentioned by bitly <a href="http://word.bitly.com/post/74839060954/ten-things-to-monitor" target="_blank" rel="external">here</a>.  I will endeavour to get this in place ASAP.</p>
<h2 id="Learn-your-tools"><a href="#Learn-your-tools" class="headerlink" title="Learn your tools"></a>Learn your tools</h2><p>Getting a thread dump by sending your java process the SIGQUIT (i.e. kill -3 [java process id]) is fine but it relies on you having access to the box and permissions to run it.  In our case (using <a href="http://dropwizard.codahale.com/" target="_blank" rel="external">dropwizard</a> and <a href="http://dropwizard.codahale.com/manual/core/#metrics" target="_blank" rel="external">metrics</a>) all I needed to do was go to this url /metrics/threads on the admin port for exactly the same data formatted in json.</p>
<h2 id="Other-Lessons"><a href="#Other-Lessons" class="headerlink" title="Other Lessons?"></a>Other Lessons?</h2><p>If you can spot any other lessons learned from this, feel free to comment.</p>
<p>EDIT: <a href="http://phillbarber.blogspot.co.uk/2015/02/how-to-test-for-connection-leaks.html" target="_blank" rel="external">See here for a more detailed explanation of how to test for connection leaks and this time with all the code!</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://phillbarber.blogspot.com/2014/02/lessons-learned-from-connection-leak-in.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Po
    
    </summary>
    
      <category term="Java" scheme="https://athrunsun.github.io/categories/Java/"/>
    
    
      <category term="Java" scheme="https://athrunsun.github.io/tags/Java/"/>
    
      <category term="HttpClient" scheme="https://athrunsun.github.io/tags/HttpClient/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) Setting up Vim for JavaScript development - Comparisons and information for useful JavaScript-specific plugins</title>
    <link href="https://athrunsun.github.io/2016/11/16/2016-11/setting_up_vim_for_javascript_development/"/>
    <id>https://athrunsun.github.io/2016/11/16/2016-11/setting_up_vim_for_javascript_development/</id>
    <published>2016-11-16T06:12:00.000Z</published>
    <updated>2019-03-18T08:00:19.498Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://davidosomething.com/blog/vim-for-javascript/" target="_blank" rel="external">Original Post</a></p>
<h1 id="Installing-plugins"><a href="#Installing-plugins" class="headerlink" title="Installing plugins"></a>Installing plugins</h1><p>I recommend using <a href="https://github.com/junegunn/vim-plug" target="_blank" rel="external">vim-plug</a> to install plugins. It’s simple, works on both Vim and Neovim, and can perform operations asynchronously.</p>
<ul>
<li><a href="https://github.com/junegunn/vim-plug" target="_blank" rel="external">vim-plug</a></li>
</ul>
<h1 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h1><p>Vim comes with a JavaScript syntax file. It is automatically loaded when you open up a JavaScript file (where the value of <code>filetype</code> is <code>javascript</code>).</p>
<p>By default Vim doesn’t automatically detect filetypes, so if you aren’t using vim-plug, you’ll need to enable it manually by adding this to your vimrc:</p>
<pre><code>filetype plugin indent on
</code></pre><p>This will enable filetype detection, running filetype specific plugins, and loading filetype specific indentation settings.</p>
<p>You may also need to enable syntax highlighting in your vimrc file if you’re not using <a href="https://github.com/junegunn/vim-plug" target="_blank" rel="external">vim-plug</a>. To manually enable syntax highlighting, add the following line to your vimrc file:</p>
<pre><code>syntax enable
</code></pre><h2 id="Plugins-that-provide-better-syntax-support"><a href="#Plugins-that-provide-better-syntax-support" class="headerlink" title="Plugins that provide better syntax support"></a>Plugins that provide better syntax support</h2><p>The standard JavaScript syntax highlighting is typically adequate, but you may want more features such as ES2015 support, or better distinguishing of keywords.</p>
<p>There are quite a few options:</p>
<ul>
<li><a href="https://github.com/pangloss/vim-javascript" target="_blank" rel="external">pangloss/vim-javascript</a><ul>
<li>Includes custom indent settings. These indent settings are also the ones included in the Vim default runtime now, and the one in the plugin may be trailing what comes with Vim (i.e., Vim has a newer version of the same indent file!)</li>
<li>Adds special concealing symbols so to make your code pretty at a glance</li>
<li>Last updated April 2016 with additional ES2015 support (better arrow function and highlighting among other things) and some regex performance updates.</li>
</ul>
</li>
<li><a href="https://github.com/sheerun/vim-polyglot" target="_blank" rel="external">sheerun/vim-polyglot</a><ul>
<li>This is a plugin that bundles a bunch of language syntax plugins into one. It includes <a href="https://github.com/pangloss/vim-javascript" target="_blank" rel="external">pangloss/vim-javascript</a> at the latest version, as well as some other plugins like <a href="https://github.com/mxw/vim-jsx" target="_blank" rel="external">mxw/vim-jsx</a>. Worth checking out if you don’t want to maintain syntax plugins on your own, but you should double-check to make sure you aren’t manually adding the bundled plugins outside of the pack (resulting in having the plugin twice).</li>
</ul>
</li>
<li><a href="https://github.com/jelera/vim-javascript-syntax" target="_blank" rel="external">jelera/vim-javascript-syntax</a><ul>
<li>Does not include custom indent settings (not that you need them…)</li>
<li>Updated about once a month according to the GitHub contributors graph</li>
</ul>
</li>
<li><a href="https://github.com/othree/yajs.vim" target="_blank" rel="external">othree/yajs.vim</a><ul>
<li>This is a fork of <a href="jelera/vim-javascript-syntax">jelera/vim-javascript-syntax</a></li>
<li>Does not include custom indent settings (again, you might not need one)</li>
<li>Updated very often to keep in line with ES specifications</li>
</ul>
</li>
<li><a href="https://github.com/bigfish/vim-js-context-coloring" target="_blank" rel="external">bigfish/vim-js-context-coloring</a><ul>
<li>This is an interesting new method of syntax highlighting. It picks out function scopes from your program by runningg it through a node.js binary that runs a JavaScript parser and assigns a color to the scope. Things within that scope are assigned a color. Because it requires in-depth parsing of your code, it may not color your code when it is incomplete (i.e., the syntax is not yet valid).</li>
<li>This syntax plugin can be used in combination with any of the above, and you can toggle it on and off.</li>
</ul>
</li>
</ul>
<p>With the exception of vim-js-context-coloring, <strong>all of these provide ES2015 (ES6) and JSDoc support to varying degrees</strong>, which Vim lacks by default. I personally use and recommend <a href="https://github.com/pangloss/vim-javascript" target="_blank" rel="external">pangloss/vim-javascript</a> purely because it has started active development again. I have not experienced any issues since switching to this from <a href="https://github.com/othree/yajs.vim" target="_blank" rel="external">othree/yajs.vim</a>.</p>
<p><a href="https://github.com/othree/yajs.vim" target="_blank" rel="external">othree/yajs.vim</a> with <a href="https://github.com/othree/es.next.syntax.vim" target="_blank" rel="external">es.next.syntax.vim</a> might better suit your needs if you use ES2016 (ES7). The author also writes a few other plugins that can be used in conjunction with it (although they may work with the other syntaxes, too, depending on the syntax groups provided). I’ve used this plugin extensively in place of the default syntax and haven’t had any problems.</p>
<p>Using <a href="https://github.com/junegunn/vim-plug" target="_blank" rel="external">vim-plug</a>, I recommend installing the plugin like this:</p>
<pre><code>Plug &#39;othree/yajs.vim&#39;, { &#39;for&#39;: &#39;javascript&#39; }
</code></pre><p>The additional requirement at the end makes sure the syntax plugin is loaded in a Vim autocommand based on filetype detection (as opposed to relying on Vim’s <code>runtimepath</code> based sourcing mechanism. This way the main Vim syntax plugin will have already run, and the plugin’s syntax will override it.</p>
<h3 id="Plugins-that-provide-better-indentation-support"><a href="#Plugins-that-provide-better-indentation-support" class="headerlink" title="Plugins that provide better indentation support"></a>Plugins that provide better indentation support</h3><p>Vim’s bundled JavaScript indent may be enough for you, especially if you use a strictly C-style whitespace (Vim’s C-style indent options is even called <code>cindent</code>). Vim, as of August 26, 2016, comes with a modified version of the <a href="https://github.com/pangloss/vim-javascript" target="_blank" rel="external">pangloss/vim-javascript</a> indent rules that does not include the reformatting <code>gq</code> action. This means 99% of people probably won’t need to change their indent file.</p>
<p>Some notable options in this case are:</p>
<ul>
<li><a href="https://github.com/pangloss/vim-javascript" target="_blank" rel="external">pangloss/vim-javascript</a><ul>
<li>Using this entire syntax plugin will provide you with a more JavaScript-y indent for things like switch/case and multi-line var declarations.</li>
<li>This indent plugin has a side-effect in that it also changes the format expression – that is, if you highlight a block and use <code>gq</code> to reformat it, it will re-indent the code using this plugin as well.</li>
<li>The Vim runtime (stuff that comes with Vim) may include a newer version of this indent file that does not have the modified <code>gq</code>.</li>
</ul>
</li>
<li><a href="https://github.com/gavocanov/vim-js-indent" target="_blank" rel="external">gavocanov/vim-js-indent</a><ul>
<li>I don’t recommend this one, but I’ve listed it here because you’ll probably find it and have questions. The author no longer uses it, so it should not be considered.</li>
<li>This is the indent portion of <a href="https://github.com/pangloss/vim-javascript" target="_blank" rel="external">pangloss/vim-javascript</a>, ripped out into its own plugin.</li>
<li>There are modifications to it, diverging it from <a href="https://github.com/pangloss/vim-javascript" target="_blank" rel="external">pangloss/vim-javascript</a>, notably support for the syntax group names in <a href="https://github.com/othree/yajs.vim" target="_blank" rel="external">othree/yajs.vim</a>. That helps it pick out keywords and when you are inside comments if you are using othree/yajs.vim.</li>
<li>The format expression from the pangloss plugin has been removed.</li>
</ul>
</li>
<li><a href="https://github.com/itspriddle/vim-javascript-indent" target="_blank" rel="external">itspriddle/vim-javascript-indent</a><ul>
<li>This is a git mirror of <a href="http://www.vim.org/scripts/script.php?script_id=1936" target="_blank" rel="external">Ryan Fabella’s indent script</a></li>
<li>It mostly detects closing brackets and parentheses and indents based on what it finds.</li>
</ul>
</li>
<li><a href="https://github.com/jiangmiao/simple-javascript-indenter" target="_blank" rel="external">jiangmiao/simple-javascript-indenter</a><ul>
<li>An indent plugin with an option for alignment under functions.</li>
</ul>
</li>
<li><a href="https://github.com/jason0x43/vim-js-indent" target="_blank" rel="external">jason0x43/vim-js-indent</a><ul>
<li>This is a somewhat new (last updated 2014, as of this writing) indent script that also has some TypeScript support. It is based on an <a href="http://www.vim.org/scripts/script.php?script_id=1840" target="_blank" rel="external">older indent script by Tye Zdrojewski</a> and the default JS-in-HTML indent logic that comes with Vim.</li>
<li>The indent logic starts with normal <code>cindent</code> styles and adds special cases for comments, JSDoc, arrays, and switch/case.</li>
</ul>
</li>
</ul>
<p>Your best bet is to stick with what comes with Vim by default, and only try out the others if your coding style does not match what the rest of the JavaScript community is converging towards. If there’s a quirk, it is probably better to submit an issue with the <a href="https://github.com/pangloss/vim-javascript" target="_blank" rel="external">pangloss/vim-javascript</a> repo.</p>
<h1 id="Related-syntaxes"><a href="#Related-syntaxes" class="headerlink" title="Related syntaxes"></a>Related syntaxes</h1><p>During JavaScript development you may find yourself editing a lot of other filetypes that plain JavaScript.</p>
<h2 id="es-next-ES2016-ES7-support"><a href="#es-next-ES2016-ES7-support" class="headerlink" title="es.next / ES2016 / ES7 support"></a>es.next / ES2016 / ES7 support</h2><p>othree has a syntax plugin that provides support for planned, but not-yet-final EcmaScript features: <a href="https://github.com/othree/es.next.syntax.vim" target="_blank" rel="external">othree/es.next.syntax.vim</a>. I personally don’t use it since I currently stick to the ES2015 feature set at most.</p>
<ul>
<li><a href="https://github.com/othree/es.next.syntax.vim" target="_blank" rel="external">othree/es.next.syntax.vim</a></li>
</ul>
<h2 id="JSX-support-for-React"><a href="#JSX-support-for-React" class="headerlink" title="JSX support for React"></a>JSX support for React</h2><p>If you write React and use its optional JSX syntax, adding the following plugin will provide you with syntax highlighting for those inline XML-nodes:</p>
<pre><code>Plug &#39;mxw/vim-jsx&#39;
</code></pre><p>This plugin requires a JavaScript syntax plugin from above to define certain JavaScript regions. It specifically mentions pangloss’ extension in the docs but <a href="https://github.com/mxw/vim-jsx/commit/80dbab7588c615126f47e50fa4d9c329d080ff95#diff-604ad63592f45d351d97cdc9eeae21a3R28" target="_blank" rel="external">actually supports any of them</a>.</p>
<ul>
<li><a href="https://github.com/mxw/vim-jsx" target="_blank" rel="external">mxw/vim-jsx</a></li>
</ul>
<h2 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h2><p>A lot of things use JSON for configuration, so I recommend <a href="https://github.com/elzr/vim-json" target="_blank" rel="external">elzr/vim-json</a> for that. Check out its options, though; I don’t like some of the defaults so I turn them off, but you might want them. Install with:</p>
<pre><code>Plug &#39;elzr/vim-json&#39;
</code></pre><ul>
<li><a href="https://github.com/elzr/vim-json" target="_blank" rel="external">elzr/vim-json</a></li>
</ul>
<h2 id="JSDoc-syntax-highlighting"><a href="#JSDoc-syntax-highlighting" class="headerlink" title="JSDoc syntax highlighting"></a>JSDoc syntax highlighting</h2><p>If you document using JSDoc, all of the syntax plugins above support JSDoc highlighting already. There’s a plugin called <a href="https://github.com/othree/jsdoc-syntax.vim" target="_blank" rel="external">othree/jsdoc-syntax.vim</a> that pulls that support out of <a href="https://github.com/othree/yajs.vim" target="_blank" rel="external">othree/yajs.vim</a>, but it is only for adding JSDoc support to other languages like TypeScript.</p>
<ul>
<li><a href="https://github.com/othree/jsdoc-syntax.vim" target="_blank" rel="external">othree/jsdoc-syntax.vim</a></li>
</ul>
<h2 id="JSDoc-auto-snippets"><a href="#JSDoc-auto-snippets" class="headerlink" title="JSDoc auto-snippets"></a>JSDoc auto-snippets</h2><p>The plugin <a href="https://github.com/heavenshell/vim-jsdoc" target="_blank" rel="external">heavenshell/vim-jsdoc</a> can automatically insert JSDoc comments for you if your cursor is on a function definition. It’ll check for the function name, arguments, and add the doc-block comment for you.<br>I use this plugin quite often (I actually have a fork of it with some additions but hopefully they get merged into the upstream).</p>
<ul>
<li><a href="https://github.com/heavenshell/vim-jsdoc" target="_blank" rel="external">heavenshell/vim-jsdoc</a></li>
</ul>
<h2 id="jQuery-plugins"><a href="#jQuery-plugins" class="headerlink" title="jQuery plugins"></a>jQuery plugins</h2><p>Files named <code>jquery.*.js</code> are typically jQuery plugins. There’s a specific syntax highlighting plugin for such files: <a href="https://github.com/itspriddle/vim-jquery" target="_blank" rel="external">itspriddle/vim-jquery</a>, but it’s pretty old and you’ll have better support combining an up-to-date syntax plugin with the JavaScript libraries plugin in the next section.</p>
<ul>
<li><a href="https://github.com/itspriddle/vim-jquery" target="_blank" rel="external">itspriddle/vim-jquery</a></li>
</ul>
<h2 id="JavaScript-libraries"><a href="#JavaScript-libraries" class="headerlink" title="JavaScript libraries"></a>JavaScript libraries</h2><p>othree has a syntax plugin, <a href="https://github.com/othree/javascript-libraries-syntax.vim" target="_blank" rel="external">othree/javascript-libraries-syntax.vim</a>, that supports special highlighting of functions and keywords for various libraries such as jQuery, lodash, React, Handlebars, Chai, etc. For an extensive list, see the README at the plugin’s homepage.</p>
<p>I personally do use this plugin.</p>
<ul>
<li><a href="https://github.com/othree/javascript-libraries-syntax.vim" target="_blank" rel="external">othree/javascript-libraries-syntax.vim</a></li>
</ul>
<h1 id="JavaScript-code-completion-for-Vim"><a href="#JavaScript-code-completion-for-Vim" class="headerlink" title="JavaScript code completion for Vim"></a>JavaScript code completion for Vim</h1><h2 id="Omni-completion"><a href="#Omni-completion" class="headerlink" title="Omni completion"></a>Omni completion</h2><p>I won’t go into too much detail about this since it isn’t JavaScript specific.</p>
<p>Vim includes basic code completion built in. See <a href="http://vim.wikia.com/wiki/Omni_completion" target="_blank" rel="external">this wikia article</a> for information on how to use that. The gist is that the completion system will run a function, the <code>omnifunc</code>, to populate autocompletion pop-up with results.</p>
<p>To use the default completion function, add this to your vimrc:</p>
<pre><code>autocmd FileType javascript setlocal omnifunc=javascriptcomplete#CompleteJS
</code></pre><p>For even better completion, consider using a plugin like <a href="https://github.com/Shougo/neocomplete.vim" target="_blank" rel="external">Shougo/neocomplete.vim</a> or <a href="https://github.com/Valloric/YouCompleteMe" target="_blank" rel="external">Valloric/YouCompleteMe</a>. On Neovim, an option is <a href="https://github.com/Shougo/deoplete.nvim" target="_blank" rel="external">Shougo/deoplete.nvim</a>.</p>
<p>These plugins will add features like automatically popping up the completion menu, caching of keywords, and integration with other sources of completion than what’s in the current Vim buffer (allowing for multiple <code>omnifunc</code>s).</p>
<p>For portability across my systems without needing a recompile, I use <a href="https://github.com/Shougo/neocomplete.vim" target="_blank" rel="external">Shougo/neocomplete.vim</a>. Shougo’s plugins and YouCompleteMe both offer roughly the same feature set, though, so whatever might be missing in one can probably be configured into it.</p>
<p>With <a href="https://github.com/Shougo/neocomplete.vim" target="_blank" rel="external">Shougo/neocomplete.vim</a>, using multiple sources of completion can be done by providing a list of function names like so:</p>
<pre><code>let g:neocomplete#sources#omni#functions.javascript = [
    \   &#39;jspc#omni&#39;,
    \   &#39;tern#Complete&#39;,
    \ ]
</code></pre><h2 id="Extended-omni-completion"><a href="#Extended-omni-completion" class="headerlink" title="Extended omni-completion"></a>Extended omni-completion</h2><p>The plugin <a href="https://github.com/1995eaton/vim-better-javascript-completion" target="_blank" rel="external">1995eaton/vim-better-javascript-completion</a> provides a somewhat up-to-date JavaScript with HTML5 methods (e.g. <code>localStorage</code> and <code>canvas</code> methods).</p>
<p>This plugin creates a new omni-completion function, <code>js#CompleteJS</code>, and replaces your current JS <code>omnifunc</code> with that. That means you’ll have to use a completion plugin or write some VimL yourself if you want to use it in conjunction with another <code>omnifunc</code> like TernJS in the next section.</p>
<ul>
<li><a href="https://github.com/1995eaton/vim-better-javascript-completion" target="_blank" rel="external">1995eaton/vim-better-javascript-completion</a></li>
</ul>
<h2 id="Code-analysis-based-completion-via-TernJS"><a href="#Code-analysis-based-completion-via-TernJS" class="headerlink" title="Code-analysis based completion via TernJS"></a>Code-analysis based completion via TernJS</h2><p>TernJS is kind of like IntelliSense if you’ve ever used Visual Studio, or like the autocompletion for many very robust IDEs. It parses your code and extracts various symbols, like function names, variable names, and values.</p>
<p>The official vim plugin can also show you function signatures (what parameters parameters it expects) and can extract values from related files (e.g. CommonJS <code>require()</code>‘d files) if you configure it to do so (via a <code>.tern-project</code>).</p>
<p>The completion is provided to Vim’s auto-completion engine via an <code>omnifunc</code>, <code>tern#Complete</code>. Again, you’ll have to setup your <code>omnifunc</code> appropriately to use TernJS results instead of the default omni-completion results.</p>
<p>Installing via <a href="https://github.com/junegunn/vim-plug" target="_blank" rel="external">vim-plug</a>, which can run additional commands before plugin installation, is done like this:</p>
<pre><code>Plug &#39;marijnh/tern_for_vim&#39;, { &#39;do&#39;: &#39;npm install&#39; }
</code></pre><p>This will install its npm dependencies for you (Tern runs a node-based analyzer in the background while you’re editing).</p>
<p>I use this plugin with many of its extra features turned off, just keeping the completion.</p>
<ul>
<li><a href="https://github.com/marijnh/tern_for_vim" target="_blank" rel="external">marijnh/tern_for_vim</a></li>
</ul>
<h2 id="Function-parameter-completion"><a href="#Function-parameter-completion" class="headerlink" title="Function parameter completion"></a>Function parameter completion</h2><p>othree has a plugin called JavaScript Parameter Complete that detects when you’re inside a function argument and provides some common autocomplete suggestions for it. This is not a feature that TernJS provides, since Tern only adds existing symbols. For example, if you’re writing an event listener, it’ll suggest things like <code>click</code>, and <code>mouseover</code> for you. You can see all the suggestions it provides in its GitHub source. Install the plugin via:</p>
<pre><code>Plug &#39;othree/jspc.vim&#39;
</code></pre><p>On load, the jspc.vim plugin automatically detects whatever <code>omnifunc</code> you already have set as your default. It wraps it with the parameter completion, and falls back to your default if you are not in a parameter completion. Because of this you should specify <code>jspc#omni</code> instead of whatever your default completion is (typically <code>javascriptcomplete#CompleteJS</code>).</p>
<ul>
<li><a href="https://github.com/othree/jspc.vim" target="_blank" rel="external">othree/jspc.vim</a></li>
</ul>
<h1 id="Code-navigation"><a href="#Code-navigation" class="headerlink" title="Code navigation"></a>Code navigation</h1><h2 id="Jumping-between-CommonJS-modules"><a href="#Jumping-between-CommonJS-modules" class="headerlink" title="Jumping between CommonJS modules"></a>Jumping between CommonJS modules</h2><p>The plugin <a href="https://github.com/moll/vim-node" target="_blank" rel="external">moll/vim-node</a> adds keybindings like for jumping to files in your CommonJS <code>require</code> statements.</p>
<pre><code>Plug &#39;moll/vim-node&#39;
</code></pre><ul>
<li><a href="https://github.com/moll/vim-node" target="_blank" rel="external">moll/vim-node</a></li>
</ul>
<h2 id="CTags-Symbol-based-navigation"><a href="#CTags-Symbol-based-navigation" class="headerlink" title="CTags - Symbol based navigation"></a>CTags - Symbol based navigation</h2><p>CTags are lists of all symbols in your projects (function names, variable names, filenames, etc.). Vim provides ctag support by default, with keybindings to jump to declarations and definitions, and there are a slew of plugins (e.g. <a href="https://github.com/ludovicchabant/vim-gutentags" target="_blank" rel="external">ludovicchabant/vim-gutentags</a>) that can auto-generate the tags file for you. Using <a href="https://github.com/majutsushi/tagbar" target="_blank" rel="external">majutsushi/tagbar</a>, <a href="https://github.com/Shougo/unite.vim" target="_blank" rel="external">Shougo/unite.vim</a>, <a href="https://github.com/ctrlpvim/ctrlp.vim" target="_blank" rel="external">ctrlpvim/ctrlp.vim</a>, or a bunch of other plugins (and plugins that work with them – plugin-plugins), you can browse through those tags.</p>
<p>Of particular note on the generation side is <a href="https://github.com/ramitos/jsctags" target="_blank" rel="external">ramitos/jsctags</a>, which will generate ctags using TernJS.</p>
<p>Personally, I find ctags too annoying to use since the files need to be regenerated to search them (except with <a href="https://github.com/majutsushi/tagbar" target="_blank" rel="external">majutsushi/tagbar</a> which runs ctags on every open, but only for the current file). Usually just using <code>git grep</code> or <a href="https://github.com/ggreer/the_silver_searcher" target="_blank" rel="external">the_silver_searcher</a> is adequate, and there are plugins for those, too (out of scope for this article).</p>
<ul>
<li><a href="https://github.com/ramitos/jsctags" target="_blank" rel="external">ramitos/jsctags</a></li>
</ul>
<h1 id="Linting"><a href="#Linting" class="headerlink" title="Linting"></a>Linting</h1><p>While there are actually JSHint, JSLint, eslint, etc. runners for Vim, for your own sanity just use <a href="https://github.com/scrooloose/syntastic" target="_blank" rel="external">scrooloose/syntastic</a>. It supports a variety of syntax checkers, but you may need to install them first. For example, for eslint support, which is the standard these days, <code>npm install -g eslint</code> first. Refer to syntastic’s <a href="https://github.com/scrooloose/syntastic/wiki/JavaScript" target="_blank" rel="external">wiki page on configuring various JavaScript linters</a>.</p>
<p>Syntastic’s pitfalls are that it is large (it is essentially a linter framework for Vim) and it doesn’t run asynchronously (doesn’t mean it is slow though – depends on the speed of the lint program).</p>
<p>You could alternatively use Vim’s built-in <code>makeprg</code>, which can run any program and output the results to Vim, but you miss out on things like using multiple <code>makeprg</code>s at a time (e.g. JSCS, eslint, and the flow type checker at once) and grouping results. Syntastic actually uses makeprg under the covers, so besides the minimal overhead of configuring some variables it really isn’t any slower.</p>
<p>There’s <a href="https://github.com/osyo-manga/vim-watchdogs" target="_blank" rel="external">osyo-manga/vim-watchdogs</a>, which runs linters asynchronously, but the docs are only in Japanese. The plugins <a href="https://github.com/Shougo/vimproc.vim" target="_blank" rel="external">Shougo/vimproc.vim</a> and <a href="https://github.com/tpope/vim-dispatch" target="_blank" rel="external">tpope/vim-dispatch</a> can run any tool async, but they aren’t easily configurable as lint-runners. If you follow modern JS design patterns, your JavaScript files should ideally be small modules so running linters asynchronously won’t provide noticeable benefit.</p>
<p>If you’re running Neovim, <a href="https://github.com/benekastah/neomake" target="_blank" rel="external">neomake</a> is an option that’s gaining popularity. It makes full use of Neovim’s asynchronous job support.</p>
<ul>
<li><a href="https://github.com/scrooloose/syntastic" target="_blank" rel="external">scrooloose/syntastic</a></li>
<li><a href="https://github.com/osyo-manga/vim-watchdogs" target="_blank" rel="external">osyo-manga/vim-watchdogs</a></li>
<li><a href="https://github.com/benekastah/neomake" target="_blank" rel="external">neomake</a></li>
</ul>
<h1 id="Formatting"><a href="#Formatting" class="headerlink" title="Formatting"></a>Formatting</h1><p>Vim has a built-in re-formatter for whitespace. Visually select some text and use the <code>=</code> key to re-indent all of it.</p>
<p>For minified JS, there’s a vim plugin, <a href="https://github.com/maksimr/vim-jsbeautify" target="_blank" rel="external">vim-jsbeautify</a>, that can run your code through jsbeautifier for you. I personally don’t use this and prefer to go to the jsbeautifier website, copying and pasting it there if I need to un-minify something.</p>
<p>There’s also <a href="https://github.com/Chiel92/vim-autoformat" target="_blank" rel="external">Chiel92/vim-autoformat</a>, which supports formatters for many different languages. Of note is <a href="http://jscs.info/" target="_blank" rel="external">jscs</a> and <a href="https://github.com/einars/js-beautify" target="_blank" rel="external">js-beautifier</a> support.</p>
<ul>
<li><a href="https://github.com/maksimr/vim-jsbeautify" target="_blank" rel="external">vim-jsbeautify</a></li>
<li><a href="https://github.com/Chiel92/vim-autoformat" target="_blank" rel="external">Chiel92/vim-autoformat</a></li>
</ul>
<h1 id="My-Vim-setup"><a href="#My-Vim-setup" class="headerlink" title="My Vim setup"></a>My Vim setup</h1><p>You can dig through <a href="https://github.com/davidosomething/dotfiles/tree/master/vim" target="_blank" rel="external">my Vim configuration on GitHub</a>. The plugins I use are all in the main vimrc file, and their configurations are interspersed into <code>plugin/</code>, <code>ftplugin/</code>, and <code>after/*/</code> to cope with the order in which Vim loads files.</p>
<ul>
<li><a href="https://github.com/davidosomething/dotfiles/tree/master/vim" target="_blank" rel="external">my Vim configuration on GitHub</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://davidosomething.com/blog/vim-for-javascript/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;Installing-pl
    
    </summary>
    
      <category term="Vim" scheme="https://athrunsun.github.io/categories/Vim/"/>
    
    
      <category term="Vim" scheme="https://athrunsun.github.io/tags/Vim/"/>
    
      <category term="JavaScript" scheme="https://athrunsun.github.io/tags/JavaScript/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) VIM and Python - a Match Made in Heaven</title>
    <link href="https://athrunsun.github.io/2016/11/16/2016-11/vim_and_python_a_match_made_in_heaven/"/>
    <id>https://athrunsun.github.io/2016/11/16/2016-11/vim_and_python_a_match_made_in_heaven/</id>
    <published>2016-11-16T02:09:00.000Z</published>
    <updated>2019-03-18T08:00:19.498Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://realpython.com/blog/python/vim-and-python-a-match-made-in-heaven/" target="_blank" rel="external">Original Post</a></p>
<p>It has come to my attention that somebody ‘round these parts has been preaching the gospel of <a href="https://realpython.com/blog/python/setting-up-sublime-text-3-for-full-stack-python-development/" target="_blank" rel="external">Sublime Text 3</a>. Well, as the resident senior developer (err, old fogey), I feel it’s my duty to provide a counterexample by way of the only TRUE Python development environment you will ever need – and that environment is of course <a href="http://www.vim.org/" target="_blank" rel="external">VIM</a>. That’s right. VIM is ubiquitous, fast, and never crashes. And it can do just about anything!</p>
<p>On the down side though, VIM can be a pain to configure, but fear not – <strong>This article will show you how to get a powerful VIM environment setup, geared towards wrangling Python day in and day out.</strong></p>
<img src="/2016/11/16/2016-11/vim_and_python_a_match_made_in_heaven/vim_as_python_ide_overview.png" alt="VIM as python IDE overview" title="VIM as python IDE overview">
<blockquote>
<p>To get the most out of this article you should have at least a basic understanding on how to use VIM and its command modes. If you’re just getting started, check out <a href="http://vim-adventures.com/" target="_blank" rel="external">this resource</a> or <a href="http://www.openvim.com/" target="_blank" rel="external">this one</a>. Spend some time with it before moving on.</p>
</blockquote>
<h1 id="Installing"><a href="#Installing" class="headerlink" title="Installing"></a>Installing</h1><p>Since VIM comes pre-installed on a number of <a href="https://en.wikipedia.org/wiki/Unix-like" target="_blank" rel="external">*nix</a> systems, let’s first and foremost check to see if it’s installed:</p>
<pre><code class="shell">vim --version
</code></pre>
<p>If installed, you should see something like:</p>
<pre><code>VIM - Vi IMproved 7.3 (2010 Aug 15, compiled Nov  5 2014 21:00:28)
Compiled by root@apple.com
Normal version without GUI.  Features included (+) or not (-):
-arabic +autocmd -balloon_eval -browse +builtin_terms +byte_offset +cindent
-clientserver -clipboard +cmdline_compl +cmdline_hist +cmdline_info +comments
-conceal +cryptv +cscope +cursorbind +cursorshape +dialog_con +diff +digraphs
-dnd -ebcdic -emacs_tags +eval +ex_extra +extra_search -farsi +file_in_path
+find_in_path +float +folding -footer +fork() -gettext -hangul_input +iconv
+insert_expand +jumplist -keymap -langmap +libcall +linebreak +lispindent
+listcmds +localmap -lua +menu +mksession +modify_fname +mouse -mouseshape
-mouse_dec -mouse_gpm -mouse_jsbterm -mouse_netterm -mouse_sysmouse
+mouse_xterm +multi_byte +multi_lang -mzscheme +netbeans_intg -osfiletype
+path_extra -perl +persistent_undo +postscript +printer -profile +python/dyn
-python3 +quickfix +reltime -rightleft +ruby/dyn +scrollbind +signs
+smartindent -sniff +startuptime +statusline -sun_workshop +syntax +tag_binary
+tag_old_static -tag_any_white -tcl +terminfo +termresponse +textobjects +title
 -toolbar +user_commands +vertsplit +virtualedit +visual +visualextra +viminfo
+vreplace +wildignore +wildmenu +windows +writebackup -X11 -xfontset -xim -xsmp
 -xterm_clipboard -xterm_save
   system vimrc file: &quot;$VIM/vimrc&quot;
     user vimrc file: &quot;$HOME/.vimrc&quot;
      user exrc file: &quot;$HOME/.exrc&quot;
  fall-back for $VIM: &quot;/usr/share/vim&quot;
Compilation: gcc -c -I. -D_FORTIFY_SOURCE=0 -Iproto -DHAVE_CONFIG_H -arch i386 -arch x86_64 -g -Os -pipe
Linking: gcc -arch i386 -arch x86_64 -o vim -lncurses
</code></pre><p>At this point, you want to look for two things-</p>
<ol>
<li><em>The VIM version.</em> This should be &gt; 7.3.</li>
<li><em>Python Support.</em> Under the list of features, make sure you see <code>+python</code>.</li>
</ol>
<p>If you have both of these, then move right along to <a href="https://realpython.com/blog/python/vim-and-python-a-match-made-in-heaven/#vim-extensions" target="_blank" rel="external">VIM Extensions</a>. If not, it’s time to <a href="http://www.vim.org/download.php" target="_blank" rel="external">install/upgrade</a>.</p>
<h2 id="OSX"><a href="#OSX" class="headerlink" title="OSX"></a>OSX</h2><p>Grab <a href="http://brew.sh/" target="_blank" rel="external">Homebrew</a>, if you don’t already have it, and run:</p>
<pre><code class="shell">$ brew update
$ brew install vim
</code></pre>
<h2 id="NIX"><a href="#NIX" class="headerlink" title="*NIX"></a>*NIX</h2><p>For Debian or Ubuntu you can try:</p>
<pre><code class="shell">$ sudo apt-get remove vim-tiny
$ sudo apt-get update
$ sudo apt-get install vim
</code></pre>
<p>For other flavors of Linux check the docs from your package manager. Here is a link to get you started: <a href="http://oss.sgi.com/LDP/HOWTO/Vim-HOWTO/introduction.html" target="_blank" rel="external">Install Vim</a></p>
<h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2><p>There are many different ways to install VIM on Windows. Start with the <a href="http://www.vim.org/download.php#pc" target="_blank" rel="external">official docs</a>.</p>
<h1 id="Verifying-the-Install"><a href="#Verifying-the-Install" class="headerlink" title="Verifying the Install"></a>Verifying the Install</h1><p>Make sure you have installed VIM &gt; 7.3 with Python support. Again, run <code>vim --version</code> to verify this. If you want to check the specific version of Python used in VIM, run <code>:python import sys; print(sys.version)</code> from within VIM:</p>
<pre><code>2.7.6 (default, Sep  9 2014, 15:04:36)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.39)]
</code></pre><p>This should output your current version of Python. If you get an error, then you don’t have Python support and you either need to reinstall or recompile if you’re building from source.</p>
<p>With VIM installed, let’s look at how to customize VIM for Python development.</p>
<h1 id="VIM-Extensions"><a href="#VIM-Extensions" class="headerlink" title="VIM Extensions"></a>VIM Extensions</h1><p>VIM can do a lot of what developers need right out of the box. However, VIM is also massively extensible and there are some pretty killer extensions that make VIM behave more like a “modern” IDE. So, the very first thing you need is a good extension manager.</p>
<blockquote>
<p>Extensions in VIM are often referred to as bundles or <a href="http://vimdoc.sourceforge.net/htmldoc/usr_05.html#plugin" target="_blank" rel="external">plugins</a>.</p>
</blockquote>
<h2 id="Vundle"><a href="#Vundle" class="headerlink" title="Vundle"></a>Vundle</h2><p>VIM has several extension managers, but the one we strongly recommend is <a href="https://github.com/gmarik/Vundle.vim" target="_blank" rel="external">Vundle</a>. Think of it as pip for VIM. It makes installing and updating packages trivial.</p>
<p>Let’s get Vundle installed:</p>
<pre><code class="shell">$ git clone https://github.com/gmarik/Vundle.vim.git ~/.vim/bundle/Vundle.vim
</code></pre>
<p>This command downloads the Vundle plugin manager and chucks it in your VIM bundles directory. Now you can manage all your extensions from the <code>.vimrc</code> <a href="https://github.com/amix/vimrc" target="_blank" rel="external">configuration file</a>.</p>
<p>Add the file to your user’s home directory:</p>
<pre><code class="shell">$ touch ~/.vimrc
</code></pre>
<p>Now set up Vundle in your <code>.vimrc</code> by adding the following to the <em>top</em> of the file:</p>
<pre><code>set nocompatible              &quot; required
filetype off                  &quot; required

&quot; set the runtime path to include Vundle and initialize
set rtp+=~/.vim/bundle/Vundle.vim
call vundle#begin()

&quot; alternatively, pass a path where Vundle should install plugins
&quot;call vundle#begin(&#39;~/some/path/here&#39;)

&quot; let Vundle manage Vundle, required
Plugin &#39;gmarik/Vundle.vim&#39;

&quot; Add all your plugins here (note older versions of Vundle used Bundle instead of Plugin)


&quot; All of your Plugins must be added before the following line
call vundle#end()            &quot; required
filetype plugin indent on    &quot; required
</code></pre><p>That’s it. You’re now set up to use Vundle. Afterward you can add the plugins you want to install, then fire up VIM and run:</p>
<pre><code>:PluginInstall
</code></pre><p>This command tells Vundle to work its magic – downloading all the plugins and installing/updating them for you.</p>
<img src="/2016/11/16/2016-11/vim_and_python_a_match_made_in_heaven/installing_plugins.png" alt="Installing plugins" title="Installing plugins">
<blockquote>
<p>For Windows users, check out the <a href="https://github.com/gmarik/Vundle.vim/wiki/Vundle-for-Windows" target="_blank" rel="external">Windows Installation Instructions</a>.</p>
</blockquote>
<h1 id="Let’s-make-an-IDE"><a href="#Let’s-make-an-IDE" class="headerlink" title="Let’s make an IDE"></a>Let’s make an IDE</h1><p>We couldn’t possibly list all the VIM features, but let’s look at a quick list of some of the powerful out-of-the-box features perfect for Python development.</p>
<h2 id="Ditch-the-Mouse"><a href="#Ditch-the-Mouse" class="headerlink" title="Ditch the Mouse"></a>Ditch the Mouse</h2><p>Probably the <em>MOST</em> important feature of VIM is that it doesn’t require a mouse (except for the graphical variants of VIM). At first this may seem like a horrible idea, but after you invest the time – and it does take time – to learn the <a href="http://stackoverflow.com/a/5400978/1799408" target="_blank" rel="external">key combinations</a>, you will speed up your overall workflow!</p>
<h2 id="Split-Layouts"><a href="#Split-Layouts" class="headerlink" title="Split Layouts"></a>Split Layouts</h2><p>Open a file with <code>:sv &lt;filename&gt;</code> and you split the layout vertically (e.g., the new file opens below the current file) or reverse the keys to <code>:vs &lt;filename&gt;</code> and you get a horizontal split (e.g., the new file opens to the right of your current file).</p>
<img src="/2016/11/16/2016-11/vim_and_python_a_match_made_in_heaven/split_layouts.png" alt="Split layouts" title="Split layouts">
<p>You can nest splits as well, so you can have splits inside of splits, horizontal and vertical, to your heart’s content. As we all know we often need to look at several files at once when developing.</p>
<p><strong>Pro Tip:</strong> Make sure to utilize tab completion to find files after typing <code>:sv</code>.</p>
<p><strong>Pro Tip:</strong> You can also specify different areas of the screen where the splits should occur by adding the following lines to the <em>.vimrc</em> file:</p>
<pre><code>set splitbelow
set splitright
</code></pre><p><strong>Pro Tip:</strong> Want to move between the splits without using the mouse? Simply add the following to <em>.vimrc</em> and you can jump between splits with just one key combination:</p>
<pre><code>&quot;split navigations
nnoremap &lt;C-J&gt; &lt;C-W&gt;&lt;C-J&gt;
nnoremap &lt;C-K&gt; &lt;C-W&gt;&lt;C-K&gt;
nnoremap &lt;C-L&gt; &lt;C-W&gt;&lt;C-L&gt;
nnoremap &lt;C-H&gt; &lt;C-W&gt;&lt;C-H&gt;
</code></pre><p>Key combos:</p>
<ul>
<li>Ctrl-j move to the split below</li>
<li>Ctrl-k move to the split above</li>
<li>Ctrl-l move to the split to the right</li>
<li>Ctrl-h move to the split to the left</li>
</ul>
<p>In other words, press <code>Ctrl</code> plus the standard VIM movement key to move to a specific pane.</p>
<blockquote>
<p>But wait what is the <code>nnoremap</code> thing? – in a nutshell <code>nnoremap</code> remaps one key combination to another; the no part means remap the key in normal mode as opposed to visual mode. Basically <code>nnoremap &lt;C-J&gt; &lt;C-W&gt;&lt;C-j&gt;</code> says in normal mode when I hit <code>&lt;C-J&gt;</code> do <code>&lt;C-W&gt;&lt;C-j&gt;</code> instead. More info can be found <a href="http://stackoverflow.com/questions/3776117/what-is-the-difference-between-the-remap-noremap-nnoremap-and-vnoremap-mapping" target="_blank" rel="external">here</a>.</p>
</blockquote>
<h2 id="Buffers"><a href="#Buffers" class="headerlink" title="Buffers"></a>Buffers</h2><p>While VIM can do tabs, many prefer <a href="http://vim.wikia.com/wiki/Vim_buffer_FAQ" target="_blank" rel="external">buffers</a> and splits. You can think of a <a href="http://stackoverflow.com/questions/26708822/why-do-vim-experts-prefer-buffers-over-tabs" target="_blank" rel="external">buffer</a> as a recently opened file. VIM provides easy access to recent buffers, just type <code>:b &lt;buffer name or number&gt;</code> to switch to an open buffer (autocomplete works here as well). You can also use <code>:ls</code> to list all buffers.</p>
<p><strong>Pro Tip:</strong> At the end of the <code>:ls</code> output, VIM will prompt with <code>Hit enter to continue</code>. You can instead type <code>:b &lt;buffer number&gt;</code> and pick the buffer immediately while you still have the list displayed (which saves a keystroke and having to remember the buffer number).</p>
<h2 id="Code-Folding"><a href="#Code-Folding" class="headerlink" title="Code Folding"></a>Code Folding</h2><p>Most “modern” IDEs provide a way to collapse (or <a href="http://vim.wikia.com/wiki/Folding" target="_blank" rel="external">fold</a>) methods and classes, showing you just the class/method definition lines instead of all the code.</p>
<p>You can enable that in <em>.vimrc</em> with the following lines:</p>
<pre><code>&quot; Enable folding
set foldmethod=indent
set foldlevel=99
</code></pre><p>This works all right, but you have to type <code>za</code> to fold (and unfold). The space key would be much better. So add this line to your <em>.vimrc</em> file as well:</p>
<pre><code>&quot; Enable folding with the spacebar
nnoremap &lt;space&gt; za
</code></pre><p>Now you can easily hide portions of your code that you’re not currently working on.</p>
<p>The initial command, <code>set foldmethod=indent</code>, creates folds based upon line indents. This however often creates more folds that you really want. But have no fear! There are several extensions that attempt to rectify that. We recommend <a href="https://github.com/tmhedberg/SimpylFold" target="_blank" rel="external">SimpylFold</a>. Install it with Vundle by adding the following line to <code>.vimrc</code></p>
<pre><code>Plugin &#39;tmhedberg/SimpylFold&#39;
</code></pre><blockquote>
<p>Don’t forget to install the plugin – <code>:PluginInstall</code>.</p>
</blockquote>
<p><strong>Pro Tip:</strong> Want to see the docstrings for folded code?</p>
<pre><code>let g:SimpylFold_docstring_preview=1
</code></pre><h2 id="Python-Indentation"><a href="#Python-Indentation" class="headerlink" title="Python Indentation"></a>Python Indentation</h2><p>Of course for code folding to work based on indentations, you want your indents to be correct. Again VIM falls short a bit out of the box because it doesn’t handle auto-indent after a function definition. Two things can be done with indentation:</p>
<ol>
<li>The first is to get indentation to follow PEP8 standards.</li>
<li>The second part is to better handle auto-indentation.</li>
</ol>
<h3 id="PEP8"><a href="#PEP8" class="headerlink" title="PEP8"></a>PEP8</h3><p>To add the proper PEP8 indentation, add the following to your <em>.vimrc</em>:</p>
<pre><code>au BufNewFile,BufRead *.py
    \ set tabstop=4
    \ set softtabstop=4
    \ set shiftwidth=4
    \ set textwidth=79
    \ set expandtab
    \ set autoindent
    \ set fileformat=unix
</code></pre><p>This will give you the standard four spaces when you hit tab, ensure your line length doesn’t go beyond 80 characters, and store the file in a unix format so you don’t get a bunch of conversion issues when checking into GitHub and/or sharing with other users.</p>
<p>And for <em>full stack development</em> you can use another <code>au</code> command for each filetype:</p>
<pre><code>au BufNewFile,BufRead *.js, *.html, *.css
    \ set tabstop=2
    \ set softtabstop=2
    \ set shiftwidth=2
</code></pre><p>This way you can have different settings for different filetypes. There is also a plugin called <a href="http://vim.wikia.com/wiki/Keep_your_vimrc_file_clean" target="_blank" rel="external">ftypes</a> which will allow you to have a separate file for each filetype you want to maintain settings for, so use that if you see fit.</p>
<h3 id="Auto-Indentation"><a href="#Auto-Indentation" class="headerlink" title="Auto-Indentation"></a>Auto-Indentation</h3><p>Autoindent will help but in some cases (like when a function signature spans multiple lines), it doesn’t always do what you want, especially when it comes to conforming to PEP8 standards. To fix that, we can use the <a href="https://github.com/vim-scripts/indentpython.vim" target="_blank" rel="external">indentpython.vim</a> extension:</p>
<pre><code>Plugin &#39;vim-scripts/indentpython.vim&#39;
</code></pre><h2 id="Flagging-Unnecessary-Whitespace"><a href="#Flagging-Unnecessary-Whitespace" class="headerlink" title="Flagging Unnecessary Whitespace"></a>Flagging Unnecessary Whitespace</h2><p>We also want to avoid extraneous whitespace. We can have VIM flag that for us so that it’s easy to spot – and then remove.</p>
<pre><code>au BufRead,BufNewFile *.py,*.pyw,*.c,*.h match BadWhitespace /\s\+$/
</code></pre><p>This will mark extra whitespace as bad, and probably color it red.</p>
<h2 id="UTF8-Support"><a href="#UTF8-Support" class="headerlink" title="UTF8 Support"></a>UTF8 Support</h2><p>For the most part, you should be using UTF8 when working with Python, especially if you’re working with Python 3. Make sure VIM knows that with the following line:</p>
<pre><code>set encoding=utf-8
</code></pre><h2 id="Auto-complete"><a href="#Auto-complete" class="headerlink" title="Auto-complete"></a>Auto-complete</h2><p>The best plugin for Python auto-complete is <a href="https://github.com/Valloric/YouCompleteMe" target="_blank" rel="external">YouCompleteMe</a>. Again, use Vundle to install:</p>
<pre><code>Bundle &#39;Valloric/YouCompleteMe&#39;
</code></pre><p>Under the hood YouCompleteMe uses a few different auto-completers (including <a href="https://github.com/davidhalter/jedi" target="_blank" rel="external">Jedi</a> for Python), and it needs some C libraries to be installed for it to work correctly. The docs have very good <a href="https://github.com/Valloric/YouCompleteMe#mac-os-x-super-quick-installation" target="_blank" rel="external">installation instructions</a> so I won’t repeat them here, but be sure you follow them.</p>
<p>It works out of the box pretty well, but let’s add a few customizations:</p>
<pre><code>let g:ycm_autoclose_preview_window_after_completion=1
map &lt;leader&gt;g  :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt;
</code></pre><p>The former line ensures that the autocomplete window goes away when you’re done with it, and the latter defines a shortcut for goto definition.</p>
<blockquote>
<p>My leader key is mapped to space, so <code>space-g</code> will goto definition of whatever I’m currently on. Helpful when exploring new code.</p>
</blockquote>
<h2 id="Virtualenv-Support"><a href="#Virtualenv-Support" class="headerlink" title="Virtualenv Support"></a>Virtualenv Support</h2><p>One issue with the goto definition above is that VIM by default doesn’t know anything about virtualenv, so you have to make VIM and YouCompleteMe aware of your virtualenv by adding the following lines of code to <em>.vimrc</em>:</p>
<pre><code>&quot;python with virtualenv support
py &lt;&lt; EOF
import os
import sys
if &#39;VIRTUAL_ENV&#39; in os.environ:
  project_base_dir = os.environ[&#39;VIRTUAL_ENV&#39;]
  activate_this = os.path.join(project_base_dir, &#39;bin/activate_this.py&#39;)
  execfile(activate_this, dict(__file__=activate_this))
EOF
</code></pre><p>This determines if you are running inside a virtualenv, and then switches to that specific virtualenv and sets up your system path so that YouCompleteMe will find the appropriate site packages.</p>
<h2 id="Syntax-Checking-Highlighting"><a href="#Syntax-Checking-Highlighting" class="headerlink" title="Syntax Checking/Highlighting"></a>Syntax Checking/Highlighting</h2><p>You can have VIM check your syntax on each save with the <a href="https://github.com/scrooloose/syntastic" target="_blank" rel="external">syntastic</a> extension:</p>
<pre><code>Plugin &#39;scrooloose/syntastic&#39;
</code></pre><p>Also add PEP8 checking with this nifty little plugin:</p>
<pre><code>Plugin &#39;nvie/vim-flake8&#39;
</code></pre><p>Finally, make your code look pretty:</p>
<pre><code>let python_highlight_all=1
syntax on
</code></pre><h2 id="Color-Schemes"><a href="#Color-Schemes" class="headerlink" title="Color Schemes"></a>Color Schemes</h2><p>Color schemes work in conjunction with the basic color scheme that you are using. Check out <a href="https://github.com/altercation/vim-colors-solarized" target="_blank" rel="external">solarized</a> for GUI mode, and <a href="https://github.com/jnurmine/Zenburn" target="_blank" rel="external">Zenburn</a> for terminal mode:</p>
<pre><code>Plugin &#39;jnurmine/Zenburn&#39;
Plugin &#39;altercation/vim-colors-solarized&#39;
</code></pre><p>Then just add a bit of logic to define which scheme to use based upon the VIM mode:</p>
<pre><code>if has(&#39;gui_running&#39;)
  set background=dark
  colorscheme solarized
else
  colorscheme zenburn
endif
</code></pre><p>Solarized also ships with a dark and light theme. To make switching between them very easy (by pressing F5) add:</p>
<pre><code>call togglebg#map(&quot;&lt;F5&gt;&quot;)
</code></pre><h2 id="File-Browsing"><a href="#File-Browsing" class="headerlink" title="File Browsing"></a>File Browsing</h2><p>If you want a proper file tree then <a href="https://github.com/scrooloose/nerdtree" target="_blank" rel="external">NERDTree</a> is the way to go.</p>
<pre><code>Plugin &#39;scrooloose/nerdtree&#39;
</code></pre><p>And if you want to use tabs, utilize <a href="https://github.com/jistr/vim-nerdtree-tabs" target="_blank" rel="external">vim-nerdtree-tabs</a>:</p>
<pre><code>Plugin &#39;jistr/vim-nerdtree-tabs&#39;
</code></pre><p>Want to hide <code>.pyc</code> files? Then add the following line:</p>
<pre><code>let NERDTreeIgnore=[&#39;\.pyc$&#39;, &#39;\~$&#39;] &quot;ignore files in NERDTree
</code></pre><h2 id="Super-Searching"><a href="#Super-Searching" class="headerlink" title="Super Searching"></a>Super Searching</h2><p>Want to search for basically anything from VIM? Check out <a href="https://github.com/kien/ctrlp.vim" target="_blank" rel="external">ctrlP</a>:</p>
<pre><code>Plugin &#39;kien/ctrlp.vim&#39;
</code></pre><p>As expected, press <code>Ctrl-P</code> to enable the search and then just start typing. If your search matches anything close to the file you’re looking for, it will find it. Oh – and it’s not just files; it will find tags as well! For more, check out this <a href="http://www.youtube.com/watch?v=9XrHk3xjYsw" target="_blank" rel="external">YouTube video</a>.</p>
<h2 id="Line-Numbering"><a href="#Line-Numbering" class="headerlink" title="Line Numbering"></a>Line Numbering</h2><p>Turn on line numbers on the side of the screen with:</p>
<pre><code>set nu
</code></pre><h2 id="Git-Integration"><a href="#Git-Integration" class="headerlink" title="Git Integration"></a>Git Integration</h2><p>Want to perform basic git commands without leaving the comfort of VIM? Then <a href="https://github.com/tpope/vim-fugitive" target="_blank" rel="external">vim-fugitive</a> is the way to go:</p>
<pre><code>Plugin &#39;tpope/vim-fugitive&#39;
</code></pre><p>See it in action on VIMcasts.</p>
<h2 id="Powerline"><a href="#Powerline" class="headerlink" title="Powerline"></a>Powerline</h2><p><a href="https://github.com/powerline/powerline" target="_blank" rel="external">Powerline</a> is a status bar that displays things like the current virtualenv, git branch, files being edited, and much more.</p>
<p>It’s written in Python, and it supports a number of other environments like zsh, bash, tmux, and IPython.</p>
<pre><code>Plugin &#39;Lokaltog/powerline&#39;, {&#39;rtp&#39;: &#39;powerline/bindings/vim/&#39;}
</code></pre><p>Take a look at the <a href="http://powerline.readthedocs.org/en/latest/" target="_blank" rel="external">official docs</a> for all the configuration options.</p>
<h2 id="System-clipboard"><a href="#System-clipboard" class="headerlink" title="System clipboard"></a>System clipboard</h2><p>Vim usually has its own clipboard and ignores the system keyboards, but sometimes you might want to cut, copy, and/or paste to/from other applications outside of VIM. On OSX, you can access your system clipboard with this line:</p>
<pre><code>set clipboard=unnamed
</code></pre><h2 id="VIM-in-the-Shell"><a href="#VIM-in-the-Shell" class="headerlink" title="VIM in the Shell"></a>VIM in the Shell</h2><p>And finally, once you’ve mastered VIM and its keyboard shortcuts, you’ll often find yourself getting annoyed with the lack of those same shortcuts in the shell. Fear not, most shells have a VI mode. To turn it on for your shell, add the following line to <code>~/.inputrc</code>:</p>
<pre><code>set editing-mode vi
</code></pre><p>Now you will not only be able to use VIM key combos in the shell, but also in the Python interpreter and any other tool that uses GNU Readline (i.e., most database shells). Now you have VIM everywhere!</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>That’s more or less it (for Python development, at least). There are a ton of other extensions that you can use, as well as alternatives to everything detailed in this post. What are some of your favorite extensions? How have you configured VIM to match your personality?</p>
<p>Here is a link to my current <a href="https://github.com/j1z0/vim-config/blob/master/vimrc" target="_blank" rel="external">VIM config</a>. Got one of your own? Please share!</p>
<p>Thanks for reading!</p>
<h1 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h1><ol>
<li><a href="http://linuxcommand.org/man_pages/vimtutor1.html" target="_blank" rel="external">VIM Tutor</a> comes with VIM, so once VIM is install just type <code>vimtutor</code> from the command line and the program will teach you how to use VIM by, well, using VIM.</li>
<li><a href="http://vimcasts.org/" target="_blank" rel="external">VIMcasts</a> are advanced tutorial videos describing how to use many of VIM’s features.</li>
<li><a href="http://vimdoc.sourceforge.net/" target="_blank" rel="external">Official VIM docs</a></li>
<li><a href="http://www.openvim.com/" target="_blank" rel="external">Open Vim</a></li>
<li><a href="http://learnvimscriptthehardway.stevelosh.com/" target="_blank" rel="external">Learn Vimscript the Hard Way</a> is perfect for learning vimscript.</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://realpython.com/blog/python/vim-and-python-a-match-made-in-heaven/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;

    
    </summary>
    
      <category term="Vim" scheme="https://athrunsun.github.io/categories/Vim/"/>
    
    
      <category term="Vim" scheme="https://athrunsun.github.io/tags/Vim/"/>
    
      <category term="Python" scheme="https://athrunsun.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Update personal blog hosted on github pages automatically with Travis CI</title>
    <link href="https://athrunsun.github.io/2016/10/09/2016-10/update_github_pages_with_travis_ci/"/>
    <id>https://athrunsun.github.io/2016/10/09/2016-10/update_github_pages_with_travis_ci/</id>
    <published>2016-10-09T01:12:00.000Z</published>
    <updated>2019-03-18T08:00:19.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Solution-1"><a href="#Solution-1" class="headerlink" title="Solution #1"></a>Solution #1</h1><p>Reference: <a href="http://notes.iissnan.com/2016/publishing-github-pages-with-travis-ci/" target="_blank" rel="external">使用 Travis CI 自动更新 GitHub Pages</a></p>
<p>A sample configuration for my personal blog hosted on github pages would be,</p>
<pre><code class="yaml">language: node_js

node_js:
  - &quot;6&quot;

env:
  global:
    - GH_REF: github.com/athrunsun/blog.git
    - secure: &quot;xxxxxx&quot;

branches:
  only:
  - master

# S: Build Lifecycle
install:
  - npm install

before_script:
  - git config --global user.name &quot;xxx&quot;
  - git config --global user.email &quot;xxx@xxx.com&quot;

script:
  - hexo clean
  - hexo generate

after_script:
  - cd public
  - git init
  - git add .
  - git commit -m &quot;Update blog $(date +%Y-%m-%d,%H:%M:%S)&quot;
  - git push -f -q &quot;https://${GH_TOKEN}@${GH_REF}&quot; master:gh-pages
# E: Build LifeCycle
</code></pre>
<p>But this requires us to install <a href="https://github.com/travis-ci/travis.rb#command-line-client" target="_blank" rel="external">travis command line client</a>, encrypt our github API token and put the result in <code>env[&quot;global&quot;][&quot;secure&quot;]</code>.</p>
<p>NOTE that we’re using a <strong>quite</strong> push with <code>-q</code> option so that we won’t leak our github API token. Also you can remove log permanently from Travis CI’s UI once you see unintentional token leakages.</p>
<h1 id="Solution-2"><a href="#Solution-2" class="headerlink" title="Solution #2"></a>Solution #2</h1><p>Reference: <a href="http://stackoverflow.com/questions/23277391/how-to-publish-to-github-pages-from-travis-ci" target="_blank" rel="external">How to publish to Github Pages from Travis CI?</a></p>
<p>A simpler solution (global environment variable <code>GITHUB_API_TOKEN</code> must be set beforehand in Travis CI’s UI),</p>
<pre><code class="yaml">language: node_js

node_js:
  - &quot;6&quot;

branches:
  only:
  - master

install:
  - npm install

script:
  - hexo clean
  - hexo generate

after_success:
  - cd public
  - git init
  - git add .
  - git -c user.name=&#39;travis&#39; -c user.email=&#39;travis&#39; commit -m &quot;Update blog $(date +%Y-%m-%d,%H:%M:%S)&quot;
  - git push -f -q &quot;https://athrunsun:${GITHUB_API_TOKEN}@github.com/athrunsun/blog.git&quot; master:gh-pages &amp;&gt; /dev/null
</code></pre>
<p>Here <code>&amp;&gt; /dev/null</code> means to <a href="http://askubuntu.com/questions/350208/what-does-2-dev-null-mean" target="_blank" rel="external">discard both standard output and error</a>.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Solution-1&quot;&gt;&lt;a href=&quot;#Solution-1&quot; class=&quot;headerlink&quot; title=&quot;Solution #1&quot;&gt;&lt;/a&gt;Solution #1&lt;/h1&gt;&lt;p&gt;Reference: &lt;a href=&quot;http://notes.iis
    
    </summary>
    
      <category term="CI" scheme="https://athrunsun.github.io/categories/CI/"/>
    
    
      <category term="GitHub" scheme="https://athrunsun.github.io/tags/GitHub/"/>
    
      <category term="CI" scheme="https://athrunsun.github.io/tags/CI/"/>
    
      <category term="Travis" scheme="https://athrunsun.github.io/tags/Travis/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) What is the difference between a SOCKS proxy and an HTTP proxy?</title>
    <link href="https://athrunsun.github.io/2016/10/05/2016-10/what_is_the_difference_between_a_socks_proxy_and_an_http_proxy/"/>
    <id>https://athrunsun.github.io/2016/10/05/2016-10/what_is_the_difference_between_a_socks_proxy_and_an_http_proxy/</id>
    <published>2016-10-05T14:43:00.000Z</published>
    <updated>2019-03-18T08:00:19.498Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.jguru.com/faq/view.jsp?EID=227532" target="_blank" rel="external">Original Post</a></p>
<p>A SOCKS server is a <strong>general purpose</strong> proxy server that establishes a TCP connection to another server on behalf of a client, then routes all the traffic back and forth between the client and the server. It works for any kind of network protocol on any port. SOCKS Version 5 adds additional support for security and UDP.</p>
<p>The SOCKS server does not interpret the network traffic between client and server in any way, and is often used because clients are behind a firewall and are not permitted to establish TCP connections to servers outside the firewall unless they do it through the SOCKS server.</p>
<p>Most web browsers for example can be configured to talk to a web server via a SOCKS server. Because the client must first make a connection to the SOCKS server and tell it the host it wants to connect to, the client must be “SOCKS enabled.”</p>
<p>On Windows, it is possible to “shim” the TCP stack so that all client software is SOCKS enabled. A free SOCKS shim is available from Hummingbird at <a href="http://www.hummingbird.com/products/nc/socks/index.html" target="_blank" rel="external">http://www.hummingbird.com/products/nc/socks/index.html</a>.</p>
<p>An HTTP proxy is similar, and may be used for the same purpose when clients are behind a firewall and are prevented from making outgoing TCP connections to servers outside the firewall.</p>
<p>However, unlike the SOCKS server, an HTTP proxy does understand and interpret the network traffic that passes between the client and downstream server, namely the HTTP protocol.</p>
<p>Because of this the HTTP proxy can <strong>ONLY</strong> be used to handle HTTP traffic, but it can be very smart about how it does it. In particular, it can recognize often repeated requests and cache the replies to improve performance.</p>
<p>Many ISPs use HTTP proxies regardless of how the browser is configured because they simply route all traffic on port 80 through the proxy server.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.jguru.com/faq/view.jsp?EID=227532&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A SOCKS server is a &lt;stron
    
    </summary>
    
      <category term="Proxy" scheme="https://athrunsun.github.io/categories/Proxy/"/>
    
    
      <category term="Proxy" scheme="https://athrunsun.github.io/tags/Proxy/"/>
    
      <category term="SOCKS" scheme="https://athrunsun.github.io/tags/SOCKS/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) DNS (UDP) tunneling by SSH with socat</title>
    <link href="https://athrunsun.github.io/2016/10/05/2016-10/dns_tunneling_by_ssh_with_socat/"/>
    <id>https://athrunsun.github.io/2016/10/05/2016-10/dns_tunneling_by_ssh_with_socat/</id>
    <published>2016-10-05T14:34:00.000Z</published>
    <updated>2019-03-18T08:00:19.498Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://gihnius.net/2014/08/60-ssh-dns-tunnel-by-socat/" target="_blank" rel="external">Original Post</a></p>
<h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>In China, many “ISP” sucks. Their DNS servers often return incorrect ip address results,  is known as DNS poisoning! DNS poisoning is a common and simple way to stop people reaching correct web pages.</p>
<p>Here is a solution to get the correct DNS queries results.</p>
<h1 id="Dependent-tools"><a href="#Dependent-tools" class="headerlink" title="Dependent tools"></a>Dependent tools</h1><ul>
<li>Server<ul>
<li>A VPS server that can access famous public DNS servers correctly, eg. <code>8.8.8.8</code> (google dns) or <code>208.67.222.222</code> (opendns).</li>
<li>SSH server running on that VPS. (Please google: how to setup ssh server)</li>
<li>socat (Socket Cat). (Please google: how to setup or install socat)</li>
<li>dnsmasq (Optional, for caching).</li>
</ul>
</li>
<li>Local<ul>
<li>SSH client</li>
<li>socat (Socket Cat)</li>
<li>dnsmasq (Optional, for caching).</li>
</ul>
</li>
</ul>
<p>ssh, socat, dnsmasq are open source softwares which can be found and installed easily.</p>
<h1 id="Samples-and-Steps"><a href="#Samples-and-Steps" class="headerlink" title="Samples and Steps"></a>Samples and Steps</h1><ul>
<li>Server<ul>
<li>Setup a DNS caching server using dnsmasq. (Optional)<ul>
<li>install dnsmasq</li>
<li>configure example using google dns and opendns servers. please check out: Setup a DNS cache server using dnsmasq</li>
<li>start dnsmasq</li>
</ul>
</li>
<li>If no local dns server, just use a public dns server instead, eg. <code>8.8.8.8:53</code></li>
<li>Forwarding <strong>UDP</strong> to <strong>TCP</strong> by socat (listen on port: <code>15353</code>)<ul>
<li>install socat</li>
<li>start socat:<ul>
<li>if use a public dns server, eg. <code>8.8.8.8:53</code><br><code>socat tcp4-listen:15353,reuseaddr,fork,bind=127.0.0.1 UDP:8.8.8.8:53</code></li>
<li>if use local dns caching server: <code>127.0.0.1:5353</code><br><code>socat tcp4-listen:15353,reuseaddr,fork,bind=127.0.0.1 UDP:127.0.0.1:53</code></li>
</ul>
</li>
</ul>
</li>
<li>You can check the forwarding dns server using command line:<br><code>dig +tcp google.com @127.0.0.1 -p 15353</code></li>
</ul>
</li>
<li>Local<ul>
<li>Setup SSH tunnel<br><code>ssh -N -L 15353:localhost:15353 username@vps.ip</code></li>
<li>Forwarding TCP to UDP by socat<ul>
<li>if no local dns caching server, you can forward to port <code>53</code><br><code>socat udp-recvfrom:53,reuseaddr,bind=127.0.0.1,fork tcp:127.0.0.1:15353</code></li>
<li>of cause can forward to any port that can be used.<br><code>socat udp-recvfrom:15353,reuseaddr,bind=127.0.0.1,fork tcp:127.0.0.1:15353</code></li>
</ul>
</li>
<li>Setup local dns caching server (Optional but recommend). See the server instruction above.</li>
</ul>
</li>
</ul>
<p>OK!</p>
<p>Oh not yet!</p>
<p>ssh (tunnel) is not always working well! WTF!</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://gihnius.net/2014/08/60-ssh-dns-tunnel-by-socat/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;Intro&quot;&gt;&lt;a h
    
    </summary>
    
      <category term="DNS" scheme="https://athrunsun.github.io/categories/DNS/"/>
    
    
      <category term="DNS" scheme="https://athrunsun.github.io/tags/DNS/"/>
    
      <category term="SSH" scheme="https://athrunsun.github.io/tags/SSH/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) 什么是DNS,A记录,子域名,CNAME别名,MX记录,TXT记录,SRV 记录,TTL值,泛域名(泛解析),域名转向,域名绑定</title>
    <link href="https://athrunsun.github.io/2016/10/05/2016-10/what_is_dns_a_record_txt_record_etc/"/>
    <id>https://athrunsun.github.io/2016/10/05/2016-10/what_is_dns_a_record_txt_record_etc/</id>
    <published>2016-10-05T13:37:00.000Z</published>
    <updated>2019-03-18T08:00:19.498Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://it815.blog.51cto.com/526819/136414" target="_blank" rel="external">Original Post</a></p>
<h1 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h1><p>DNS，Domain Name System或者Domain Name Service（域名系统或者域名服务）。域名系统为Internet上的主机分配域名地址和IP地址。由于网络中的计算机都必须有个IP地址，来识别,互相之间才能通信,但让我们记住一大串的IP地址来访问网站显然是不可能的,所以用户使用域名地址，而DNS系统的功能就是自动把域名地址翻译为IP地址。域名服务是运行域名系统的Internet工具。执行域名服务的服务器称之为DNS服务器，通过DNS服务器来应答域名服务的查询。</p>
<ol>
<li>DNS就是域名服务器，他的任务就是确定域名的解析，比如A记录MX记录等等。 </li>
<li>任何域名都至少有一个DNS，一般是2个。但为什么要2个以上呢？因为DNS可以轮回处理，这样第一个解析失败可以找第二个。这样只要有一个DNS解析正常，就不会影响域名的正常使用。 </li>
<li>如何确定域名的DNS。很简单到<a href="http://www.internic.net/whois.html" target="_blank" rel="external">http://www.internic.net/whois.html</a>输入你要查询的域名就可以看到了。这个是国际域名管理中心。唯一的权威。只要这里能查到某个域名，就表示域名是生效的。它说你什么时候到期，就是什么时候到期。 </li>
<li>有效的DNS表示当前正在起作用的DNS服务器是谁，比如查询结果是<code>NS.XINNETDNS.COM</code>、<code>NS.XINNET.CN</code>(新网信海)就表示当前域名是由<code>NS.XINNETDNS.COM</code>、<code>NS.XINNET.CN</code>(新网信海)负责解析。其他未显示的DNS的设置，都是无效的。 </li>
<li>DNS是可以修改的。修改以后需要24-72小时以后，全世界范围的所有DNS服务器才能刷新过来。internic的信息一般在24小时以后可以看到。另外，修改的过程，并不表示域名会停止解析，只要你在2边都做好了解析。如果生效了就是新的DNS在起作用。如果没生效。就是旧的DNS在起作用。要么生效，要么不生效。不存在2个都不起作用的时间。所以域名解析，不会中断。前提是两边都做了解析。 </li>
</ol>
<h1 id="A记录"><a href="#A记录" class="headerlink" title="A记录"></a>A记录</h1><p>A = Address，记录是用来指定主机名（或域名）对应的IP地址记录。用户可以将该域名下的网站服务器指向到自己的web server上。同时也可以设置您域名的子域名。<strong>通俗来说A记录就是服务器的IP</strong>,域名绑定A记录就是告诉DNS,当你输入域名的时候给你引导向设置在DNS的A记录所对应的服务器 </p>
<h1 id="子域名"><a href="#子域名" class="headerlink" title="子域名"></a>子域名</h1><p>子域名道理等同二级域名，不过比二级域名更加延伸，比如我们继续扩展该域名的主机名，设置主机名为<code>bbs.at</code>,那么就可以建立一个三级域名：<code>bbs.at.abc.com</code>，当然也可以建立四级域名<code>bbs.at.go.abc.com</code>，五级域名<code>bbs.at.go.home.abc.com</code>……，依次类推，可以建立无限级别的域名，我们统称这些域名为顶级域名<code>abc.com</code>的子域名。</p>
<h1 id="CNAME别名指向记录"><a href="#CNAME别名指向记录" class="headerlink" title="CNAME别名指向记录"></a>CNAME别名指向记录</h1><p>CNAME = Canonical Name，通常称别名指向。在这里，您可以定义一个主机别名，比如设置<code>ftp.***.com</code>，用来指向一个主机<code>www.***.com</code>,那么以后就可以用<code>FTP.***.com</code>来代替访问<code>www.***.com</code>了。</p>
<h1 id="MX记录"><a href="#MX记录" class="headerlink" title="MX记录"></a>MX记录</h1><p>MX记录也叫做邮件路由记录，用户可以将该域名下的邮件服务器指向到自己的mail server上，然后即可自行操控所有的邮箱设置。您只需在线填写您服务器的IP地址，即可将您域名下的邮件全部转到您自己设定相应的邮件服务器上。简单的说，通过操作MX记录，您才可以得到以您域名结尾的邮局。</p>
<h1 id="TXT记录"><a href="#TXT记录" class="headerlink" title="TXT记录"></a>TXT记录</h1><p>TXT记录，一般指为某个主机名或域名设置的说明，如：</p>
<pre><code>admin IN TXT &quot;管理员, 电话： 13901234567&quot;
mail IN TXT &quot;邮件主机, 存放在xxx , 管理人：AAA&quot;
Jim IN TXT &quot;contact: abc@mailserver.com&quot;
</code></pre><p>也就是您可以设置TXT，以便使别人联系到您。</p>
<h1 id="SRV记录"><a href="#SRV记录" class="headerlink" title="SRV记录"></a>SRV记录</h1><p>SRV记录：一般是为Microsoft的活动目录设置时的应用。DNS可以独立于活动目录，但是活动目录必须有DNS的帮助才能工作。为了活动目录能够正常的工作，DNS服务器必须支持服务定位（SRV）资源记录，资源记录把服务名字映射为提供服务的服务器名字。活动目录客户和域控制器使用SRV资源记录决定域控制器的IP地址。（此技术细节请参考相应网站）</p>
<h1 id="TTL值"><a href="#TTL值" class="headerlink" title="TTL值"></a>TTL值</h1><p>TTL值全称是“生存时间”(Time To Live)，简单的说它表示DNS记录在DNS服务器上缓存时间。要理解TTL值，请先看下面的一个例子：</p>
<p>假设，有这样一个域名<code>myhost.abc.com</code>（其实，这就是一条DNS记录，通常表示在<code>abc.com</code>域中有一台名为myhost的主机）对应IP地址为<code>1.1.1.1</code>，它的TTL为10分钟。这个域名或称这条记录存储在一台名为<code>dns.abc.com</code>的DNS服务器上。</p>
<p>现在有一个用户在浏览器中键入一下地址（又称URL）：<code>http://myhost.abc.com/</code>这时会发生什么呢？ </p>
<p>该访问者指定的DNS服务器（或是他的ISP,互联网服务商, 动态分配给他的）<code>8.8.8.8</code>就会试图为他解释<code>myhost.abc.com</code>，当然<code>8.8.8.8</code>这台DNS服务器由于没有包含<code>myhost.abc.com</code>这条信息，因此无法立即解析，但是通过全球DNS的递归查询后，最终定位到<code>dns.abc.com</code>这台DNS服务器，<code>dns.abc.com</code>这台DNS服务器将<code>myhost.abc.com</code>对应的IP地址<code>1.1.1.1</code>告诉<code>8.8.8.8</code>这台DNS服务器，然有再由<code>8.8.8.8</code>告诉用户结果。<code>8.8.8.8</code>为了以后加快对<code>myhost.abc.com</code>这条记录的解析，就将刚才的<code>1.1.1.1</code>结果保留一段时间，这就是TTL时间，在这段时间内如果用户又有对<code>myhost.abc.com</code>这条记录的解析请求，它就直接告诉用户<code>1.1.1.1</code>，当TTL到期则又会重复上面的过程</p>
<h1 id="泛域名与泛解析"><a href="#泛域名与泛解析" class="headerlink" title="泛域名与泛解析"></a>泛域名与泛解析</h1><p>泛域名是指在一个域名根下，以<code>*.Domain.com</code>的形式表示这个域名根所有未建立的子域名。 </p>
<p>泛解析是把<code>*.Domain.com</code>的A 记录解析到某个IP地址上,然后别人通过任意的前缀<code>.domain.com</code>访问都能访问到你解析的站点上。例： </p>
<p>域名根<code>name.com</code>只建立了<code>www.name.com</code>和<code>name.com</code>这两个域名记录，那么<code>ftp.name.com</code>、<code>mail.name.com</code>、<code>bbs.name.com</code>等域名记录是不存在的，但为域名根<code>name.com</code>建立泛域名记录 <code>*.name.com</code>后，<code>*.name.com</code>就涵盖了<code>ftp.name.com</code>、<code>mail.name.com</code>、<code>bbs.name.com</code> 等所有不存在的子域名记录。</p>
<p>您可以定义<code>*.name.com</code>指向一个IP，那么当访问者无论是输入<code>ftp.name.com</code>、<code>mail.name.com</code>或 <code>bbs.name.com</code>的时候，访问者都将直接访问您定义<code>*.name.com</code>的那个IP。</p>
<h1 id="域名绑定"><a href="#域名绑定" class="headerlink" title="域名绑定"></a>域名绑定</h1><p>什么是域名绑定：域名绑定是指，域名绑定是指域名和主机(即某个服务器)的空间进行关联绑定,其实就是在虚拟服务器上设置或者WEB服务器上设置，使一个域名被引导向服务器上的某一特定空间（某一个特定站点），访问者访问你的域名的时候就会打开你存放在该空间上的网页，简单来说其实就是把域名解析到服务器IP,然后在服务器上设置该域名有权限访问的过程。一般虚拟主机有控制面板给进行绑定域名，如果没有面板就需要自己在服务器上的IIS里面设置</p>
<h1 id="域名转向"><a href="#域名转向" class="headerlink" title="域名转向"></a>域名转向</h1><p>域名转向我们又称为域名(URL)指向或域名转发，当用户地址栏中输入您的域名时，将会自动跳转到您所指定的另一个网络地址（URL）。 </p>
<p>假设<code>abc.com</code>是您注册的域名，则通过URL转发服务可以实现当用户访问<code>http://www.abc.com/</code>时，自动转向访问另外一个URL，如:我的空间不支持绑定到目录功能,所以为了方便访问者,我就设置:<code>http://bbs.bnxb.com</code>来访问,这个是设置了通过URL转发服务转发到<code>http://www.bnxb.com/bbs</code>上面来实现的，这样您就可以轻松实现多个域名指向一个网站或网站子目录；另外，通过URL转发服务，可以方便的实现将您的中文域名，设置自动转发到您的英文域名主站点。域名转发的另外一个好处就是可以把长域名压缩,用短域名的转向代替,让你的访客不需输入那么长的域名。</p>
<h1 id="IIS连接数"><a href="#IIS连接数" class="headerlink" title="IIS连接数"></a>IIS连接数</h1><p>IIS连接数指并发连接数，什么意思呢？</p>
<p>要分几种情况：（以100M空间50人在线为例）</p>
<ol>
<li>用户单点下载你的文件，结束后正常断开，这些连接是按照瞬间计算的，就是说你50人的网站瞬间可以接受同时50个点下载。</li>
<li>用户打开你的页面，就算停留在该页面，这时候网页已经加载完了没有对服务器再发出任何请求，那么在用户完全打开这个页面的时间内算一个在线，在页面完全打开后IIS连接数就释放。</li>
<li>上面B的情况用户继续打开同一个网站的其他页面，那么在线人数按照用户最后一次点击（发出请求）计算，在这个时间内不管用户怎么点击（包括新窗口打开）都还是一人在线。</li>
<li>当你的页面内存在框架(Iframe)，那么每多一个框架就要多一倍的在线！因为这相当于用户同一时间向服务器请求了多个页面。</li>
<li>当用户打开页面然后正常关闭浏览器，用户的在线人数也会马上清除。</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://it815.blog.51cto.com/526819/136414&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;DNS&quot;&gt;&lt;a href=&quot;#DNS&quot; clas
    
    </summary>
    
      <category term="DNS" scheme="https://athrunsun.github.io/categories/DNS/"/>
    
    
      <category term="DNS" scheme="https://athrunsun.github.io/tags/DNS/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) Advanced Git log</title>
    <link href="https://athrunsun.github.io/2016/10/03/2016-10/advanced_git_log/"/>
    <id>https://athrunsun.github.io/2016/10/03/2016-10/advanced_git_log/</id>
    <published>2016-10-03T15:45:00.000Z</published>
    <updated>2019-03-18T08:00:19.498Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.atlassian.com/git/tutorials/git-log/" target="_blank" rel="external">Original Post</a></p>
<p>The purpose of any version control system is to record changes to your code. This gives you the power to go back into your project history to see who contributed what, figure out where bugs were introduced, and revert problematic changes. But, having all of this history available is useless if you don’t know how to navigate it. That’s where the git log command comes in.</p>
<p>By now, you should already know the basic git log command for displaying commits. But, you can alter this output by passing many different parameters to git log.</p>
<p>The advanced features of git log can be split into two categories: formatting how each commit is displayed, and filtering which commits are included in the output. Together, these two skills give you the power to go back into your project and find any information that you could possibly need.</p>
<h1 id="Formatting-Log-Output"><a href="#Formatting-Log-Output" class="headerlink" title="Formatting Log Output"></a>Formatting Log Output</h1><p>First, this article will take a look at the many ways in which <code>git log</code>’s output can be formatted. Most of these come in the form of flags that let you request more or less information from <code>git log</code>.</p>
<p>If you don’t like the default <code>git log</code> format, you can use <code>git config</code>’s aliasing functionality to create a shortcut for any of the formatting options discussed below. Please see in <a href="https://www.atlassian.com/git/tutorials/setting-up-a-repository/config" target="_blank" rel="external">The git config Command</a> for how to set up an alias.</p>
<h2 id="Oneline"><a href="#Oneline" class="headerlink" title="Oneline"></a>Oneline</h2><p>The <code>--oneline</code> flag condenses each commit to a single line. By default, it displays only the commit ID and the first line of the commit message. Your typical <code>git log --oneline</code> output will look something like this:</p>
<pre><code>0e25143 Merge branch &#39;feature&#39;
ad8621a Fix a bug in the feature
16b36c6 Add a new feature
23ad9ad Add the initial code base
</code></pre><p>This is very useful for getting a high-level overview of your project.</p>
<h2 id="Decorating"><a href="#Decorating" class="headerlink" title="Decorating"></a>Decorating</h2><p>Many times it’s useful to know which branch or tag each commit is associated with. The <code>--decorate</code> flag makes <code>git log</code> display all of the references (e.g., branches, tags, etc) that point to each commit.</p>
<p>This can be combined with other configuration options. For example, running <code>git log --oneline --decorate</code> will format the commit history like so:</p>
<pre><code>0e25143 (HEAD, master) Merge branch &#39;feature&#39;
ad8621a (feature) Fix a bug in the feature
16b36c6 Add a new feature
23ad9ad (tag: v0.9) Add the initial code base
</code></pre><p>This lets you know that the top commit is also checked out (denoted by <code>HEAD</code>) and that it is also the tip of the <code>master</code> branch. The second commit has another branch pointing to it called <code>feature</code>, and finally the 4th commit is tagged as <code>v0.9</code>.</p>
<p>Branches, tags, <code>HEAD</code>, and the commit history are almost all of the information contained in your Git repository, so this gives you a more complete view of the logical structure of your repository.</p>
<h2 id="Diffs"><a href="#Diffs" class="headerlink" title="Diffs"></a>Diffs</h2><p>The <code>git log</code> command includes many options for displaying diffs with each commit. Two of the most common options are <code>--stat</code> and <code>-p</code>.</p>
<p>The <code>--stat</code> option displays the number of insertions and deletions to each file altered by each commit (note that modifying a line is represented as 1 insertion and 1 deletion). This is useful when you want a brief summary of the changes introduced by each commit. For example, the following commit added 67 lines to the <code>hello.py</code> file and removed 38 lines:</p>
<pre><code>commit f2a238924e89ca1d4947662928218a06d39068c3
Author: John &lt;john@example.com&gt;
Date:   Fri Jun 25 17:30:28 2014 -0500

    Add a new feature

 hello.py | 105 ++++++++++++++++++++++++-----------------
 1 file changed, 67 insertion(+), 38 deletions(-)
</code></pre><p>The amount of <code>+</code> and <code>-</code> signs next to the file name show the relative number of changes to each file altered by the commit. This gives you an idea of where the changes for each commit can be found.</p>
<p>If you want to see the actual changes introduced by each commit, you can pass the <code>-p</code> option to <code>git log</code>. This outputs the entire patch representing that commit:</p>
<pre><code>commit 16b36c697eb2d24302f89aa22d9170dfe609855b
Author: Mary &lt;mary@example.com&gt;
Date:   Fri Jun 25 17:31:57 2014 -0500

    Fix a bug in the feature

diff --git a/hello.py b/hello.py
index 18ca709..c673b40 100644
--- a/hello.py
+++ b/hello.py
@@ -13,14 +13,14 @@ B
-print(&quot;Hello, World!&quot;)
+print(&quot;Hello, Git!&quot;)
</code></pre><p>For commits with a lot of changes, the resulting output can become quite long and unwieldy. More often than not, if you’re displaying a full patch, you’re probably searching for a specific change. For this, you want to use the pickaxe option.</p>
<h2 id="The-Shortlog"><a href="#The-Shortlog" class="headerlink" title="The Shortlog"></a>The Shortlog</h2><p>The <code>git shortlog</code> command is a special version of <code>git log</code> intended for creating release announcements. It groups each commit by author and displays the first line of each commit message. This is an easy way to see who’s been working on what.</p>
<p>For example, if two developers have contributed 5 commits to a project, the <code>git shortlog</code> output might look like the following:</p>
<pre><code>Mary (2):
      Fix a bug in the feature
      Fix a serious security hole in our framework

John (3):
      Add the initial code base
      Add a new feature
      Merge branch &#39;feature&#39;
</code></pre><p>By default, <code>git shortlog</code> sorts the output by author name, but you can also pass the <code>-n</code> option to sort by the number of commits per author.</p>
<h2 id="Graphs"><a href="#Graphs" class="headerlink" title="Graphs"></a>Graphs</h2><p>The <code>--graph</code> option draws an ASCII graph representing the branch structure of the commit history. This is commonly used in conjunction with the <code>--oneline</code> and <code>--decorate</code> commands to make it easier to see which commit belongs to which branch:</p>
<pre><code class="shell">git log --graph --oneline --decorate
</code></pre>
<p>For a simple repository with just 2 branches, this will produce the following:</p>
<pre><code>*   0e25143 (HEAD, master) Merge branch &#39;feature&#39;
|\
| * 16b36c6 Fix a bug in the new feature
| * 23ad9ad Start a new feature
* | ad8621a Fix a critical security issue
|/
* 400e4b7 Fix typos in the documentation
* 160e224 Add the initial code base
</code></pre><p>The asterisk shows which branch the commit was on, so the above graph tells us that the <code>23ad9ad</code> and <code>16b36c6</code> commits are on a topic branch and the rest are on the <code>master</code> branch.</p>
<p>While this is a nice option for simple repositories, you’re probably better off with a more full-featured visualization tool like <code>gitk</code> or <a href="https://www.atlassian.com/software/sourcetree/overview" target="_blank" rel="external">SourceTree</a> for projects that are heavily branched.</p>
<h2 id="Custom-Formatting"><a href="#Custom-Formatting" class="headerlink" title="Custom Formatting"></a>Custom Formatting</h2><p>For all of your other <code>git log</code> formatting needs, you can use the <code>--pretty=format:&quot;&lt;string&gt;&quot;</code> option. This lets you display each commit however you want using <code>printf</code>-style placeholders.</p>
<p>For example, the <code>%cn</code>, <code>%h</code> and <code>%cd</code> characters in the following command are replaced with the committer name, abbreviated commit hash, and the committer date, respectively.</p>
<pre><code class="shell">git log --pretty=format:&quot;%cn committed %h on %cd&quot;
</code></pre>
<p>This results in the following format for each commit:</p>
<pre><code>John committed 400e4b7 on Fri Jun 24 12:30:04 2014 -0500
John committed 89ab2cf on Thu Jun 23 17:09:42 2014 -0500
Mary committed 180e223 on Wed Jun 22 17:21:19 2014 -0500
John committed f12ca28 on Wed Jun 22 13:50:31 2014 -0500
</code></pre><p>The complete list of placeholders can be found in the <a href="https://www.kernel.org/pub/software/scm/git/docs/git-log.html#_pretty_formats" target="_blank" rel="external">Pretty Formats</a> section of the <code>git log</code> manual page.</p>
<p>Aside from letting you view only the information that you’re interested in, the <code>--pretty=format:&quot;&lt;string&gt;&quot;</code> option is particularly useful when you’re trying to pipe <code>git log</code> output into another command.</p>
<h1 id="Filtering-the-Commit-History"><a href="#Filtering-the-Commit-History" class="headerlink" title="Filtering the Commit History"></a>Filtering the Commit History</h1><p>Formatting how each commit gets displayed is only half the battle of learning <code>git log</code>. The other half is understanding how to navigate the commit history. The rest of this article introduces some of the advanced ways to pick out specific commits in your project history using <code>git log</code>. All of these can be combined with any of the formatting options discussed above.</p>
<h2 id="By-Amount"><a href="#By-Amount" class="headerlink" title="By Amount"></a>By Amount</h2><p>The most basic filtering option for <code>git log</code> is to limit the number of commits that are displayed. When you’re only interested in the last few commits, this saves you the trouble of viewing all the commits in a pager.</p>
<p>You can limit git log’s output by including the <code>-&lt;n&gt;</code> option. For example, the following command will display only the 3 most recent commits.</p>
<pre><code class="shell">git log -3
</code></pre>
<h2 id="By-Date"><a href="#By-Date" class="headerlink" title="By Date"></a>By Date</h2><p>If you’re looking for a commit from a specific time frame, you can use the <code>--after</code> or -<code>-before</code> flags for filtering commits by date. These both accept a variety of date formats as a parameter. For example, the following command only shows commits that were created <em>after</em> July 1st, 2014 (inclusive):</p>
<pre><code class="shell">git log --after=&quot;2014-7-1&quot;
</code></pre>
<p>You can also pass in relative references like <code>&quot;1 week ago&quot;</code> and <code>&quot;yesterday&quot;</code>:</p>
<pre><code class="shell">get log --after=&quot;yesterday&quot;
</code></pre>
<p>To search for a commits that were created between two dates, you can provide both a <code>--before</code> and <code>--after</code> date. For instance, to display all the commits added between July 1st, 2014 and July 4th, 2014, you would use the following:</p>
<pre><code class="shell">git log --after=&quot;2014-7-1&quot; --before=&quot;2014-7-4&quot;
</code></pre>
<p>Note that the <code>--since</code> and <code>--until</code> flags are synonymous with <code>--after</code> and <code>--before</code>, respectively.</p>
<h2 id="By-Author"><a href="#By-Author" class="headerlink" title="By Author"></a>By Author</h2><p>When you’re only looking for commits created by a particular user, use the <code>--author</code> flag. This accepts a regular expression, and returns all commits whose author matches that pattern. If you know exactly who you’re looking for, you can use a plain old string instead of a regular expression:</p>
<pre><code class="shell">git log --author=&quot;John&quot;
</code></pre>
<p>This displays all commits whose author includes the name <em>John</em>. The author name doesn’t need to be an <em>exact</em> match — it just needs to <em>contain</em> the specified phrase.</p>
<p>You can also use regular expressions to create more complex searches. For example, the following command searches for commits by either <em>Mary</em> or <em>John</em>.</p>
<pre><code class="shell">git log --author=&quot;John\|Mary&quot;
</code></pre>
<p>Note that the author’s email is also included with the author’s name, so you can use this option to search by email, too.</p>
<p>If your workflow separates committers from authors, the <code>--committer</code> flag operates in the same fashion.</p>
<h2 id="By-Message"><a href="#By-Message" class="headerlink" title="By Message"></a>By Message</h2><p>To filter commits by their commit message, use the <code>--grep</code> flag. This works just like the <code>--author</code> flag discussed above, but it matches against the commit message instead of the author.</p>
<p>For example, if your team includes relevant issue numbers in each commit message, you can use something like the following to pull out all of the commits related to that issue:</p>
<pre><code class="shell">git log --grep=&quot;JRA-224:&quot;
</code></pre>
<p>You can also pass in the <code>-i</code> parameter to <code>git log</code> to make it ignore case differences while pattern matching.</p>
<h2 id="By-File"><a href="#By-File" class="headerlink" title="By File"></a>By File</h2><p>Many times, you’re only interested in changes that happened to a particular file. To show the history related to a file, all you have to do is pass in the file path. For example, the following returns all commits that affected either the <code>foo.py</code> or the <code>bar.py</code> file:</p>
<pre><code class="shell">git log -- foo.py bar.py
</code></pre>
<p>The <code>--</code> parameter is used to tell <code>git log</code> that subsequent arguments are file paths and not branch names. If there’s no chance of mixing it up with a branch, you can omit the <code>--</code>.</p>
<h2 id="By-Content"><a href="#By-Content" class="headerlink" title="By Content"></a>By Content</h2><p>It’s also possible to search for commits that introduce or remove a particular line of source code. This is called a <em>pickaxe</em>, and it takes the form of <code>-S&quot;&lt;string&gt;&quot;</code>. For example, if you want to know when the string <code>Hello, World!</code> was added to any file in the project, you would use the following command:</p>
<pre><code class="shell">git log -S&quot;Hello, World!&quot;
</code></pre>
<p>If you want to search using a regular expression instead of a string, you can use the <code>-G&quot;&lt;regex&gt;&quot;</code> flag instead.</p>
<p>This is a very powerful debugging tool, as it lets you locate all of the commits that affect a particular line of code. It can even show you when a line was copied or moved to another file.</p>
<h2 id="By-Range"><a href="#By-Range" class="headerlink" title="By Range"></a>By Range</h2><p>You can pass a range of commits to <code>git log</code> to show only the commits contained in that range. The range is specified in the following format, where <code>&lt;since&gt;</code> and <code>&lt;until&gt;</code> are commit references:</p>
<pre><code class="shell">git log &lt;since&gt;..&lt;until&gt;
</code></pre>
<p>This command is particularly useful when you use branch references as the parameters. It’s a simple way to show the differences between 2 branches. Consider the following command:</p>
<pre><code class="shell">git log master..feature
</code></pre>
<p>The <code>master..feature</code> range contains all of the commits that are in the <code>feature</code> branch, but aren’t in the <code>master</code> branch. In other words, this is how far <code>feature</code> has progressed since it forked off of <code>master</code>. You can visualize this as follows:</p>
<img src="/2016/10/03/2016-10/advanced_git_log/1.svg" alt="Dectecting a fork in the history using ranges" title="Dectecting a fork in the history using ranges">
<p>Note that if you switch the order of the range (<code>feature..master</code>), you will get all of the commits in <code>master</code>, but not in <code>feature</code>. If <code>git log</code> outputs commits for both versions, this tells you that your history has diverged.</p>
<h2 id="Filtering-Merge-Commits"><a href="#Filtering-Merge-Commits" class="headerlink" title="Filtering Merge Commits"></a>Filtering Merge Commits</h2><p>By default, <code>git log</code> includes merge commits in its output. But, if your team has an always-merge policy (that is, you merge upstream changes into topic branches instead of rebasing the topic branch onto the upstream branch), you’ll have a lot of extraneous merge commits in your project history.</p>
<p>You can prevent <code>git log</code> from displaying these merge commits by passing the <code>--no-merges</code> flag:</p>
<pre><code class="shell">git log --no-merges
</code></pre>
<p>On the other hand, if you’re <em>only</em> interested in the merge commits, you can use the <code>--merges</code> flag:</p>
<pre><code class="shell">git log --merges
</code></pre>
<p>This returns all commits that have at least two parents.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>You should now be fairly comfortable using <code>git log</code>’s advanced parameters to format its output and select which commits you want to display. This gives you the power to pull out exactly what you need from your project history.</p>
<p>These new skills are an important part of your Git toolkit, but remember that <code>git log</code> is often used in conjunction other Git commands. Once you’ve found the commit you’re looking for, you typically pass it off to <code>git checkout</code>, <code>git revert</code>, or some other tool for manipulating your commit history. So, be sure to keep on learning about Git’s advanced features.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.atlassian.com/git/tutorials/git-log/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The purpose of any ver
    
    </summary>
    
      <category term="Git" scheme="https://athrunsun.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://athrunsun.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) Reset, Checkout, and Revert</title>
    <link href="https://athrunsun.github.io/2016/10/03/2016-10/git_reset_checkout_revert/"/>
    <id>https://athrunsun.github.io/2016/10/03/2016-10/git_reset_checkout_revert/</id>
    <published>2016-10-03T15:11:00.000Z</published>
    <updated>2019-03-18T08:00:19.498Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.atlassian.com/git/tutorials/resetting-checking-out-and-reverting" target="_blank" rel="external">Original Post</a></p>
<p>The <code>git reset</code>, <code>git checkout</code>, and <code>git revert</code> command are some of the most useful tools in your Git toolbox. They all let you undo some kind of change in your repository, and the first two commands can be used to manipulate either commits or individual files.</p>
<p>Because they’re so similar, it’s very easy to mix up which command should be used in any given development scenario. In this article, we’ll compare the most common configurations of <code>git reset</code>, <code>git checkout</code>, and <code>git revert</code>. Hopefully, you’ll walk away with the confidence to navigate your repository using any of these commands.</p>
<img src="/2016/10/03/2016-10/git_reset_checkout_revert/1.svg" alt="The main components of a Git repository" title="The main components of a Git repository">
<p>It helps to think about each command in terms of their effect on the three main components of a Git repository: the working directory, the staged snapshot, and the commit history. Keep these components in mind as you read through this article.</p>
<h1 id="Commit-level-Operation"><a href="#Commit-level-Operation" class="headerlink" title="Commit-level Operation"></a>Commit-level Operation</h1><p>The parameters that you pass to <code>git reset</code> and <code>git checkout</code> determine their scope. When you don’t include a file path as a parameter, they operate on whole commits. That’s what we’ll be exploring in this section. Note that <code>git revert</code> has no file-level counterpart.</p>
<h2 id="Reset"><a href="#Reset" class="headerlink" title="Reset"></a>Reset</h2><p>On the commit-level, resetting is a way to move the tip of a branch to a different commit. This can be used to remove commits from the current branch. For example, the following command moves the <code>hotfix</code> branch backwards by two commits.</p>
<pre><code class="shell">git checkout hotfix
git reset HEAD~2
</code></pre>
<p>The two commits that were on the end of <code>hotfix</code> are now dangling commits, which means they will be deleted the next time Git performs a garbage collection. In other words, you’re saying that you want to throw away these commits. This can be visualized as the following:</p>
<img src="/2016/10/03/2016-10/git_reset_checkout_revert/2.svg" alt="Resetting the hotfix branch to HEAD~2" title="Resetting the hotfix branch to HEAD~2">
<p>This usage of <code>git reset</code> is a simple way to undo changes that haven’t been shared with anyone else. It’s your go-to command when you’ve started working on a feature and find yourself thinking, “Oh crap, what am I doing? I should just start over.”</p>
<p>In addition to moving the current branch, you can also get <code>git reset</code> to alter the staged snapshot and/or the working directory by passing it one of the following flags:</p>
<ul>
<li><code>--soft</code> – The staged snapshot and working directory are not altered in any way.</li>
<li><code>--mixed</code> – The staged snapshot is updated to match the specified commit, but the working directory is not affected. This is the default option.</li>
<li><code>--hard</code> – The staged snapshot and the working directory are both updated to match the specified commit.</li>
</ul>
<p>It’s easier to think of these modes as defining the scope of a <code>git reset</code> operation:</p>
<img src="/2016/10/03/2016-10/git_reset_checkout_revert/3.svg" alt="The scope of git reset's modes" title="The scope of git reset's modes">
<p>These flags are often used with HEAD as the parameter. For instance, <code>git reset --mixed HEAD</code> has the affect of unstaging all changes, but leaves them in the working directory. On the other hand, if you want to completely throw away all your uncommitted changes, you would use <code>git reset --hard HEAD</code>. These are two of the most common uses of git reset.</p>
<p>Be careful when passing a commit other than <code>HEAD</code> to <code>git reset</code>, since this re-writes the current branch’s history. As discussed in <a href="https://www.atlassian.com/git/tutorials/resetting-checking-out-and-reverting/commit-level-operations" target="_blank" rel="external">The Golden Rule of Rebasing</a>, this a big problem when working on a public branch.</p>
<h2 id="Checkout"><a href="#Checkout" class="headerlink" title="Checkout"></a>Checkout</h2><p>By now, you should be very familiar with the commit-level version of <code>git checkout</code>. When passed a branch name, it lets you switch between branches.</p>
<pre><code class="shell">git checkout hotfix
</code></pre>
<p>Internally, all the above command does is move <code>HEAD</code> to a different branch and update the working directory to match. Since this has the potential to overwrite local changes, Git forces you to commit or stash any changes in the working directory that will be lost during the checkout operation. Unlike <code>git reset</code>, <code>git checkout</code> doesn’t move any branches around.</p>
<img src="/2016/10/03/2016-10/git_reset_checkout_revert/4.svg" alt="Moving HEAD from master to hotfix" title="Moving HEAD from master to hotfix">
<p>You can also check out arbitrary commits by passing in the commit reference instead of a branch. This does the exact same thing as checking out a branch: it moves the <code>HEAD</code> reference to the specified commit. For example, the following command will check out out the grandparent of the current commit:</p>
<pre><code class="shell">git checkout HEAD~2
</code></pre>
<img src="/2016/10/03/2016-10/git_reset_checkout_revert/5.svg" alt="Moving HEAD to an arbitary commit" title="Moving HEAD to an arbitary commit">
<p>This is useful for quickly inspecting an old version of your project. However, since there is no branch reference to the current <code>HEAD</code>, this puts you in a <code>detached HEAD state</code>. This can be dangerous if you start adding new commits because there will be no way to get back to them after you switch to another branch. For this reason, you should always create a new branch before adding commits to a detached <code>HEAD</code>.</p>
<h2 id="Revert"><a href="#Revert" class="headerlink" title="Revert"></a>Revert</h2><p>Reverting undoes a commit by creating a new commit. This is a safe way to undo changes, as it has no chance of re-writing the commit history. For example, the following command will figure out the changes contained in the 2nd to last commit, create a new commit undoing those changes, and tack the new commit onto the existing project.</p>
<pre><code class="shell">git checkout hotfix
git revert HEAD~2
</code></pre>
<p>This can be visualized as the following:</p>
<img src="/2016/10/03/2016-10/git_reset_checkout_revert/6.svg" alt="Reverting the 2nd to last commit" title="Reverting the 2nd to last commit">
<p>Contrast this with <code>git reset</code>, which does alter the existing commit history. For this reason, <code>git revert</code> should be used to undo changes on a public branch, and <code>git reset</code> should be reserved for undoing changes on a private branch.</p>
<p>You can also think of <code>git revert</code> as a tool for undoing <em>committed</em> changes, while <code>git reset HEAD</code> is for undoing <em>uncommitted</em> changes.</p>
<p>Like <code>git checkout</code>, <code>git revert</code> has the potential to overwrite files in the working directory, so it will ask you to commit or stash changes that would be lost during the revert operation.</p>
<h1 id="File-level-Operations"><a href="#File-level-Operations" class="headerlink" title="File-level Operations"></a>File-level Operations</h1><p>The <code>git reset</code> and <code>git checkout</code> commands also accept an optional file path as a parameter. This dramatically alters their behavior. Instead of operating on entire snapshots, this forces them to limit their operations to a single file.</p>
<h2 id="Reset-1"><a href="#Reset-1" class="headerlink" title="Reset"></a>Reset</h2><p>When invoked with a file path, <code>git reset</code> updates the staged snapshot to match the version from the specified commit. For example, this command will fetch the version of foo.py in the 2nd-to-last commit and stage it for the next commit:</p>
<pre><code class="shell">git reset HEAD~2 foo.py
</code></pre>
<p>As with the commit-level version of <code>git reset</code>, this is more commonly used with <code>HEAD</code> rather than an arbitrary commit. Running <code>git reset HEAD foo.py</code> will unstage <code>foo.py</code>. The changes it contains will still be present in the working directory.</p>
<img src="/2016/10/03/2016-10/git_reset_checkout_revert/7.svg" alt="Moving a file from the commit history into the staged snapshot" title="Moving a file from the commit history into the staged snapshot">
<p>The <code>--soft</code>, <code>--mixed</code>, and <code>--hard</code> flags do not have any effect on the file-level version of <code>git reset</code>, as the staged snapshot is <em>always</em> updated, and the working directory is <em>never</em> updated.</p>
<h2 id="Checkout-1"><a href="#Checkout-1" class="headerlink" title="Checkout"></a>Checkout</h2><p>Checking out a file is similar to using <code>git reset</code> with a file path, except it updates the working directory instead of the stage. Unlike the commit-level version of this command, this does not move the <code>HEAD</code> reference, which means that you won’t switch branches.</p>
<img src="/2016/10/03/2016-10/git_reset_checkout_revert/8.svg" alt="Moving a file from the commit history into the working directory" title="Moving a file from the commit history into the working directory">
<p>For example, the following command makes <code>foo.py</code> in the working directory match the one from the 2nd-to-last commit:</p>
<pre><code class="shell">git checkout HEAD~2 foo.py
</code></pre>
<p>Just like the commit-level invocation of <code>git checkout</code>, this can be used to inspect old versions of a project—but the scope is limited to the specified file.</p>
<p>If you stage and commit the checked-out file, this has the effect of “reverting” to the old version of that file. Note that this removes <em>all</em> of the subsequent changes to the file, whereas the <code>git revert</code> command undoes only the changes introduced by the specified commit.</p>
<p>Like <code>git reset</code>, this is commonly used with <code>HEAD</code> as the commit reference. For instance, <code>git checkout HEAD foo.py</code> has the effect of discarding unstaged changes to <code>foo.py</code>. This is similar behavior to <code>git reset HEAD --hard</code>, but it operates only on the specified file.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>You should now have all the tools you could ever need to undo changes in a Git repository. The <code>git reset</code>, <code>git checkout</code>, and <code>git revert</code> commands can be confusing, but when you think about their effects on the working directory, staged snapshot, and commit history, it should be easier to discern which command fits the development task at hand.</p>
<p>The table below sums up the most common use cases for all of these commands. Be sure to keep this reference handy, as you’ll undoubtedly need to use at least some them during your Git career.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Scope</th>
<th>Common use cases</th>
</tr>
</thead>
<tbody>
<tr>
<td>git reset</td>
<td>Commit-level</td>
<td>Discard commits in a private branch or throw away uncommited changes</td>
</tr>
<tr>
<td>git reset</td>
<td>File-level</td>
<td>Unstage a file</td>
</tr>
<tr>
<td>git checkout</td>
<td>Commit-level</td>
<td>Switch between branches or inspect old snapshots</td>
</tr>
<tr>
<td>git checkout</td>
<td>File-level</td>
<td>Discard changes in the working directory</td>
</tr>
<tr>
<td>git revert</td>
<td>Commit-level</td>
<td>Undo commits in a public branch</td>
</tr>
<tr>
<td>git revert</td>
<td>File-level</td>
<td>(N/A)</td>
</tr>
</tbody>
</table>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.atlassian.com/git/tutorials/resetting-checking-out-and-reverting&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/
    
    </summary>
    
      <category term="Git" scheme="https://athrunsun.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://athrunsun.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) String、StringBuffer与StringBuilder之间区别</title>
    <link href="https://athrunsun.github.io/2016/09/30/2016-9/string_vs_string_buffer_vs_string_builder/"/>
    <id>https://athrunsun.github.io/2016/09/30/2016-9/string_vs_string_buffer_vs_string_builder/</id>
    <published>2016-09-30T05:47:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://silencewt.github.io/2015/05/11/【转载】String、StringBuffer与StringBuilder之间区别/" target="_blank" rel="external">Original Post</a></p>
<p>Reproduced from <a href="http://www.cnblogs.com/A_ming/archive/2010/04/13/1711395.html" target="_blank" rel="external">here</a></p>
<p>这两天在看Java编程的书，看到<code>String</code>的时候将之前没有弄懂的都理清了一遍，本来想将<code>String</code>之间的区别记录下来的，在找资料的时候发现这位网友整理的很不错，值得借鉴。我就在这个上面添一点自己的理解了。原文地址在上面。</p>
<p>关于这三个类在字符串处理中的位置不言而喻，那么他们到底有什么优缺点，到底什么时候该用谁呢？下面我们从以下几点说明一下:</p>
<p>1.三者在执行速度方面的比较：<code>StringBuilder</code> &gt; <code>StringBuffer</code> &gt; <code>String</code></p>
<p>2.<code>String</code> &lt; (<code>StringBuffer</code>，<code>StringBuilder</code>)的原因</p>
<pre><code>String：字符串常量
StringBuffer：字符串变量
StringBuilder：字符串变量
</code></pre><p>从上面的名字可以看到，<code>String</code>是“字符串常量”，也就是不可改变的对象。对于这句话的理解你可能会产生这样一个疑问，比如这段代码：</p>
<pre><code class="java">String s = &quot;abcd&quot;;
s = s + 1;
System.out.print(s);// result: abcd1
</code></pre>
<p>我们明明就是改变了<code>String</code>型的变量s的，为什么说是没有改变呢? 其实这是一种欺骗，JVM是这样解析这段代码的：首先创建对象s，赋予一个abcd，然后再创建一个新的对象s用来执行第二行代码，也就是说我们之前对象s并没有变化，所以我们说<code>String</code>类型是不可改变的对象了，由于这种机制，每当用<code>String</code>操作字符串时，实际上是在不断的创建新的对象，而原来的对象就会变为垃圾被ＧＣ回收掉，可想而知这样执行效率会有多底。<code>String</code>类中每一个看起来会修改<code>String</code>值的方法，实际上都是创建一个全新的<code>String</code>对象，已包含修改后的字符串，而最初的<code>String</code>对象则丝毫未动。</p>
<p>而<code>StringBuffer</code>与<code>StringBuilder</code>就不一样了，他们是字符串变量，是可改变的对象，每当我们用它们对字符串做操作时，实际上是在一个对象上操作的，这样就不会像String一样创建一些而外的对象进行操作了，当然速度就快了。<code>StringBuffer</code>和<code>String</code>有很多相似之处，但是其内部的实现却有很大的差别，<code>StringBuffer</code>其实是一个分装一个字符数组，同时提供了对这个字符数组的相关操作。<code>StringBuffer()</code>构造一个字符缓冲区，其初始容量为16个字符。</p>
<p>3.一个特殊的例子：</p>
<pre><code class="java">String str = &quot;This is only a&quot; + &quot;simple&quot; + &quot;test&quot;;
StringBuffer builder = new StringBuilder(&quot;This is only a&quot;).append(&quot;simple&quot;).append(&quot;test&quot;);
</code></pre>
<p>你会很惊讶的发现，生成str对象的速度简直太快了，而这个时候<code>StringBuffer</code>居然速度上根本一点都不占优势。其实这是JVM的一个把戏，实际上<code>String str = &quot;This is only a&quot; + &quot; simple&quot; + &quot;test&quot;;</code>其实就是<code>String str = &quot;This is only a simple test&quot;;</code></p>
<p>所以不需要太多的时间了。但大家这里要注意的是，如果你的字符串是来自另外的<code>String</code>对象的话，速度就没那么快了，譬如：</p>
<pre><code class="java">String str2 = &quot;This is only a&quot;;
String str3 = &quot;simple&quot;;
String str4 = &quot;test&quot;;
String str1 = str2 +str3 + str4;
</code></pre>
<p>这时候JVM会规规矩矩的按照原来的方式去做。</p>
<p>4.<code>StringBuilder</code>与<code>StringBuffer</code></p>
<pre><code>StringBuilder：线程非安全的
StringBuffer：线程安全的
</code></pre><p>当我们在字符串缓冲区被多个线程使用时，JVM不能保证<code>StringBuilder</code>的操作是安全的，虽然他的速度最快，但是可以保证<code>StringBuffer</code>是可以正确操作的。当然大多数情况下就是我们是在单线程下进行的操作，所以大多数情况下是建议用<code>StringBuilder</code>而不用<code>StringBuffer</code>的，就是速度的原因。</p>
<p>对于三者使用的总结：</p>
<blockquote>
<p>1.如果要操作少量的数据用 = String</p>
<p>2.单线程操作字符串缓冲区下操作大量数据 = StringBuilder</p>
<p>3.多线程操作字符串缓冲区下操作大量数据 = StringBuffer.</p>
</blockquote>
<p>关于三者的速度，自己写了个测试代码：</p>
<pre><code class="java">package com.wt.others;

public class StringCompare {
    public static void main(String[] args) {
        // TODO Auto-generated method stub
        String text = &quot;&quot;;
        long beginTime = 0l;
        long endTime = 0l;
        StringBuffer buffer = new StringBuffer();
        StringBuilder builder = new StringBuilder();
        beginTime = System.currentTimeMillis();
        for(int i=0; i&lt;20000; i++){
            buffer.append(String.valueOf(i));
        }
        endTime = System.currentTimeMillis();
        System.out.println(&quot;StringBuffer time is : &quot;+ (endTime - beginTime));

        beginTime = System.currentTimeMillis();
        for(int i=0; i&lt;20000; i++){
            builder.append(String.valueOf(i));
        }
        endTime = System.currentTimeMillis();
        System.out.println(&quot;StringBuilder time is : &quot;+ (endTime - beginTime));

        beginTime = System.currentTimeMillis();
        for(int i=0; i&lt;20000; i++){
            text = text + i;
        }
        endTime = System.currentTimeMillis();
        System.out.println(&quot;String time is : &quot;+ (endTime - beginTime));
    }
}
</code></pre>
<p>运行结果可以直观的看出：</p>
<pre><code>StringBuffer time is : 5
StringBuilder time is : 3
String time is : 1550
</code></pre><p>如果将20000改为100，结果为：</p>
<pre><code>StringBuffer time is : 1
StringBuilder time is : 0
String time is : 1
</code></pre><p>还是可以直观看出在单线程使用时，<code>StringBuilder</code>速度很快。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://silencewt.github.io/2015/05/11/【转载】String、StringBuffer与StringBuilder之间区别/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/
    
    </summary>
    
      <category term="Java" scheme="https://athrunsun.github.io/categories/Java/"/>
    
    
      <category term="Java" scheme="https://athrunsun.github.io/tags/Java/"/>
    
      <category term="String" scheme="https://athrunsun.github.io/tags/String/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) 《Google软件测试之道》摘录</title>
    <link href="https://athrunsun.github.io/2016/09/30/2016-9/software_testing_google_approach/"/>
    <id>https://athrunsun.github.io/2016/09/30/2016-9/software_testing_google_approach/</id>
    <published>2016-09-30T05:47:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://silencewt.github.io/2015/06/05/《Google软件测试之道》摘录/" target="_blank" rel="external">Original Post</a></p>
<p>以下是最近看的一本书《Google软件测试之道》里的一些摘录，收获很多。</p>
<ol>
<li><p>讨论测试开发比并没有什么意义，如果你是一名开发人员，同时也是一名测试人员，如果你的职位头衔上有测试的字样，你的任务就是使那些头衔上没有测试的人可以更好的去做测试。</p>
</li>
<li><p>只有在软件产品变得重要的时候质量才显得重要。</p>
</li>
<li><p>假如你被要求去实现一个函数count（void *）返回一个字符串中大写字母A出现的次数。如果候选人上来就直接开始写代码，这无非在传递一个强烈的信息，只有一件事情需要去做而我正在做这个事情，这个事情就是写代码。SET不会遵循这样的世界观，他们会先把问题搞清楚。</p>
<p> 这个函数是用来做什么的?我们为什么要构建它？这个函数的原型看起来正确吗？我们期望候选人可以关心函数的正确性以及如何验证期望的行为。一个问题值得更多的关注!候选人如果没头没脑地就跳进来编码，试图解决问题，在对待测试问题上他同样会没头没脑。如果我们提出一个问题是给模块增加测试场景，我们不希望候选人上就直接开始罗列所有可能的测试用例，直到我们强迫他停下来。其实我们只是希望他先执行最佳的测试用例。</p>
<p> SET的时间是有限的。我们希望候选人能够回过头来寻找最有效的解决问题的方法，为先前的函数定义可以做一些改进。优秀的SET在面对拙劣的API定义的情况下，在测试的过程中也可以把这个API定义变得更漂亮些。</p>
<p> <strong>普通的候选人</strong>会花几分钟通过提问题和陈述的方式来理解需求文档，例如以下几点。</p>
<ul>
<li>传入的字符串编码是什么：ASCII, UTF-8或其他的编码方式?</li>
<li>函数名字比较槽糕，应该是驼峰式(CamelCased)的?需要更多说明描述，还是这里应该遵循其他的什么命名规范?</li>
<li>返回值类型是什么(或许面试官忘记了，所以我会增加一个int类型的返回值在函数原型之前)?</li>
<li>如果只有一个A的情况，计数结果是多少?它对小写字母a也计数吗?</li>
<li><p>在标准库中不是已经有这样的函数了吗(为了面试的目的，假装你是第一个实现这个函数功能的人)?</p>
<p><strong>更好的候选人</strong>则会考虑的更多一些。</p>
</li>
<li>考虑下扩展性：或许返回值的类型应该是1个64位的整形，因为Google经常涉及海量数据。</li>
<li>考虑下复用性：为什么这个函数是针对大写字母A进行计数的?一个好的办法是参数化，使得任意的字符都可以被计数，而不是使用不同的函数来实现。</li>
<li><p>考虑下安全性：这此指针都是来自于可信任的地址吗?</p>
<p><strong>最佳的候选人</strong>会这样考虑。</p>
</li>
<li>考虑扩展<blockquote>
<p>这个函数会在Shared data(译注:数据分区，是数据库存储分割(partition)的一种方式。水平分割是一个数据库的设计一准则，数据以记录行的方式存储在不同的物理位置，而不是通过不同列的方式存储。或许这才是调用这个函数最有用的形式。在这个场景需要考虑一些什么问题吗?针对整个互联网的所有文档运行这个函数，该如何考虑性能和正确性?</p>
<p>如果这个子程序被每一个Google查询所调用，而且由于外部的封装层面已经对参数做了验证，传递的指针是安全的，或许减少1个空指针的检查会每天节省上亿次的cpu调用周期，井缩短用户的响应时间。最少要理解全部参数验证所带来的潜在影响。</p>
</blockquote>
</li>
<li>考虑基于常量的优化<blockquote>
<p>我们可以假设输入的数据是已经排好顺序的吗？如果是那样，我们或许可以在找到第个大写字母B之后就快速退出。输入的数据是什么结构?多数情况下都是A吗?多数是字符的混合，还是只包含字毋A和空格？如果那样，在我们比较指令的地方或许可以做些优化。当在处理大数据，甚至小数据的时候，在代码执行的时候对于真实的计算延迟也会有比较显著的亚线性变化。</p>
</blockquote>
</li>
<li>考虑安全性<blockquote>
<p>在许多系统上，如果这是一段对于安全敏感的代码，可以考虑更多的非空的指针做测试，在某些系统上，1是一个非法指针。</p>
<p>增加一个字符长度的参数，用以保证代码不会运行到指定字符串之外的部分。检查字符串长度，这个参数的值是否正常。那些不是以null结尾的字符串是黑客们的最爱。</p>
<p>如果指针指向的数据能被其他的线程修改，这里就有潜在的线程安全问题。</p>
<p>我们是否应该使用try/catch来捕获异常的发生？或者如果未能如预期那样正常的调用代码，我们或许应该返回错误代码给调用者。如果有错误代码的话，这些代码经过良好的定义并有文档吗？这意味着候选人在思考大型代码库和运行时刻的上下文环境方面的问题，这样的思索可以避免错误代码的重复和遗漏。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>在Google，如果测试运行失败需要清除的知道测试代码在做什么，否则这个测试就应该被禁止掉，或者被标记为怪异的测试，或是忽略这个测试的运行失败，这个问题如果发生了，这是编写出坏代码的SWE的责任，或是代码审查时给予通过的投票的SWE或SET的责任。</p>
</li>
<li><p>使用白盒测试知道哪些用例是无效的：</p>
<p> 通常情况下，<strong>普通的候选人</strong>会这样做。</p>
<ul>
<li>他们会比较有条理地或体系化地提供特定的字符串(如不同的字符串大小)而不是随机的字符串。</li>
<li><p>专注于产生有意义的测试数据。考虑如何去运行大型测试和使用真实环境的数据做测试。</p>
<p><strong>更优秀的候选人</strong>会这样做的更多一些。</p>
</li>
<li>在并发线程中调用这个函数，去查看在串扰(cross talk)、死锁和内存泄露方面是否存在问题。</li>
<li>构建长时间持续运行的测试场景。例如在一个while(true)循环中调用函数，并确保他们在不间断地长时间运行过程中保持功能正常。</li>
<li>在构建测试用例、测试数据的产生方法、验证和执行上保持浓厚的兴趣。</li>
</ul>
</li>
<li><p>Selenium在浏览器内部使用JavaScript实现，而WebDriver使用浏览器本身的API集成到浏览器内部。两种方法各有优劣。例如，Selenium可以在瞬间打开一个新的Chrome浏览器，但却不能上传文件或者很好地处理用户交互，因为它是JavaScript实现，必须限定在JS沙箱之内。由于WebDriver构建在浏览器里面，它可以突破这些限制，但打开个新的浏览器却比较痛苦。在我们都开始为Google工作的时候，我们决定把这两个集成到一起。</p>
</li>
<li><p>风险分析</p>
<ul>
<li>哪些事件需要担心</li>
<li>这些事件发生的可能性有多大?</li>
<li>一旦发生，对公司产生多大影响?</li>
<li>一旦发生，对客户产生多大影响?</li>
<li>产品具备什么缓解措施?</li>
<li>这些缓解措施有多大可能会失败?</li>
<li>处理这些失败的成本有哪些？</li>
<li>恢复过程有多困难?</li>
<li>事件是一次性问题，还是会再次发生?</li>
</ul>
</li>
<li><p>对于一个web测试页面，一个文本输入框，一个计数按钮，用于计算一个字符串中大写字母A出现的个数。请设计出一系列字符串来测试这个web页面。</p>
<p> 一些候选人头扎进去开始罗列测试用例，这往往是一个危险的信号，说明他们还没有充分思考这个问题。根据我们的经验，追求数量而非质量的倾向，是一种低效的工作方式，因此会给负面评价。通过观察候选人在找到答案之前思考和解决问题的方式，能了解他们很多东西。</p>
<p> 更好的是那些会提出一些问题，<strong>来做进一步澄清的候选人</strong>：大写还是小写？只是英语吗？计算完成后文本会被清除吗？多次按下按钮会发生什么事情？诸如此类。在问题被澄清之后，候选人开始列举测试用例。重点观察他们是否使用一些疯狂的做法。他们只是在试图破坏软件，还是同时在验证它能正常工作？他们知道这两者的区别吗？他们是否能从最显而易见的简单的输入开始，尽快地发现大bug?他们能清晰地列出测试计划或数据吗?在白板上随机摆放字符串不能反映出思路的清晰性，他们很可能毫无测试计划，或者只有很粗糙很随意的测试计划。</p>
<p> 一个典型的列表如下：</p>
<ul>
<li>“banana”: 3（一个合法的英文字）</li>
<li>“A”和”a”: 1（一个简单的有正常结果的合法输入）</li>
<li>“”: 0（一个简单的结果为0的合法输入）</li>
<li>Null: 0（简单的错误输入）</li>
<li>“AA”和”aa”: 2（个数&gt;1并且所有字母都是A的输入）</li>
<li>“b”: 0（一个简单的非空合法输入，结果是0）</li>
<li>“aba”: 2（目标字符出现在开头和结尾，以寻找循环边界错误）</li>
<li>“bab”: 1（目标字符出现在中间）</li>
<li>space/tabs等: N（空白字符与N个A的混合）</li>
<li>不包含A的长字符串: N, 其中N&gt;0</li>
<li>包含A的长字符串: N, 其中N是A出现的个数</li>
<li>X\nX字符串: N, 其中N是A出现的个数（格式化字符串）</li>
<li><p>{java/C/HTML/JavaScript}: N, 其中N是A出现的个数（可执行字符）</p>
<p>无论丢失上述测试和总结哪几个都是一个不好的征兆。</p>
<p><strong>更好的候选人</strong>会超越输入选择，讨论更加高级的测试问题。他们可能会做以下的事情。</p>
</li>
<li>质疑界面的外观、调色板和对比度。如“这些与相关应用风格一致吗?”，“视力困难的人能使用么？”等</li>
<li>担心文本框太小了，建议加长以便显示更长的输入字符串。</li>
<li>考虑这个应用能否在同一台服务器运行多个实例。会发生多个用户的串扰吗？</li>
<li>提出疑问“数据会被记录吗”，输入串可能包含地址或其他身份信息。</li>
<li>建议使用真实数据进行自动化测试，如从词典或书本里选择。</li>
<li>提出疑问，“计算足够快吗?在大负载下呢?”</li>
<li>提出疑问，“该页是可发现的吗？用户怎么能找到该页面呢？”</li>
<li>输入HTML和JavaScript，看是否会破坏页面渲染。</li>
<li>询问是对大写还是小写的A计数，还是都包括。</li>
<li><p>尝试复制和粘贴字符串。</p>
<p>还有一些想法更加高级，反映了富有经验的、宝贵的测试思维，能够比问题走的更远。他们可能会这样做。</p>
</li>
<li>意识到计算会通过URL-encoded HTTP GET请求传递到服务器，字符串可能会在穿越网络时被截断。因此，无法保证支持多长的URL</li>
<li>建议将此应用参数化。为何只对字母A一计数呢?</li>
<li>考虑计算其他语台中的A(如埃A或变音符号)。</li>
<li>考虑该应用是否可以被国际化。</li>
<li>考虑编写脚本或者手工采样来探知字符串长度的上限(例如，通过2的指数递进算法)，然后确保在此区间内功能正常。</li>
<li>考虑背后的实现和代码。也许有一个计数器遍历该字符串，另外一个跟踪已经遇到了多少个A累加器)。因此，可以在边界值附近变化A的个数和字符串的长度来进行测试。</li>
<li>提出疑问，”HTTP POST方法和参数会被黑掉吗?也许有安全漏洞?”</li>
<li><p>用脚本创建各种有趣的排列组合和字符串特性如长度、A的个数等的组合，自动生成测试输入和验证。</p>
<p>了解候选人使用多长的字符串做为测试用例，这通常能暗示他们工作时的表现。如果候选人只是一般性的知道使用“长字符串”(最常见的答案)，但却无法就特定场景进行技术性的分析，这是一种糟糕的迹象。更懂技术的候选人，会询问字符串的规格说明，进而围绕极限点进行边界值测试。例如，当极限点是1000的时候，他们会尝试999. 1000和10010最好的候选人还会尝试2^32，以及许多其他有趣的值，例如2和10的次方。重点在于候选人表现出对真正重要的数字值的理解，而不只是使用随机数值——他们需要对底层的算法、语言、运行时和硬件都有所了解，因为这些正是错误最经常出现的地方。他们还应当基于可能的实现细节尝试不同的长度，并考虑到计数器、指针及抓环的边界错误。最优秀的候选人还会意识到系统可能是有状态的，测试必须将先前的输入考虑在内。因此，多次输入同一字符串，或者在长度为1000的字符串之后输入一个长度为0的，这些就属于重要的使用情形。</p>
<p>在Google，鉴于快节奏的发布周期，规格说明经常变来变去，可以有不同的理解和修改。如果候选人能指出“5个字符的最大长度”这种描述是有点奇怪的，有可能会使用户感到疑惑，这正反映了他们能从用户角度思考。如果候选人不假思索地接受了这个描述并匆忙动手，那他们在实际工作中也很有可能如此，结果是自费力气验证了错误的行为。那些能反驳或者质疑规格说明的候选人，往往在工作中有优异的表现。当然，也要注意反驳或者质疑的方式。</p>
</li>
</ul>
</li>
<li><p>加入一个新项目的头几个星期，<strong>我主要用来倾听而不是发表意见，深入理解团队非常重要，要学习产品的架构，了解团队的最新动态</strong>。我不能接受一位医生在观察我不到五分钟的时间就给我开乓抗生素类的药诗之:。同样地，我也不期望个测试团队可以接受，我一开始就提出的什么解决方案。在进行诊断之前你必须先要学习。</p>
<p> 我感觉人们有时候做事只是因为看到别人这么做，或者他们测试某个特性的时候只是做那些他们知道怎么做的东西。如果你不问他们为什么，他们自己也不会费心思考这事儿，因为他们已经把那些作为了一种习惯。</p>
</li>
<li><p>我们做的每件事都有明确的目的。我们质疑所有的事情：测试用例、每项自动化测试。其实我们正在做的很多事情就通不过这种审视。如果自动化不能带来明确的价值，我们就废弃它。所有的事情都是价值驱动的，这才能成就团队。如果要我给新晋测试经理什么建议，我会告诉他们：你们做的每一件事都要创造价值，能够持续地创造价值。</p>
</li>
<li><p><strong>我的测试人员个个都是通才</strong>。具体来说，每个人都能做手工测试，真的是每个人都能。探索式测试足深入学习理解一个产品的最佳途径。我永远不会让 一个测试开发工程师成为一个框架开发者。我希望他们深入产品并了解如何使用它。每个测试人员都必须强调用户。他们必须是专家级的用户，通晓整个产品的每个细节。在我的团队，我们把如稳定性测试、电源管理、性能测试、压力测试和第三方应用程序的快速检查都留给自动化测试完成。举个例子，没有人能够手动发现相机的内存泄露或在各个平台下验证一个单一特性的功能——这丝都需要自动化。大量重复性的工作不适合手工测试，或者一些需要机器才能达到的高精度测试就必须通过自动化测试来完成。</p>
</li>
<li><p>Google的测试流程可以非常简练地概括为：<strong>让每个工程师都注重质量</strong>。只要大家诚实认真地这么做，质量就会提高。代码质量从一开始就能更好，早期构建版本的质量会更高，集成也不再是必须的，系统测试可以关注于真正面向用户的问题。所有的工程师和项目都能从堆积如山的bug中解脱出来。</p>
</li>
<li><p>Google在测试方面的秘方：（James）那就是测试人员所拥有的技术能力(包括计算机科学的专业文凭)、测试资源的稀缺从而获得开发人员帮助和不断进行测试优化、优先考虑自动化(这样才能让人去做那些计算机做不好的事情)，以及快速迭代、集成和获得用户反馈的能力。其他公司要想效仿Google的做法，应该从这四个方面做起：<strong>技能、稀缺性、自动化和迭代集成</strong>。这就是Google测试的“秘方”，照方抓药吧！</p>
</li>
<li><p>任何角色都不应被过分强调。团队的每个人都是在为产品工作，而不是为了开发过程中的某个部分。开发过程本身就是为产品服务的。除了做出更好的产品，流程的存在还有其他的目的吗？用户爱上的是产品，而不是开发产品流程。</p>
</li>
<li><p><strong>测试的价值是在于测试的动作，而不是测试产物</strong>。</p>
<p>相对于被测代码来说，测试工程师生成的测试产物都是次要的：测试用例是次要的：测试计划是次要的：bug报告是次要的。这些产物都需要通过测试活动才能体现价值。不幸的是，我们过分称赞这此产物(比如在年度评估时，统计测试上程师提交的bug数量) ,而忘记了被测的软件。所有测试产物的价值，在于它们对代码的影响，进而通过产品来体现。</p>
<p>独立的测试团队，倾向于把重点放在建设和维护测试产物上。如果把测试的目标定位在产品的源码上，整个产品都将受益。因此，测试人员必须把产品放在第一位。</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://silencewt.github.io/2015/06/05/《Google软件测试之道》摘录/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以下是最近看的一本书《Goog
    
    </summary>
    
      <category term="Testing" scheme="https://athrunsun.github.io/categories/Testing/"/>
    
    
      <category term="Testing" scheme="https://athrunsun.github.io/tags/Testing/"/>
    
      <category term="Google" scheme="https://athrunsun.github.io/tags/Google/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) Exception Wrapping</title>
    <link href="https://athrunsun.github.io/2016/09/30/2016-9/exception_wrapping/"/>
    <id>https://athrunsun.github.io/2016/09/30/2016-9/exception_wrapping/</id>
    <published>2016-09-30T05:38:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tutorials.jenkov.com/java-exception-handling/exception-wrapping.html" target="_blank" rel="external">Original Post</a></p>
<h1 id="What-is-Exception-Wrapping"><a href="#What-is-Exception-Wrapping" class="headerlink" title="What is Exception Wrapping?"></a>What is Exception Wrapping?</h1><p>Exception wrapping is wrapping is when you catch an exception, wrap it in a different exception and throw that exception. Here is an example:</p>
<pre><code class="java">try{
    dao.readPerson();
} catch (SQLException sqlException) {
    throw new MyException(&quot;error text&quot;, sqlException);
}
</code></pre>
<p>The method dao.readPerson() can throw an SQLException. If it does, the SQLException is caught and wrapped in a MyException. Notice how the SQLException (the sqlException variable) is passed to the MyException’s constructor as the last parameter.</p>
<p>Exception wrapping is a standard feature in Java since JDK 1.4. Most (if not all) of Java’s built-in exceptions has constructors that can take a “cause” parameter. They also have a getCause() method that will return the wrapped exception.</p>
<h1 id="Why-Use-Exception-Wrapping"><a href="#Why-Use-Exception-Wrapping" class="headerlink" title="Why Use Exception Wrapping?"></a>Why Use Exception Wrapping?</h1><p>The main reason one would use exception wrapping is to prevent the code further up the call stack from having to know about every possible exception in the system. There are two main reasons for this.</p>
<p>The first reason is, that declared exceptions aggregate towards the top of the call stack. If you do not wrap exceptions, but instead pass them on by declaring your methods to throw them, you may end up with top level methods that declare many different exceptions. Declaring all these exceptions in each method back up the call stack becomes tedious.</p>
<p>The second reason is that you may not want your top level components to know anything about the bottom level components, nor the exceptions they throw. For instance, the purpose of DAO interfaces and implementations is to abstract the details of data access away from the rest of the application. Now, if your DAO methods throw SQLException’s then the code using the DAO’s will have to catch them. What if you change to an implementation that reads the data from a web service instead of from a database? Then you DAO methods will have to throw both RemoteException and SQLException. And, if you have a DAO that reads data from a file, you will need to throw IOException too. That is three different exceptions, each bound to their own DAO implementation.</p>
<p>To avoid this your DAO interface methods can throw DaoException. In each implementation of the DAO interface (database, file, web service) you will catch the specific exceptions (SQLException, IOException, RemoteException), wrap it in a DaoException, and throw the DaoException. Then code using the DAO interface will only have to deal with DaoException’s. It does not need to know anything about what data access technology is used in the various implementations.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tutorials.jenkov.com/java-exception-handling/exception-wrapping.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p
    
    </summary>
    
      <category term="Java" scheme="https://athrunsun.github.io/categories/Java/"/>
    
    
      <category term="Java" scheme="https://athrunsun.github.io/tags/Java/"/>
    
      <category term="Exception" scheme="https://athrunsun.github.io/tags/Exception/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) Java is Pass-by-Value, Dammit!</title>
    <link href="https://athrunsun.github.io/2016/09/30/2016-9/java_is_pass_by_value/"/>
    <id>https://athrunsun.github.io/2016/09/30/2016-9/java_is_pass_by_value/</id>
    <published>2016-09-30T02:00:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://javadude.com/articles/passbyvalue.htm" target="_blank" rel="external">Original Post</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>I finally decided to write up a little something about Java’s parameter passing. I’m really tired of hearing folks (incorrectly) state “primitives are passed by value, objects are passed by reference”.</p>
<p>I’m a compiler guy at heart. The terms “pass-by-value” semantics and “pass-by-reference” semantics have very precise definitions, and they’re often horribly abused when folks talk about Java. I want to correct that… The following is how I’d describe these</p>
<h2 id="Pass-by-value"><a href="#Pass-by-value" class="headerlink" title="Pass-by-value"></a>Pass-by-value</h2><blockquote>
<p>The actual parameter (or argument expression) is fully evaluated and the resulting value is copied into a location being used to hold the formal parameter’s value during method/function execution. That location is typically a chunk of memory on the runtime stack for the application (which is how Java handles it), but other languages could choose parameter storage differently.</p>
</blockquote>
<h2 id="Pass-by-reference"><a href="#Pass-by-reference" class="headerlink" title="Pass-by-reference"></a>Pass-by-reference</h2><blockquote>
<p>The formal parameter merely acts as an alias for the actual parameter. Anytime the method/function uses the formal parameter (for reading or writing), it is actually using the actual parameter.</p>
</blockquote>
<p>Java is <em><strong>strictly</strong></em> pass-by-value, exactly as in C. Read the Java Language Specification (JLS). It’s spelled out, and it’s correct. In <a href="http://java.sun.com/docs/books/jls/third_edition/html/classes.html#8.4.1" target="_blank" rel="external">here</a>:</p>
<blockquote>
<p>When the method or constructor is invoked <a href="http://java.sun.com/docs/books/jls/third_edition/html/expressions.html#20448" target="_blank" rel="external">(�15.12)</a>, the <em><strong>values</strong></em> of the actual argument expressions initialize newly created parameter variables, each of the declared <strong><strong>Type</strong></strong>, before execution of the body of the method or constructor. The <em><strong>Identifier</strong></em> that appears in the <em><strong>DeclaratorId</strong></em> may be used as a simple name in the body of the method or constructor to refer to the formal parameter.</p>
</blockquote>
<p>[In the above, <em><strong>values</strong></em> is my emphasis, not theirs]</p>
<p>In short: Java has <em><strong>pointers</strong></em> and is strictly pass-by-value. There’s no funky rules. It’s simple, clean, and clear. (Well, as clear as the evil C++-like syntax will allow ;)</p>
<p><em>Note: See the <a href="http://javadude.com/articles/passbyvalue.htm#A%20Note%20on%20Remote%20Method%20Invocation" target="_blank" rel="external">note at the end of this article</a> for the semantics of remote method invocation (RMI). What is typically called “pass by reference” for remote objects is actually incredibly bad semantics.</em></p>
<h1 id="The-Litmus-Test"><a href="#The-Litmus-Test" class="headerlink" title="The Litmus Test"></a>The Litmus Test</h1><p>There’s a simple “litmus test” for whether a language supports pass-by-reference semantics:</p>
<p>Can you write a traditional swap(a,b) method/function in the language?</p>
<p>A traditional swap method or function takes two arguments and swaps them such that variables passed into the function are changed outside the function. Its basic structure looks like</p>
<p><em>Figure 1: (Non-Java) Basic swap function structure</em></p>
<pre><code>swap(Type arg1, Type arg2) {
    Type temp = arg1;
    arg1 = arg2;
    arg2 = temp;
}
</code></pre><p>If you can write such a method/function in your language such that calling</p>
<p><em>Figure 2: (Non-Java) Calling the swap function</em></p>
<pre><code>Type var1 = ...;
Type var2 = ...;
swap(var1,var2);
</code></pre><p>actually switches the values of the variables var1 and var2, the language supports pass-by-reference semantics.</p>
<p>For example, in Pascal, you can write</p>
<p><em>Figure 3: (Pascal) Swap function</em></p>
<pre><code>procedure swap(var arg1, arg2: SomeType);

    var
        temp : SomeType;
    begin
        temp := arg1;
        arg1 := arg2;
        arg2 := temp;
    end;

...

{ in some other procedure/function/program }

var
    var1, var2 : SomeType;

begin
    var1 := ...; { value &quot;A&quot; }
    var2 := ...; { value &quot;B&quot; } 
    swap(var1, var2);
    { now var1 has value &quot;B&quot; and var2 has value &quot;A&quot; }
end;
</code></pre><p>or in C++ you could write</p>
<p><em>Figure 4: (C++) Swap function</em></p>
<pre><code>void swap(SomeType&amp; arg1, Sometype&amp; arg2) {
    SomeType temp = arg1;
    arg1 = arg2;
    arg2 = temp;
}

...

SomeType var1 = ...; // value &quot;A&quot;
SomeType var2 = ...; // value &quot;B&quot;
swap(var1, var2); // swaps their values!
// now var1 has value &quot;B&quot; and var2 has value &quot;A&quot;
</code></pre><p>(Please let me know if my Pascal or C++ has lapsed and I’ve messed up the syntax…)</p>
<p>But you cannot do this in Java!</p>
<h1 id="Now-the-details…"><a href="#Now-the-details…" class="headerlink" title="Now the details…"></a>Now the details…</h1><p>The problem we’re facing here is statements like</p>
<p><em>In Java, Objects are passed by reference, and primitives are passed by value.</em></p>
<p>This is half incorrect. Everyone can easily agree that primitives are passed by value; there’s no such thing in Java as a pointer/reference to a primitive.</p>
<p>However, <em><strong>Objects are not passed by reference</strong></em>. A correct statement would be <em><strong>Object references are passed by value</strong></em>.</p>
<p>This may seem like splitting hairs, bit it is <em>far</em> from it. There is a world of difference in meaning. The following examples should help make the distinction.</p>
<p>In Java, take the case of</p>
<p><em>Figure 5: (Java) Pass-by-value example</em></p>
<pre><code class="java">public void foo(Dog d) {
    d = new Dog(&quot;Fifi&quot;); // creating the &quot;Fifi&quot; dog
}

Dog aDog = new Dog(&quot;Max&quot;); // creating the &quot;Max&quot; dog
// at this point, aDog points to the &quot;Max&quot; dog
foo(aDog);
// aDog still points to the &quot;Max&quot; dog
</code></pre>
<p>the variable passed in (aDog) <em><strong>is not</strong></em> modified! After calling foo, aDog <em><strong>still</strong></em> points to the “Max” Dog!</p>
<p>Many people mistakenly think/state that something like</p>
<p><em>Figure 6: (Java) Still pass-by-value…</em></p>
<pre><code class="java">public void foo(Dog d) { 
    d.setName(&quot;Fifi&quot;);
}
</code></pre>
<p>shows that Java does in fact pass objects by reference.</p>
<p>The mistake they make is in the definition of</p>
<p><em>Figure 7: (Java) Defining a Dog pointer</em></p>
<pre><code class="java">Dog d;
</code></pre>
<p>itself. When you write that definition, you are defining a <em><strong>pointer</strong></em> to a Dog object, <em><strong>not</strong></em> a Dog object itself.</p>
<h2 id="On-Pointers-versus-References…"><a href="#On-Pointers-versus-References…" class="headerlink" title="On Pointers versus References…"></a>On Pointers versus References…</h2><p>The problem here is that the folks at Sun made a naming mistake.</p>
<p>In programming language design, a “pointer” is a variable that indirectly tracks the location of some piece of data. The value of a pointer is often the memory address of the data you’re interested in. Some languages allow you to manipulate that address; others do not.</p>
<p>A “reference” is an alias to another variable. Any manipulation done to the reference variable directly changes the original variable.</p>
<p>Check out the second sentence of <a href="http://java.sun.com/docs/books/jls/third_edition/html/typesValues.html#4.3.1" target="_blank" rel="external">http://java.sun.com/docs/books/jls/third_edition/html/typesValues.html#4.3.1</a>.</p>
<blockquote>
<p>“The reference values (often just references) are pointers to these objects, and a special null reference, which refers to no object”</p>
</blockquote>
<p>They emphasize “pointers” in their description… Interesting…</p>
<p>When they originally were creating Java, they had “pointer” in mind (you can see some remnants of this in things like<br>NullPointerException).</p>
<p>Sun wanted to push Java as a secure language, and one of Java’s advantages was that it does not allow pointer arithmetic as C++ does.</p>
<p>They went so far as to try a different name for the concept, formally calling them “references”. A big mistake and it’s caused even more confusion in the process.</p>
<p>There’s a good explanation of reference variables at <a href="http://www.cprogramming.com/tutorial/references.html" target="_blank" rel="external">http://www.cprogramming.com/tutorial/references.html</a>. (C++ specific, but it says the right thing about the concept of a reference variable.)</p>
<p>The word “reference” in programming language design originally comes from how you pass data to subroutines/functions/procedures/methods. A reference parameter is an alias to a variable passed as a parameter.</p>
<p>In the end, Sun made a naming mistake that’s caused confusion. Java has pointers, and if you accept that, it makes the way Java behaves make much more sense.</p>
<h2 id="Calling-Methods"><a href="#Calling-Methods" class="headerlink" title="Calling Methods"></a>Calling Methods</h2><p>Calling</p>
<p><em>Figure 8: (Java) Passing a pointer by value</em></p>
<pre><code class="java">foo(d);
</code></pre>
<p>passes the <em><strong>value of d</strong></em> to foo; it does not pass the object that d points to!</p>
<p>The value of the pointer being passed is similar to a memory address. Under the covers it may be a tad different, but you can think of it in exactly the same way. The value uniquely identifies some object on the heap.</p>
<p><em><strong>However</strong></em>, it makes no difference how pointers are <em><strong>implemented</strong></em> under the covers. You program with them <em><strong>exactly</strong></em> the same way in Java as you would in C or C++. The syntax is just slightly different (another poor choice in Java’s design; they should have used the same -&gt; syntax for de-referencing as C++).</p>
<p>In Java,</p>
<p><em>Figure 9: (Java) A pointer</em></p>
<pre><code class="java">Dog d;
</code></pre>
<p>is <em><strong>exactly</strong></em> like C++’s</p>
<p><em>Figure 10: (C++) A pointer</em></p>
<pre><code class="cpp">Dog *d;
</code></pre>
<p>And using</p>
<p><em>Figure 11: (Java) Following a pointer and calling a method</em></p>
<pre><code class="java">d.setName(&quot;Fifi&quot;);
</code></pre>
<p>is exactly like C++’s</p>
<p><em>Figure 12: (C++) Following a pointer and calling a method</em></p>
<pre><code class="cpp">d-&gt;setName(&quot;Fifi&quot;);
</code></pre>
<p>To sum up: Java <em><strong>has</strong></em> pointers, and the <em><strong>value</strong></em> of the <em><strong>pointer</strong></em> is passed in. There’s no way to actually pass an object itself as a parameter. You can only pass a pointer to an object.</p>
<p>Keep in mind, when you call</p>
<p><em>Figure 13: (Java) Even more still passing a pointer by value</em></p>
<pre><code class="java">foo(d);
</code></pre>
<p>you’re not passing an object; you’re passing a <em><strong>pointer</strong></em> to the object.</p>
<p>For a slightly different (but still correct) take on this issue, please see <a href="http://www-106.ibm.com/developerworks/library/j-praxis/pr1.html" target="_blank" rel="external">this</a>. It’s from Peter Haggar’s excellent book, Practical Java.)</p>
<h1 id="A-Note-on-Remote-Method-Invocation-RMI"><a href="#A-Note-on-Remote-Method-Invocation-RMI" class="headerlink" title="A Note on Remote Method Invocation (RMI)"></a>A Note on Remote Method Invocation (RMI)</h1><p>When passing parameters to remote methods, things get a bit more complex. First, we’re (usually) dealing with passing data between two independent virtual machines, which might be on separate physical machines as well. Passing the value of a pointer wouldn’t do any good, as the target virtual machine doesn’t have access to the caller’s heap.</p>
<p>You’ll often hear “pass by value” and “pass by reference” used with respect to RMI. These terms have more of a “logical” meaning, and really aren’t correct for the intended use.</p>
<p>Here’s what is usually meant by these phrases with regard to RMI. Note that this is not proper usage of “pass by value” and “pass by reference” semantics:</p>
<p><strong>RMI Pass-by-value</strong></p>
<blockquote>
<p>The actual parameter is serialized and passed using a network protocol to the target remote object. Serialization essentially “squeezes” the data out of an object/primitive. On the receiving end, that data is used to build a “clone” of the original object or primitive. Note that this process can be rather expensive if the actual parameters point to large objects (or large graphs of objects).</p>
</blockquote>
<p><strong>This isn’t quite the right use of “pass-by-value”; I think it should really be called something like “pass-by-memento”. (See “Design Patterns” by Gamma et al for a description of the Memento pattern).</strong></p>
<p><strong>RMI Pass-by-reference</strong></p>
<blockquote>
<p>The actual parameter, which <em>is itself a remote object</em>, is represented by a proxy. The proxy keeps track of where the actual parameter lives, and anytime the target method uses the formal parameter, <em>another remote method invocation occurs</em> to “call back” to the actual parameter. This can be useful if the actual parameter points to a large object (or graph of objects) and there are few call backs.</p>
</blockquote>
<p><strong>This isn’t quite the right use of “pass-by-reference” (again, you cannot change the actual parameter itself). I think it should be called something like “pass-by-proxy”. (Again, see “Design Patterns” for descriptions of the Proxy pattern).</strong></p>
<h1 id="Follow-up-from-stackoverflow-com"><a href="#Follow-up-from-stackoverflow-com" class="headerlink" title="Follow up from stackoverflow.com"></a>Follow up from stackoverflow.com</h1><p><em>I posted the following as some clarification when a discussion on this article arose on <a href="http://stackoverflow.com" target="_blank" rel="external">http://stackoverflow.com</a>.</em></p>
<p>The Java Spec says that everything in java is pass-by-value. There is no such thing as “pass-by-reference” in java.</p>
<p>The key to understanding this is that something like</p>
<p><em>Figure 14: (Java) Not a Dog; a pointer to a Dog</em></p>
<pre><code class="java">Dog myDog;
</code></pre>
<p>is not a Dog; it’s actually a pointer to a Dog.</p>
<p>What that means, is when you have</p>
<p><em>Figure 15: (Java) Passing the Dog’s location</em></p>
<pre><code class="java">Dog myDog = new Dog(&quot;Rover&quot;);
foo(myDog);
</code></pre>
<p>you’re essentially passing the address of the created Dog object to the foo method. (I say essentially b/c java pointers aren’t direct addresses, but it’s easiest to think of them that way)</p>
<p>Suppose the Dog object resides at memory address 42. This means we pass 42 to the method.</p>
<p>If the Method were defined as</p>
<p><em>Figure 16: (Java) Looking at the called method in detail</em></p>
<pre><code class="java">public void foo(Dog someDog) {
    someDog.setName(&quot;Max&quot;);     // AAA
    someDog = new Dog(&quot;Fifi&quot;);  // BBB
    someDog.setName(&quot;Rowlf&quot;);   // CCC
}
</code></pre>
<p>Let’s look at what’s happening.</p>
<p>the parameter someDog is set to the value 42</p>
<p><strong>at line “AAA”</strong></p>
<blockquote>
<p>someDog is followed to the Dog it points to (the Dog object at address 42) that Dog (the one at address 42) is asked to change his name to Max</p>
</blockquote>
<p><strong>at line “BBB”</strong></p>
<blockquote>
<p>a new Dog is created. Let’s say he’s at address 74 we assign the parameter someDog to 74</p>
</blockquote>
<p><strong>at line “CCC”</strong></p>
<blockquote>
<p>someDog is followed to the Dog it points to (the Dog object at address 74) that Dog (the one at address 74) is asked to change his name to Rowlf then, we return</p>
</blockquote>
<p>Now let’s think about what happens outside the method:</p>
<p><em><strong>Did myDog change?</strong></em></p>
<p>There’s the key.</p>
<p>Keeping in mind that myDog is a pointer, and not an actual Dog, the answer is NO. myDog still has the value 42; it’s still pointing to the original Dog.</p>
<p>It’s perfectly valid to follow an address and change what’s at the end of it; that does not change the variable, however.</p>
<p>Java works exactly like C. You can assign a pointer, pass the pointer to a method, follow the pointer in the method and change the data that was pointed to. However, you cannot change where that pointer points.</p>
<p>In C++, Ada, Pascal and other languages that support pass-by-reference, you can actually change the variable that was passed.</p>
<p>If Java had pass-by-reference semantics, the foo method we defined above would have changed where myDog was pointing when it assigned someDog on line BBB.</p>
<p>Think of reference parameters as being aliases for the variable passed in. When that alias is assigned, so is the variable that was passed in.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://javadude.com/articles/passbyvalue.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href
    
    </summary>
    
      <category term="Testing" scheme="https://athrunsun.github.io/categories/Testing/"/>
    
    
      <category term="Testing" scheme="https://athrunsun.github.io/tags/Testing/"/>
    
      <category term="TestNG" scheme="https://athrunsun.github.io/tags/TestNG/"/>
    
  </entry>
  
  <entry>
    <title>(Reproduce) TestNG Configuration Failures, Policy, and alwaysRun</title>
    <link href="https://athrunsun.github.io/2016/09/24/2016-9/testng_configuration_failures_policy_and_always_run/"/>
    <id>https://athrunsun.github.io/2016/09/24/2016-9/testng_configuration_failures_policy_and_always_run/</id>
    <published>2016-09-24T06:00:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://community.perfectomobile.com/posts/1094590-testng-configuration-failures-policy-and-alwaysrun" target="_blank" rel="external">Original Post</a></p>
<p>TestNG Listeners are fundamental in setting up and managing our integration with Selenium driver behind the scenes of a test. The issue we may run into from time to time is the driver initialization may fail and unless you suppress the exception this will cause a configuration failure in testNG.</p>
<p>Below I will attempt to explain some things you can do to overcome the configuration failure and help you better handle it in your framework.</p>
<h1 id="alwaysRun"><a href="#alwaysRun" class="headerlink" title="alwaysRun"></a>alwaysRun</h1><p>When configuration failures occur testNG’s default behavior is to then skip every <strong>after</strong> listener down the line. For instance if your exception occurred in <code>beforeClass</code> or <code>beforeMethod</code> then <code>afterMethod</code> and <code>afterClass</code> will be skipped. You can solve the issue of subsequent <strong>after</strong> listeners not being executed by adding the attribute <code>alwaysRun=true</code> to the annotation of the listeners. This could be useful if you are collecting reporting information during your execution and your rely on these listeners to set some data for your reporting.</p>
<p>Remember to create flags to verify if any additional cleanup should be performed in the event that the <strong>before</strong> listeners DID fail. For instance if the driver was never created calling driver quit could throw another exception in your <code>afterMethod</code> execution.</p>
<pre><code class="java">@AfterMethod(alwaysRun = true)
    public void afterMethod(Method method) {
</code></pre>
<h1 id="Should-you-add-alwaysRun-to-your-before-listeners"><a href="#Should-you-add-alwaysRun-to-your-before-listeners" class="headerlink" title="Should you add alwaysRun to your before listeners?"></a>Should you add <code>alwaysRun</code> to your <strong>before</strong> listeners?</h1><p>If you are adding group names to your methods you probably should but that is entirely up to you. When adding <code>alwaysRun</code> to <strong>before</strong> listeners it tells the listener that it is ok to run even if it doesn’t contain the group name for the test specified in your <code>testng.xml</code> suite.</p>
<pre><code class="java">@BeforeMethod(alwaysRun = true)
    public void beforeMethod(Method method)
</code></pre>
<p>If you wish to have a different set of <strong>before</strong> listeners which perform different behaviors based on the group name then you shouldn’t use <code>alwaysRun</code>.</p>
<h1 id="configFailurePolicy"><a href="#configFailurePolicy" class="headerlink" title="configFailurePolicy"></a>configFailurePolicy</h1><p>The default behavior of the <code>configFailurePolicy</code> setting has changed, purposely or not, from the behavior of “continue” to the behavior of “skip” over time. What this controls is whether the test methods should attempt to be ran regardless of a configuration failure. When set to skip the methods are skipped, when set to continue the methods attempt to run anyways.</p>
<p>In general you likely want your tests to skip because there is no need to attempt to run them if the driver has failed to initialize, to do so would only lead to additional failures and waste additional execution time. To force the setting of skip add the <code>configfailurepolicy=&quot;skip&quot;</code> to the the suite tag of your <code>testng.xml</code>.</p>
<p>However if you wish to have the execution continue on for some reason you can change this to <code>configfailurepolicy=&quot;continue&quot;</code>.</p>
<p>As of this writing the most current version of testNG is 6.9.10 and its default configfailurepolicy (what happens when this attribute is omitted from your testng.xml) is set to skip.</p>
<pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE suite SYSTEM &quot;http://testng.org/testng-1.0.dtd&quot;&gt;
&lt;suite name=&quot;Suite&quot; parallel=&quot;tests&quot; thread-count=&quot;10&quot; verbose=&quot;10&quot; configfailurepolicy=&quot;skip&quot;&gt;
  &lt;listeners&gt;
    &lt;listener class-name=&quot;org.uncommons.reportng.HTMLReporter&quot;/&gt;
    &lt;listener class-name=&quot;org.uncommons.reportng.JUnitXMLReporter&quot;/&gt;
    &lt;listener class-name=&quot;utilities.TestListener&quot; /&gt;
  &lt;/listeners&gt;
  &lt;test name=&quot;Test Chrome implicitNotVisible&quot;&gt;
  &lt;parameter name=&quot;targetEnvironment&quot; value=&quot;Chrome&quot; /&gt;
    &lt;parameter name=&quot;network&quot; value=&quot;&quot; /&gt;
    &lt;parameter name=&quot;networkLatency&quot; value=&quot;&quot; /&gt;
    &lt;classes&gt;
      &lt;class name=&quot;AmazonTesting.SleepTestSystem&quot;&gt;
        &lt;methods&gt;
          &lt;include name=&quot;implicitNotVisible&quot; /&gt;
        &lt;/methods&gt;
      &lt;/class&gt;
    &lt;/classes&gt;
  &lt;/test&gt;
&lt;/suite&gt;
</code></pre>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://community.perfectomobile.com/posts/1094590-testng-configuration-failures-policy-and-alwaysrun&quot; target=&quot;_blank&quot; rel=&quot;exte
    
    </summary>
    
      <category term="Testing" scheme="https://athrunsun.github.io/categories/Testing/"/>
    
    
      <category term="Testing" scheme="https://athrunsun.github.io/tags/Testing/"/>
    
      <category term="TestNG" scheme="https://athrunsun.github.io/tags/TestNG/"/>
    
  </entry>
  
  <entry>
    <title>Checkout multiple git working trees</title>
    <link href="https://athrunsun.github.io/2016/03/24/2016-3/git_multiple_working_trees/"/>
    <id>https://athrunsun.github.io/2016/03/24/2016-3/git_multiple_working_trees/</id>
    <published>2016-03-24T06:00:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p>The <code>worktree</code> sub command of git enable us to check out multiple branches, i.e. have multiple working trees at the same time.</p>
<p>This is really useful when I want to:</p>
<ul>
<li>Compare code from two branches in IDE instead of a GUI tool like smartgit.</li>
<li>Perform a long running test on one branch and working on another branch.</li>
</ul>
<p>See <a href="https://github.com/blog/2042-git-2-5-including-multiple-worktrees-and-triangular-workflows" target="_blank" rel="external">this github blog post</a> and <a href="https://git-scm.com/docs/git-worktree" target="_blank" rel="external">official documentation</a> for reference.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The &lt;code&gt;worktree&lt;/code&gt; sub command of git enable us to check out multiple branches, i.e. have multiple working trees at the same time.
    
    </summary>
    
      <category term="Git" scheme="https://athrunsun.github.io/categories/Git/"/>
    
    
  </entry>
  
  <entry>
    <title>(Reproduce) Difference between system testing and end to end testing?</title>
    <link href="https://athrunsun.github.io/2016/02/16/2016-2/system_testing_vs_end_to_end_testing/"/>
    <id>https://athrunsun.github.io/2016/02/16/2016-2/system_testing_vs_end_to_end_testing/</id>
    <published>2016-02-16T08:25:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://stackoverflow.com/questions/19378183/difference-between-system-testing-and-end-to-end-testing" target="_blank" rel="external">Original Post</a></p>
<p>For me there isn’t really a huge difference between the two and in some establishments the terms could be used interchangeably. Everywhere is different. I would try and explain it like so:</p>
<p><strong>System testing:</strong> You’re testing the whole system i.e. all of it’s components to ensure that each is functioning as intended. This is more from a functional side to <strong>check against requirements</strong>.</p>
<p><strong>End to end testing:</strong> This is more about the actual flow through a system in a more realistic end user scenario. Can a user navigate the application as expected and does it work. <strong>You’re testing the workflow</strong>.</p>
<p>For example if you were to test an e-commerce site the shop front, browsing for items, cart and checkout would all work fine in systems test. You may then find issues with the workflow of moving between these areas of functionality in an end to end test.</p>
<p>Reference:</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/System_testing" target="_blank" rel="external">System Testing</a></li>
<li><a href="http://www.techopedia.com/definition/7035/end-to-end-test" target="_blank" rel="external">End To End Testing</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/19378183/difference-between-system-testing-and-end-to-end-testing&quot; target=&quot;_blank&quot; rel=&quot;exter
    
    </summary>
    
      <category term="Testing" scheme="https://athrunsun.github.io/categories/Testing/"/>
    
    
  </entry>
  
  <entry>
    <title>(Reproduce) Android Rooting: A Developer&#39;s Guide</title>
    <link href="https://athrunsun.github.io/2016/02/13/2016-2/android_rooting_a_developers_guide/"/>
    <id>https://athrunsun.github.io/2016/02/13/2016-2/android_rooting_a_developers_guide/</id>
    <published>2016-02-13T09:30:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://seasonofcode.com/posts/android-rooting-a-developers-guide.html" target="_blank" rel="external">Original Post</a></p>
<p>By Chuan Ji</p>
<p>Nov 21, 2012</p>
<p>First things first — this is not about how to apply a rooting method, e.g., a one-click-root, to an Android device. Rather, it is about how one could go about developing a rooting method for a device that no one has rooted before, and is told through my experiences with rooting a particular device — the Barnes &amp; Noble Nook Tablet 8GB. For context, you can read my original thread “<a href="http://forum.xda-developers.com/showthread.php?t=1529553" target="_blank" rel="external">Root for Nook Tablet 8GB (w/ Android Market)</a> on XDA-Developers where I published my rooting method, which has reached a download count of — wait for it — OVER NINE THOUSAND!!!</p>
<p>For an overview of how rooting works behind the scenes, you may want to read my previous article <a href="http://seasonofcode.com/posts/how-rooting-works-a-technical-explanation-of-the-android-rooting-process.html" target="_blank" rel="external">How Rooting Works - A Technical Explanation of the Android Rooting Process</a> as background.</p>
<p>Sometime in late February (2012), on a visit to to a Barnes &amp; Noble store in Boston, I bought the then freshly released Nook Tablet 8GB entirely on impulse for $199. Being the hax0r that I am, the first thing I did when I got home was to try to root the device. It came as a nasty surprise, therefore, when I discovered that no one had yet succeeded in rooting the device. All I could find was a <a href="http://www.youtube.com/watch?v=x8e0OLWQYc4" target="_blank" rel="external">YouTube video</a> showing that the existing rooting method for its cousin, the Nook Tablet 16GB, did not work. After waiting for a few days, the absolutely pathetic app store and handicaps instituted by B&amp;N finally motivated me to develop a rooting method for the device myself.</p>
<h3 id="The-Plan"><a href="#The-Plan" class="headerlink" title="The Plan"></a>The Plan</h3><p>So, how do you go about rooting an Android device? As I explain in <a href="http://seasonofcode.com/posts/how-rooting-works-a-technical-explanation-of-the-android-rooting-process.html" target="_blank" rel="external">my previous article</a>, rooting is basically a two-step process:</p>
<ol>
<li>Find exploit that allows execution of arbitrary code as root</li>
<li>Use exploit to install <code>su</code> (with SUID bit set) and <code>Superuser.apk</code> as root</li>
</ol>
<p>After su and Superuser.apk are installed correctly, apps that require root (such as <a href="http://matrixrewriter.com/android/" target="_blank" rel="external">Titanium Backup</a> or <a href="https://play.google.com/store/apps/details?id=org.adaway&amp;hl=en" target="_blank" rel="external">AdAway</a>) will invoke su to run code as the privileged user.</p>
<h3 id="The-Process"><a href="#The-Process" class="headerlink" title="The Process"></a>The Process</h3><p>There are many generic or device-specific exploits that a hax0r may leverage to achieve privileged execution of arbitrary code. I would again refer you to <a href="http://jon.oberheide.org/files/bsides11-dontrootrobots.pdf" target="_blank" rel="external">this excellent presentation on various Android root exploits</a> that have been or may still be used for this purpose.</p>
<p>However, none of these methods that I knew of could work on the Nook Tablet, which is probably one of the most locked-down Android ROMs out there:</p>
<ul>
<li>Bootloader is locked.</li>
<li>ADB is disabled, and cannot be enabled from the UI.</li>
<li>Installing non-market apps (raw APKs) is disabled, and cannot be enabled from the UI.</li>
<li>No access to Google Play / Android Market (or any Google Apps).</li>
</ul>
<p>This rules out</p>
<p>1) root APKs and<br>2) the majority of exploits out there that require executing commands over ADB. It means that one cannot run any code on the device that does not come from B&amp;N period.</p>
<p>But of course there was another way in. Somebody on XDA-Developers had discovered that the bootloader of the Nook Tablet supported booting off an Android system located in partition images stored on an external microSD card. This mechanism is probably used to repair corrupted system partitions by B&amp;N customer support.</p>
<p>The solution, then, is clear: we create dummy system partition images that, instead of booting an Android system, installs <code>su</code> and <code>Superuser.apk</code> into the “normal” Android system in internal flash memory. More concretely, I modified the system initialization file inside the initrd inside the boot partition image to invoke a custom script that copied the relevant files into the system partition in the internal flash memory.</p>
<p>I based my work on <a href="http://forum.xda-developers.com/showthread.php?t=1517513" target="_blank" rel="external">bauwks’s 2nduboot images</a> and used <a href="https://gitorious.org/ac100/abootimg" target="_blank" rel="external">abootimg</a> to unpack files in the boot partition image <code>boot.img</code>:</p>
<pre><code class="shell"># Extracts files in the boot partition image into the current directory.
abootimg -x ./boot.img
# Extract files in the initrd cpio archive into the folder ./ramdisk/
aboot-unpack-initrd ./initrd.img
</code></pre>
<p>I changed the system initialization file <code>init.omap4430.rc</code> in the initrd to mount the system partition of the internal flash memory at <code>/foo</code> rather than <code>/system</code>, because later system initialization steps attempt to remount <code>/system</code> as read-only and so on, and for some reason I could not disable that behavior:</p>
<pre><code class="shell">on fs
    mkdir /foo
    mount ext4 /dev/block/platform/mmci-omap-hs.1/by-name/system /foo wait
</code></pre>
<p>I added the following to the system initialization file init.rc in the initrd to start my rooting script:</p>
<pre><code class="shell">service root_script /sbin/busybox ash /assets/run.sh
    oneshot
</code></pre>
<p>My rooting script, which I place in the directory <code>assets</code> in the initrd, installs not only <code>su</code>, but also Google Play and other Google apps which are missing from the Nook Tablet ROM:</p>
<pre><code class="shell"># Install su and Superuser.apk
/sbin/busybox cp /assets/su /foo/bin/
/sbin/busybox cp /assets/su /foo/xbin/
/sbin/busybox chmod 06755 /foo/xbin/su
/sbin/busybox chmod 06755 /foo/bin/su
/sbin/busybox cp /assets/Superuser.apk /foo/app/

# Install Busybox.
/sbin/busybox cp /sbin/busybox /foo/xbin/
/sbin/busybox chmod 06755 /foo/xbin/busybox

# Install Google Play and other Google apps.
/sbin/busybox cp /assets/*.apk /foo/app/
/sbin/busybox cp /assets/com.google.android.maps..xml /foo/etc/permissions/
/sbin/busybox cp /assets/com.google.android.maps.jar /foo/framework/
/sbin/busybox cp /assets/libvoicesearch.so /foo/lib/

# Done.
/sbin/busybox mount -o ro,remount /foo
</code></pre>
<p>In accordance with the above script, I had placed all <code>assets</code> in the assets directory inside the initrd, and the Busybox binary in <code>sbin</code> inside the initrd. With all changes done, I pack everything back into a new boot.img:</p>
<pre><code class="shell"># Build initrd cpio archive
abootimg-pack-initrd initrd.img.new
# Build new boot.img using previously extracted components
abootimg --create boot.img.new -f ./bootimg.cfg -k ./zImage -r ./initrd.img.new
</code></pre>
<p>Then I replace the <code>boot.img</code> on the SD card image with my <code>boot.img.new</code>, and the rooting method is done.</p>
<h3 id="Final-words"><a href="#Final-words" class="headerlink" title="Final words"></a>Final words</h3><p>The actual process, of course, was much, much more painful. The Nook Tablet’s bootloader is very picky; some microSD cards just won’t work, there is a file size limit on <code>boot.img</code>, etc.. It was also after much frustration that I discovered the mount-to-<code>/foo</code> trick. And I could not even keep track of how many factory restores I had to perform on the device to undo bad modifications. But it was still a lot of fun, and the euphoria at the end and the feeling of accomplishment when reply posts started rolling in and random people were donating $5 as a token of their appreciation could not be overstated.</p>
<p>Good luck rooting!</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://seasonofcode.com/posts/android-rooting-a-developers-guide.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;B
    
    </summary>
    
      <category term="Android" scheme="https://athrunsun.github.io/categories/Android/"/>
    
    
  </entry>
  
  <entry>
    <title>(Reproduce) How Rooting Works -- A Technical Explanation of the Android Rooting Process</title>
    <link href="https://athrunsun.github.io/2016/02/13/2016-2/how_rooting_works_a_technical_explanation_of_the_android_rooting_process/"/>
    <id>https://athrunsun.github.io/2016/02/13/2016-2/how_rooting_works_a_technical_explanation_of_the_android_rooting_process/</id>
    <published>2016-02-13T09:28:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://seasonofcode.com/posts/how-rooting-works-a-technical-explanation-of-the-android-rooting-process.html" target="_blank" rel="external">Original Post</a></p>
<p>By Chuan Ji</p>
<p>Oct 19, 2011</p>
<p>I have always been curious how rooting actually worked behind the scenes. After recently acquiring a new Eee Pad Slider, a Honeycomb tablet that so far no one has been able to root, the frustration of being locked out of this amazing piece of hardware with so much potential led me to finally sit down and figure out what exactly rooting means, what it entails from a technical perspective, and how hackers out in the wild are approaching the rooting of a new device. Although all this information is out there, I have not been able to find a good article that had both the level of technical detail that I wanted and an appropriate introduction to the big picture, and so I decided to write my own.</p>
<p>This is NOT a noob-friendly guide to rooting a particular Android device. Rather, it is a general explanation of how stock Android ROMs try to prevent unprivileged access, how hackers attack this problem and how rooting software leverage various exploits to defeat these security mechanisms.</p>
<h3 id="I-The-Goal"><a href="#I-The-Goal" class="headerlink" title="I. The Goal"></a>I. The Goal</h3><p>Let us first take a step back and consider <em>exactly</em> what we mean by rooting. Forget flashing custom ROMs, enabling WiFi tethering or installing Superuser.apk; fundamentally, rooting is about obtaining root access to the underlying Linux system beneath Android and thus gaining absolute control over the software that is running on the device. Things that require root access on a typical Linux system — mounting and unmounting file systems, starting your favorite SSH or HTTP or DHCP or DNS or proxy servers, killing system processes, chroot-ing, etc., — require root access on Android as well. Being able to run arbitrary commands as the root user allows you to do absolutely <em>anything</em> on a Linux / Android system, and this is real goal of rooting.</p>
<p>Stock OEM Android builds typically do not allow users to execute arbitrary code as root. This essentially means that you as a user are granted only limited control over your own device; you can make your device do task X only if the manufacturer explicitly decided to allow it and shipped a program to do it. You will not be able to use third-party apps to accomplish a task that your manufacturer does not wish you to do. WiFi tethering is a good example of this. Cell phone carriers obviously do not want you to tether your phone without paying them additional charges. Therefore, many phones come pre-packaged with their own proprietary WiFi tethering apps that demand extraneous fees. But without root access, you will not be able to install a free alternative like <a href="http://code.google.com/p/android-wifi-tether/" target="_blank" rel="external">Wireless Tether For Root Users</a>. Why this is accepted practice in the industry is a mystery to me. The only difference between cell phones, tablets and computers is their form factor; but while a PC vendor would fail spectacularly if they tried to prevent users from running arbitrary programs on their machines, cell phone vendors are clearly not judged along the same lines. But such arguments would belong to another article.</p>
<h3 id="II-The-Enemy-Protection-Mechanisms-On-A-Stock-OEM-Android-ROM"><a href="#II-The-Enemy-Protection-Mechanisms-On-A-Stock-OEM-Android-ROM" class="headerlink" title="II. The Enemy: Protection Mechanisms On A Stock OEM Android ROM"></a>II. The Enemy: Protection Mechanisms On A Stock OEM Android ROM</h3><h4 id="1-Bootloader-and-Recovery"><a href="#1-Bootloader-and-Recovery" class="headerlink" title="1. Bootloader and Recovery"></a>1. Bootloader and Recovery</h4><p>The bootloader, the first piece of code executed when your device is powered on, is responsible for loading the Android OS and the recovery system and flashing a new ROM. People refer to some bootloaders as “unlocked” if a user can flash and boot arbitrary ROMs without hacking; unfortunately, many Android devices have locked bootloaders that you would have to hack around in order to make them do anything other than boot the stock ROM. A Samsung smartphone I had used some months ago had an unlocked bootloader; I could press a certain combination of hardware keys on the phone, connect it to my computer, and flash any custom ROM onto it using Samsung’s utilities without having to circumvent any protection mechanisms. The same is not true for my Motorola Droid 2 Global; the bootloader, as far as I know, cannot be hacked. The Eee Pad Slider, on the other hand, is an interesting beast; as with other nVidia Tegra 2 based devices, its bootloader is controllable through the <code>nvflash</code> utility, but only if you know the <em>secure boot key</em> (SBK) of the device. (The SBK is a private AES key used to encrypt the commands sent to the bootloader; the bootloader will only accept the command if it has been encrypted by the particular key of the device.) Currently, as the SBK of the Eee Pad Slider is not publicly known, the bootloader remains inaccessible.</p>
<p>System recovery is the second piece of low-level code on board any Android device. It is separate from the Android userland and is typically located on its own partition; it is usually booted by the bootloader when you press a certain combination of hardware keys. It is important to understand that it is a totally independent program; Linux and the Android userland is not loaded when you boot into recovery, and any high-level concept such as root does not exist here. It is simple program that really is a very primitive OS, and it has absolute control over the system and will do anything you want as long as the code to do it is built in. Stock recovery varies with the manufacturer, but often includes functionalities like reformatting the <code>/data</code> partition (factory reset) and flashing an update ROM (<code>update.zip</code>, located at the root of the external microSD card) signed by the manufacturer. Note I said signed by the manufacturer; typically it is not possible to flash custom update files unless you obtain the private key of the manufacturer and sign your custom update with it, which is both impossible for most and illegal under certain jurisdictions. However, since recovery is stored in a partition just like <code>/system</code>, <code>/data</code> and <code>/cache</code> (more about that later), you can replace it with a custom recovery if you have root access in Linux / Android. Most people do just that upon rooting their device; <a href="http://www.clockworkmod.com/" target="_blank" rel="external">ClockworkMod Recovery</a> is a popular third-party recovery image, and allows you to flash arbitrary ROMs, backup and restore partitions, and lots of other magic.</p>
<h4 id="2-ADB"><a href="#2-ADB" class="headerlink" title="2. ADB"></a>2. ADB</h4><p>ADB (see <a href="http://developer.android.com/guide/developing/tools/adb.html" target="_blank" rel="external">the official documentation for ADB</a>) allows a PC or a Mac to connect to an Android device and perform certain operations. One such operation is to launch a simple shell on the device, using the command <code>adb shell</code>. The real question is what user do the commands executed by that shell process run as. It turns out that it depends on the value of an Android system property, named <code>ro.secure</code>. (You can view the value of this property by typing <code>getprop ro.secure</code> either through an ADB shell or on a terminal emulator on the device.) If <code>ro.secure=0</code>, an ADB shell will run commands as the root user on the device. But if <code>ro.secure=1</code>, an ADB shell will run commands as an unprivileged user on the device. Guess what <code>ro.secure</code> is set to on almost every stock OEM Android build. But can we change the value of <code>ro.secure</code> on a system? The answer is no, as implied by the <code>ro</code> in the name of the property. The value of this property is set at boot time from the <code>default.prop</code> file in the root directory. The contents of the root directory are essentially <em>copied</em> from a partition in the internal storage on boot, but you cannot write to the partition if you are not already root. In other words, this property denies root access via ADB, and the only way you could change it is by gaining root access in the first place. Thus, it is secure.</p>
<h4 id="3-Android-UI"><a href="#3-Android-UI" class="headerlink" title="3. Android UI"></a>3. Android UI</h4><p>On an Android system, all Android applications that you can see or interact with directly are running as _un_privileged users in sandboxes. Logically, a program running as an unprivileged user cannot start another program that is run as the privileged user; otherwise any program can simply start another copy of itself in privileged mode and gain privileged access to everything. On the other hand, a program running as root can start another program as root or as an unprivileged user. On Linux, privilege escalation is usually accomplished via the <code>su</code> and <code>sudo</code> programs; they are often the only programs in the system that are able to execute the system call <code>setuid(0)</code> that changes the current program from running as an unprivileged user to running as root. Apps that label themselves as requiring root are in reality just executing other programs (often just native binaries packaged with the app) through <code>su</code>. Unsurprisingly, stock OEM ROMs never come with these <code>su</code>. You cannot just download it or copy it over either; it needs to have its SUID bit set, which indicates to the system that the programs this allowed to escalate its runtime privileges to root. But of course, if you are not root, you cannot set the SUID bit on a program. To summarize, what this means is that any program that you can interact with on Android (and hence running in unprivileged mode) is unable to either<br>1) gain privileged access and execute in privileged mode, or<br>2) start another program that executes in privileged mode. If this holds, the Android system by itself is pretty much immune to privilege escalation attempts.</p>
<p>We will see the loophole exploited by on-device rooting applications in the next section.</p>
<h3 id="III-Fighting-the-System"><a href="#III-Fighting-the-System" class="headerlink" title="III. Fighting the System"></a>III. Fighting the System</h3><p>So how the hell do you root an Android? Well, from the security mechanisms described above, we can figure out how to attack each component in turn.</p>
<p>If your device happens to have an unlocked bootloader, you’re pretty much done. An example is the Samsung phone that I had had. Since the bootloader allowed the flashing of arbitrary ROMs, somebody essentially pulled the stock ROM from the phone (using <code>dd</code>), added <code>su</code>, and repackaged it into a modified ROM. All I as a user needed to do was to power off the phone, press a certain combination of hardware keys to start the phone in flashing mode, and use Samsung’s utilities to flash the modified ROM onto the phone.</p>
<p>Believe it or not, certain manufacturers don’t actually set <code>ro.secure</code> to 1. If that is the case, rooting is even easier; just plug the phone into your computer and run ADB, and you now have a shell that can execute any program as root. You can then mount <code>/system as</code> read-write, install <code>su</code> and all your dreams have come true.</p>
<p>But many other Android devices have locked bootloaders and <code>ro.secure</code> set. As explained above, they should not be root-able because you can only interact with unprivileged programs on the system and they cannot help you execute any privileged code. So what’s the solution?</p>
<p>We know that a number of important programs, including low-level system services, must run as root even on Android in order to access hardware resources. Typing <code>ps</code> on an Android shell (either via ADB or a terminal emulator on the device) will give you an idea. These programs are started by the <code>init</code> process, the first process started by the kernel (I often feel that the kernel and the <code>init</code> process are kind of analogous to Adam and Eve — the kernel spawns <code>init</code> in a particular fashion, and <code>init</code> then goes on and spawns all other processes) which has to run as root because it needs to start other privileged system processes.</p>
<p>Now here’s the key insight: if you can hack / trick one of these system processes running in privileged mode to execute your arbitrary code, you have just gained privileged access to the system. This how all one-click-root methods work, including z4root, gingerbreak, and so on. If you are truly curious, I highly recommend <a href="http://jon.oberheide.org/files/bsides11-dontrootrobots.pdf" target="_blank" rel="external">this excellent presentation on the various exploits used by current rooting tools</a>, but the details are not as relevant here as the simple idea behind them. That idea is that there are vulnerabilities in the system processes running as root in the background that, if exploited, will allow us to execute arbitrary code as root. Well, that “arbitrary code” is most certainly a piece of code that mounts <code>/system</code> in read-write mode and installs a copy of <code>su</code> permanently on the system, so that from then on we don’t need to jump through the hoops to run the programs we really wanted to run in the first place.</p>
<p>Since Android is open source as is Linux, what people have done is to scrutinize and reason about the source code of the various system services until they find a security hole they can leverage. This becomes increasingly hard as Google and the maintainers of the various pieces of code fix those particular vulnerabilities when they are discovered and published, which means that the exploits will eventually become obsolete with newer devices. But the good news is that manufacturers are not stupid enough to push OTA updates to fix a vulnerability just to prevent rooting as it is very expensive for them; in addition, devices in the market are always lagging behind the newest software releases. Thus, it takes quite some time before these rooting tools are rendered useless by new patches, and by then hopefully other exploits would have been discovered.</p>
<h3 id="IV-See-It-In-Action"><a href="#IV-See-It-In-Action" class="headerlink" title="IV. See It In Action!"></a>IV. See It In Action!</h3><p>To see all of this in action, you are invited to check out my follow-up article: <a href="http://seasonofcode.com/posts/android-rooting-a-developers-guide.html" target="_blank" rel="external">Android Rooting: A Developer’s Guide</a>, which explains how I applied this stuff to figure out how to root an actual device.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://seasonofcode.com/posts/how-rooting-works-a-technical-explanation-of-the-android-rooting-process.html&quot; target=&quot;_blank&quot; rel
    
    </summary>
    
      <category term="Android" scheme="https://athrunsun.github.io/categories/Android/"/>
    
    
  </entry>
  
  <entry>
    <title>(Reproduce) Alternatives To Git Submodule: Git Subtree</title>
    <link href="https://athrunsun.github.io/2016/02/10/2016-2/alternative_to_git_submodule_git_subtree/"/>
    <id>https://athrunsun.github.io/2016/02/10/2016-2/alternative_to_git_submodule_git_subtree/</id>
    <published>2016-02-10T08:48:00.000Z</published>
    <updated>2019-03-18T08:00:19.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blogs.atlassian.com/2013/05/alternatives-to-git-submodule-git-subtree/" target="_blank" rel="external">Original Post</a></p>
<p>By <a href="http://blogs.atlassian.com/author/npaolucci/" target="_blank" rel="external">Nicola Paolucci</a></p>
<p><a href="http://blogs.atlassian.com/blog-cat/developer/" target="_blank" rel="external">Developer</a></p>
<p>On May 16, 2013</p>
<p>Update: I wrote a follow up <a href="https://developer.atlassian.com/blog/2015/05/the-power-of-git-subtree" target="_blank" rel="external">article on the power of Git subtree</a></p>
<p>The Internet is full of articles on why you <a href="http://codingkilledthecat.wordpress.com/2012/04/28/why-your-company-shouldnt-use-git-submodules/" target="_blank" rel="external">should</a> <a href="http://ayende.com/blog/4746/the-problem-with-git-submodules" target="_blank" rel="external">not</a> <a href="http://somethingsinistral.net/blog/git-submodules-are-probably-not-the-answer/" target="_blank" rel="external">use</a> Git submodules. I mostly agree, although I am not so harsh in my evaluation. As I explained in a <a href="http://blogs.atlassian.com/2013/03/git-submodules-workflows-tips/" target="_blank" rel="external">previous post</a>, <code>submodules</code> are useful for a few use cases but have several drawbacks.</p>
<p>Are there alternatives? The answer is: yes! There are (at least) two tools that can help track the history of software dependencies in your project while allowing you to keep using git:</p>
<ul>
<li><a href="https://github.com/git/git/blob/master/contrib/subtree/git-subtree.txt" target="_blank" rel="external">git subtree</a></li>
<li><a href="https://code.google.com/p/git-repo/" target="_blank" rel="external">google repo</a></li>
</ul>
<p>In this post I will be looking at <code>git subtree</code> and show why it is an improvement – albeit not perfect – over <code>git submodule</code>.</p>
<p>As a working example I run to my usual use case. How do I easily store and keep up to date the vim plugins used in <a href="https://bitbucket.org/durdn/cfg" target="_blank" rel="external">my dotfiles</a>?</p>
<h3 id="Why-use-subtree-instead-of-submodule"><a href="#Why-use-subtree-instead-of-submodule" class="headerlink" title="Why use subtree instead of submodule?"></a>Why use subtree instead of submodule?</h3><p>There are several reasons why you might find <code>subtree</code> better to use:</p>
<ul>
<li>Management of a simple workflow is easy.</li>
<li>Older version of <code>git</code> are supported (even before <code>v1.5.2</code>).</li>
<li>The sub-project’s code is available right after the <code>clone</code> of the super project is done.</li>
<li><code>subtree</code> does not require users of your repository to learn anything new, they can ignore the fact that you are using <code>subtree</code> to manage dependencies.</li>
<li><code>subtree</code> does not add new metadata files like <code>submodules</code> doe (i.e. <code>.gitmodule</code>).</li>
<li>Contents of the module can be modified without having a separate repository copy of the dependency somewhere else.</li>
</ul>
<p>In my opinion the drawbacks are acceptable:</p>
<ul>
<li>You must learn about a new merge strategy (i.e. <code>subtree</code>).</li>
<li>Contributing code back <code>upstream</code> for the sub-projects is slightly more complicated.</li>
<li>The responsibility of not mixing super and sub-project code in commits lies with you.</li>
</ul>
<h3 id="How-to-use-git-subtree"><a href="#How-to-use-git-subtree" class="headerlink" title="How to use git subtree?"></a>How to use git subtree?</h3><p><code>git subtree</code> is available in stock version of <code>git</code> available since May 2012 – <code>1.7.11</code>+. The version installed by <a href="http://mxcl.github.io/homebrew/" target="_blank" rel="external">homebrew</a> on OSX already has subtree properly wired but on some platforms you might need to follow the <a href="https://github.com/git/git/blob/master/contrib/subtree/INSTALL" target="_blank" rel="external">installation instructions</a>.</p>
<p>Let me show you the canonical example of tracking a vim plug-in using <code>git subtree</code>.</p>
<h4 id="The-quick-and-dirty-way-without-remote-tracking"><a href="#The-quick-and-dirty-way-without-remote-tracking" class="headerlink" title="The quick and dirty way without remote tracking"></a>The quick and dirty way without remote tracking</h4><p>If you just want a couple of one liners to cut and paste just read this paragraph.</p>
<p>First add the <code>subtree</code> at a specified <code>prefix</code> folder:</p>
<pre><code class="shell">git subtree add --prefix .vim/bundle/tpope-vim-surround https://bitbucket.org/vim-plugins-mirror/vim-surround.git master --squash
</code></pre>
<p>(The common practice is to not store the entire history of the sub-project in your main repository, but If you want to preserve it just omit the <code>-squash</code> flag.)</p>
<p>The above command produces this output:</p>
<pre><code class="shell">git fetch https://bitbucket.org/vim-plugins-mirror/vim-surround.git master
warning: no common commits
remote: Counting objects: 338, done.
remote: Compressing objects: 100% (145/145), done.
remote: Total 338 (delta 101), reused 323 (delta 89)
Receiving objects: 100% (338/338), 71.46 KiB, done.
Resolving deltas: 100% (101/101), done.
From https://bitbucket.org/vim-plugins-mirror/vim-surround.git
* branch            master     -} FETCH_HEAD
Added dir &#39;.vim/bundle/tpope-vim-surround&#39;
</code></pre>
<p>As you can see this records a <code>merge commit</code> by squashing the whole history of the <code>vim-surround</code> repository into a single one:</p>
<pre><code class="shell">1bda0bd [3 minutes ago] (HEAD, stree) Merge commit &#39;ca1f4da9f0b93346bba9a430c889a95f75dc0a83&#39; as &#39;.vim/bundle/tpope-vim-surround&#39; [Nicola Paolucci]
ca1f4da [3 minutes ago] Squashed &#39;.vim/bundle/tpope-vim-surround/&#39; content from commit 02199ea [Nicola Paolucci]
</code></pre>
<p>If after a while you want to update the code of the plugin from the <code>upstream</code> repository you can just <code>subtree pull</code>:</p>
<pre><code class="shell">git subtree pull --prefix .vim/bundle/tpope-vim-surround https://bitbucket.org/vim-plugins-mirror/vim-surround.git master --squash
</code></pre>
<p>This is very quick and painless but the commands are slightly lengthy and hard to remember. We can make the commands shorter by adding the sub-project as a remote.</p>
<h4 id="Adding-the-sub-project-as-a-remote"><a href="#Adding-the-sub-project-as-a-remote" class="headerlink" title="Adding the sub-project as a remote"></a>Adding the sub-project as a remote</h4><p>Adding the subtree as a remote allows us to refer to it in shorter form:</p>
<pre><code class="shell">git remote add -f tpope-vim-surround https://bitbucket.org/vim-plugins-mirror/vim-surround.git
</code></pre>
<p>Now we can add the subtree (as before), but now we can refer to the remote in short form:</p>
<pre><code class="shell">git subtree add --prefix .vim/bundle/tpope-vim-surround tpope-vim-surround master --squash
</code></pre>
<p>The command to update the sub-project at a later date becomes:</p>
<pre><code class="shell">git fetch tpope-vim-surround master
git subtree pull --prefix .vim/bundle/tpope-vim-surround tpope-vim-surround master --squash
</code></pre>
<h4 id="Contributing-back-to-upstream"><a href="#Contributing-back-to-upstream" class="headerlink" title="Contributing back to upstream"></a>Contributing back to upstream</h4><p>We can freely commit our fixes to the sub-project in our local working directory now.</p>
<p>When it’s time to contribute back to the <code>upstream</code> project we need to fork the project and add it as another remote:</p>
<pre><code class="shell">git remote add durdn-vim-surround ssh://git@bitbucket.org/durdn/vim-surround.git
</code></pre>
<p>Now we can use the <code>subtree push</code> command like the following:</p>
<pre><code class="shell">git subtree push --prefix=.vim/bundle/tpope-vim-surround/ durdn-vim-surround master

git push using:  durdn-vim-surround master
Counting objects: 5, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 308 bytes, done.
Total 3 (delta 2), reused 0 (delta 0)
To ssh://git@bitbucket.org/durdn/vim-surround.git
  02199ea..dcacd4b  dcacd4b21fe51c9b5824370b3b224c440b3470cb -} master
</code></pre>
<p>After this we’re ready and we can open a <code>pull-request</code> to the maintainer of the package.</p>
<h4 id="Without-using-the-subtree-command"><a href="#Without-using-the-subtree-command" class="headerlink" title="Without using the subtree command"></a>Without using the subtree command</h4><p><code>git subtree</code> is different from the <a href="https://www.kernel.org/pub/software/scm/git/docs/howto/using-merge-subtree.html" target="_blank" rel="external">subtree merge strategy</a>. You can still use the merge strategy even if for some reason <code>git subtree</code> is not available. Here is how you would go about it:</p>
<p>Add the dependency as a simple <a href="https://github.com/git/git/blob/master/contrib/subtree/INSTALL" target="_blank" rel="external">git remote</a>:</p>
<pre><code class="shell">git remote add -f tpope-vim-surround https://bitbucket.org/vim-plugins-mirror/vim-surround.git
</code></pre>
<p>Before reading the contents of the dependency into the repository it’s important to record a merge so that we can track the entire tree history of the plug-in up to this point:</p>
<pre><code class="shell">git merge -s ours --no-commit tpope-vim-surround/master
</code></pre>
<p>Which outputs:</p>
<pre><code class="shell">Automatic merge went well; stopped before committing as requested
</code></pre>
<p>We then read the content of the latest tree-object in the plugin repository into our working directory ready to be committed:</p>
<pre><code class="shell">git read-tree --prefix=.vim/bundle/tpope-vim-surround/ -u tpope-vim-surround/master
</code></pre>
<p>Now we can commit (and it will be a merge commit that will preserve the history of the tree we read):</p>
<pre><code class="shell">git ci -m&quot;[subtree] adding tpope-vim-surround&quot;

[stree 779b094] [subtree] adding tpope-vim-surround
</code></pre>
<p>When we want to update the project we can now <code>pull</code> using the <code>subtree</code> merge strategy:</p>
<pre><code class="shell">git pull -s subtree tpope-vim-surround master
</code></pre>
<h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h3><p>After having used <code>submodule</code> for a while I appreciate <code>git subtree</code> much more, lots of <code>submodule</code> problems are superseded and solved by <code>subtree</code>. As usual, with all things <code>git</code>, there is a learning curve to make the most of the feature.</p>
<p>Follow me <a href="http://twitter.com/durdn" target="_blank" rel="external">@durdn</a> for more Git rocking. And check out <a href="http://www.atlassian.com/software/stash/overview" target="_blank" rel="external">Atlassian Stash</a> if you’re looking for a killer tool to manage your Git repos.</p>
<p><strong>Update: I just wrote a <a href="https://developer.atlassian.com/blog/2015/05/the-power-of-git-subtree" target="_blank" rel="external">new article on the power of Git subtree</a>.</strong></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blogs.atlassian.com/2013/05/alternatives-to-git-submodule-git-subtree/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Original Post&lt;/a&gt;&lt;
    
    </summary>
    
      <category term="Git" scheme="https://athrunsun.github.io/categories/Git/"/>
    
    
  </entry>
  
  <entry>
    <title>Java Spring - &quot;classpath:&quot; and &quot;classpath:*&quot; prefix</title>
    <link href="https://athrunsun.github.io/2016/01/22/2016-1/java_spring_classpath_prefix/"/>
    <id>https://athrunsun.github.io/2016/01/22/2016-1/java_spring_classpath_prefix/</id>
    <published>2016-01-22T13:52:00.000Z</published>
    <updated>2019-03-18T08:00:19.494Z</updated>
    
    <content type="html"><![CDATA[<h4 id="StackOverflow-Spring-classpath-prefix-difference"><a href="#StackOverflow-Spring-classpath-prefix-difference" class="headerlink" title="StackOverflow: Spring classpath prefix difference"></a><a href="http://stackoverflow.com/questions/3294423/" target="_blank" rel="external">StackOverflow: Spring classpath prefix difference</a></h4><p>The <code>classpath*:conf/appContext.xml</code> simply means that all <code>appContext.xml</code> files under conf folders in all your jars on the classpath will be picked up and joined into one big application context.</p>
<p>In contrast, <code>classpath:conf/appContext.xml</code> will load only one such file… the first one found on your classpath.</p>
<p>One very important thing - if you use the <code>*</code> and Spring finds no matches, it will not complain. If you don’t use the <code>*</code> and there are no matches, the context will not start up!</p>
<h4 id="What-is-the-difference-between-“classpath-”-and-“classpath-”-in-Spring-XML"><a href="#What-is-the-difference-between-“classpath-”-and-“classpath-”-in-Spring-XML" class="headerlink" title="What is the difference between “classpath:” and “classpath:/” in Spring XML?"></a><a href="http://stackoverflow.com/questions/13994840/" target="_blank" rel="external">What is the difference between “classpath:” and “classpath:/” in Spring XML?</a></h4><p>I don’t see any difference between these two. The biggest difference that you will see is that the relative path and the <code>*</code> on the classpath location</p>
<p>Here is an excerpt from <a href="http://static.springsource.org/spring/docs/3.0.x/spring-framework-reference/html/resources.html" target="_blank" rel="external">Spring Resources</a>, look for section 4.7.2.2</p>
<p><strong>Classpath*:</strong></p>
<p>The <code>classpath*:</code> prefix can also be combined with a PathMatcher pattern in the rest of the location path, for example <code>classpath*:META-INF/*-beans.xml</code>. In this case, the resolution strategy is fairly simple: a <code>ClassLoader.getResources()</code> call is used on the last non-wildcard path segment to get all the matching resources in the class loader hierarchy, and then off each resource the same PathMatcher resoltion strategy described above is used for the wildcard subpath.</p>
<p>This means that a pattern like <code>classpath*:*.xml</code> will not retrieve files from the root of jar files but rather only from the root of <strong>expanded directories</strong>. This originates from a limitation in the JDK’s <code>ClassLoader.getResources()</code> method which only returns file system locations for a passed-in empty string (indicating potential roots to search).</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;StackOverflow-Spring-classpath-prefix-difference&quot;&gt;&lt;a href=&quot;#StackOverflow-Spring-classpath-prefix-difference&quot; class=&quot;headerlink&quot; tit
    
    </summary>
    
      <category term="Java" scheme="https://athrunsun.github.io/categories/Java/"/>
    
    
  </entry>
  
</feed>
